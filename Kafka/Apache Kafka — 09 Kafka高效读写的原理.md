## Apache Kafka — Kafka高效读写的原理



无论 kafka 作为 MQ 也好，作为存储层也罢，无非就是两个功能（好简单的样子），一是 Producer 生产的数据存到 broker，二是 Consumer 从 broker 读取数据。那 Kafka 的快也就体现在读写两个方面了，下面我们就聊聊 Kafka 高效的原因。



## 一、顺序写磁盘



<img src="https://image.easyblog.top/20191228112029_11745.png" style="zoom:150%;" />

我们都知道，影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。而**机械硬盘的连续读写性能很好，但随机读写性能很差**，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。

因此，在许多的开源框架如 **Kafka**、[HBase](https://cloud.tencent.com/product/hbase?from=10680) 中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。

**具体来说，Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 partition 的末尾**。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。

同时，由于磁盘有限，磁盘不可能保存所有数据，实际上作为消息系统 Kafka 也没必要保存所有数据，需要删除旧的数据。又由于顺序写入的原因，所以 **Kafka 采用各种删除策略删除数据的时候，并非通过使用“读 - 写”模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个文件的方式去删除 Partition 内的数据**。这种方式清除旧数据的方式，也避免了对文件的随机写操作。



## 二、零拷贝技术

Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程。这一过程的性能直接影响 Kafka 的整体吞吐量。

传统 Linux 系统中，标准的 I/O 接口（例如read，write）都是**基于数据拷贝操作**的，即 **I/O 操作会导致数据在内核地址空间的缓冲区和用户地址空间的缓冲区之间进行拷贝**，所以标准 I/O 也被称作缓存 I/O。这样做的好处是，如果所请求的数据已经存放在内核的高速缓冲存储器中，那么就可以减少实际的 I/O 操作，但坏处就是数据拷贝的过程，会导致 CPU 开销。

> 操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。 为了避免用户进程直接操作内核，保证内核安全，操作系统将内存划分为两部分，一部分是**内核空间（Kernel-space）**，一部分是**用户空间（User-space）**。



我们不妨把 Kafka 的生产和消费简化成如下两个过程来看：

1. **网络数据持久化到磁盘 (Producer 到 Broker)**
2. **磁盘文件通过网络发送（Broker 到 Consumer）**

### 2.1 网络数据持久化到磁盘

传统模式下使用 `read()` 系统调用读取数据，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。这一过程实际上**发生了四次数据拷贝**：

1. 首先通过 DMA copy 将网络数据拷贝到内核态 Socket Buffer
2. 然后应用程序将内核态 Buffer 数据读入用户态（CPU copy）
3. 接着用户程序将用户态 Buffer 再拷贝到内核态（CPU copy）
4. 最后通过 DMA copy 将数据拷贝到磁盘文件

>  DMA（Direct Memory Access）：直接存储器访问。DMA 是一种无需 CPU 的参与，让外设和系统内存之间进行双向数据传输的硬件机制。使用 DMA 可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐率。

同时，还伴随着四次上下文切换，如下图所示：

<img src="https://image.easyblog.top/960sgasah7.png" style="zoom:75%;" />

数据落盘通常都是非实时的，kafka 生产者数据持久化也是如此。Kafka 的数据**并不是实时的写入硬盘**，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率。

对于 kafka 来说，Producer 生产的数据存到 broker，这个过程读取到 socket buffer 的网络数据，其实可以直接在内核空间完成落盘。并没有必要将 socket buffer 的网络数据，读取到应用进程缓冲区；在这里应用进程缓冲区其实就是 broker，broker 收到生产者的数据，就是为了持久化。

在此特殊场景下，接收来自 socket buffer 的网络数据，应用进程不需要中间处理、直接进行持久化时。可以使用 mmap 内存文件映射。此过程如下图所示：

<img src="https://image.easyblog.top/s9xo1tjp4d.png" alt="s9xo1tjp4d" style="zoom:75%;" />

但是，`mmap` 也有一个很明显的缺陷——不可靠，写到 `mmap` 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。为此，Kafka 提供了一个参数——`producer.type` 来控制是不是主动将数据flush到磁盘；如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 就叫异步(async)，默认是 sync。



### 2.2 磁盘文件通过网络发送

同样地，传统方式会使用 `send()`系统调用发送数据：会先读取磁盘、再用 socket 发送，实际也是经过四次 copy。

```c
buffer = File.read Socket.send(buffer)
```

这一过程可以类比上边的生产消息：

1. 首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝）
2. 然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝）
3. 接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝）
4. 最后通过 DMA 拷贝将数据拷贝到 NIC Buffer



Linux 2.4版本开始， 内核增加了 `sendfile()` 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件 - 网络发送由一个 `sendfile()`  调用完成，整个过程只有两次上下文切换，因此大大提高了性能。

<img src="https://image.easyblog.top/jwsgj6ky88.png" style="zoom:70%;" />

Kafka通过零拷贝技术只用将磁盘文件中的数据复制到页面缓存中一份，然后将数据直接从页面缓存直接发送到网络中（发送给不同的订阅者时，都可以使用同一个页面缓存），避免了重复复制操作。

比如，有十个消费者，传统方式下，数据复制次数为4*10=40次，而使用零拷贝技术只需要复制1+10=11次，一次为磁盘复制到页面缓存，10次表示10个消费者各自读取一次页面缓存。






## 参考资料

* [CSDN. kafka高效读写的原因](https://blog.csdn.net/qq_39034845/article/details/108189321)
* [腾讯云. Kafka为什么能那么快？高效读写数据，原来是这样做到的](https://cloud.tencent.com/developer/article/1686119)

