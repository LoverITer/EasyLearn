

## 第一章 计算机网络

### 1、网络模型和协议

**OSI**定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），即 OSI，开放互连系统参考模型。

<img src="http://image.easyblog.top/1631856828503e063d023-4d33-496b-9486-b883a6e5d3c2.gif" style="width:45%;" />

OSI的七层协议体系结构概念清楚，理论完整，但既复杂又不实用。TCP/IP体系结构则不同，TCP/IP是一个四层体系结构，包含**应用层、运输层、网络层和网络接口层**。

<img src="http://image.easyblog.top/1631859345937e6910bb4-4032-427e-8a22-e959bf5283ff.png" style="width:65%;" />



 TCP/IP并不是单指TCP和IP两个具体的协议而是表示互联网所使用的整个TCP/IP协议族，这些协议分布网络模型的各层，它们各司其职完成网络通信任务：

**（1）应用层**

体系结构中的最高层，任务是**通过应用进程间的交互来完成特定网络应用**。应用层协议定义的是应用进程间通信和交互的规则。应用层协议：DNS、HTTP、SMTP等。应用层传输的数据单元是**报文（message）**。

**（2）传输层**

运输层的任务就是负责向**两台主机中进程之间的通信提供通用的数据传输服务**。由于一台主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用是运输层把收到的信息分别交付上面应用层中的相应进程。

运输层主要使用以下两种协议：

* **传输控制协议TCP**：提供面向连接的、可靠的数据传输服务，数据传输单位是**报文段（segment）**。

* **用户数据报协议UDP**：提供无连接的、尽最大努力的数据传输服务（不保证数据传输的可靠性），数据传输单位是用户数据报。

**（3）网络层**

网络层负责为分组交换网上的不同**主机**提供通信服务，网络层把运输层产生的报文段或用户数据报封装成分组或包进行传送。在TCP/IP体系中，网络层使用IP协议，因此分组也叫做IP数据报，或简称数据报。

**无论哪一层传送的数据单元，都可笼统地用分组来表示**，运输层的用户数据报UDP和网络层的IP数据报不同。

网络层的另一个任务即选择合适的路由，使源主机运输层传下来的分组，能够通过网络中的路由器找到目的主机。网络层中的**网络**不是通常提到的具体网络，而是计算机网络体系结构模型中的第三层的名称。

互联网由大量的异构网络通过路由器相互连接起来。互联网使用的网络层协议是无连接的**网际协议IP**和许多种路由选择协议，因此互联网的网络层也叫做**网际层**或**IP层**。

**（4）网络接口层**

网络接口层主要包括两个部分：数据两路链路层和物理层

**（4.1）数据链路层**

简称为链路层。两个相邻结点之间传送数据时，数据链路层将网络层交下来的IP数据报**组装成帧（framing）**，在两个相邻结点之间的链路上传送**帧（**frame**）**。每一帧包括数据和必要的控制信息（如同步信息、地址信息、差错控制等）。

接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始到哪个比特结束。还使接收端能够检测收到的帧中有无差错，如发现差错就简单地丢弃。

**（4.2）物理层**

传送的数据单位是**比特**。物理层要考虑用多大的电压代表1或0，以及接收方如何识别发送方所发送的比特。物理层还要确定连接电缆的插头应有多少根引脚以及各引脚如何连接。传递信息所利用的物理媒体，如双绞线、同轴电缆、光缆、无线信道等并不在物理层协议内而是其下面。

### 2、TCP和UDP简介

首先应该明确的是这两个协议都是传输层的协议，传输层从通信和信息处理的角度看，**它向上面的应用层提供通信服务**，它属于面向通信部分的最高层，同时也是用户功能中的最底层。当网络边缘的两台主机利用网络的核心功能进行端到端的通信时，只有主机的协议栈才有运输层，而路由器在转发分组时只用到下三层的功能。

根据应用程序的不同需求，传输层需要两种协议，即**面向连接的TCP**和**无连接的UDP**。

#### 2.1 TCP：传输控制协议

**TCP是面向连接的、可靠的字节流的传输层通信协议。**

- **面向连接**：发送端和接收端建立一个连接通道，为了维护连接的可靠性，通过一定的数据结构来维护双方的交互状态。
- **可靠性**：无论网络链路出现了怎样变化，TCP都可以保证一个报文一定到达接收端。
- **字节流**：发送的时候发的是一个流，没头没尾。所以无论消息有多大都可以进行传输，并且消息是[有序的]，通过序列号保证报文的有序性和正确性。

#### 2.2 UDP：用户数据报协议

**UDP是一个面向数据报文的、无连接、不可靠的传输层通信协议。**

* **无连接**：发送数据前不需要建立连接，减小了开销和发送时延。

* **尽最大努力交付：不保证可靠服务，主机不需要维持复杂的连接状态表。

* UDP是**面向数据报文的：**UDP对应用层交下来的报文，既不合并也不拆分，而是保留这些报文的边界。因此应用程序需要选择合适大小的报文，太长（需要分片）太短（首部相对长度太大）都会降低IP等的效率。

**TCP和UDP的区别**

1、**连接**

- TCP是面向连接的传输协议，传输数据前需要建立连接
- UDP不需要建立连接，即刻传输数据

2、**服务对象**

- TCP是一对一的两点服务，即一条连接只有两个端点
- UDP支持一对一、一对多、多对多的交互通信

3、**可靠性**

- TCP是可靠交互数据的，数据可以无差错、不丢失、不重复、按需到达。
- UDP不保证可靠交互数据，可靠性主要依赖于网络环境

4、**拥塞控制，流量控制**

- TCP通过流量控制和拥塞控制，保证数据传输的安全性
- UDP不会去感知传输通道是否阻塞，接收方的接收压力，即使网络拥堵了，也不会自主控制发送速率

5、**首部开销**

- TCP首部比UDP大很多，没有使用[选项]字段时是20字节
- UDP首部长度为8个字节，并且是固定不变的，开销较小

### 3、TCP/UDP/IP报文格式

#### 3.1 IP报文格式

IP报文是在网络层传输的数据单元，也叫IP数据报。IP报文格式如下图

<img src="http://image.easyblog.top/16318632339838d775139-a9b0-49c2-bee9-25fd0cf85cb6.png" style="width:50%;" />

*  **版本**：IP协议的版本，目前的IP协议版本号为4，下一代IP协议版本号为6。
* **首部长度**：IP报头的长度。固定部分的长度（20字节）和可变部分的长度之和。共占4位。最大为1111，即10进制的15，代表IP报头的最大长度可以为15个32bits（4字节），也就是最长可为15*4=60字节，除去固定部分的长度20字节，可变部分的长度最大为40字节。
* **服务类型**：字段包括一个3 bit的优先权子字段（现在已被忽略），4 bit的TOS子字段和1 bit未用位，但必须置0。4 bit的TOS分别代表：最小时延、最大吞吐量、最高可靠性和最小费用。 4 bit中只能置其中1 bit。如果所有4 bit均为0，那么就意味着是一般服务。注意：现在大多数的TCP/IP实现都不支持TOS特性。
* **总长度**：IP报文的总长度。它的值是报头的长度和数据部分的长度之和，以字节为单位。
* **标识**：唯一的标识主机发送的每一份数据报。通常每发送一个报文，它的值加 1。当IP报文长度超过传输网络的MTU（最大传输单元）时必须分片，这个标识字段的值被复制到所有数据分片的标识字段中，使得这些分片在达到最终目的地时可以依照标识字段的内容重新组成原先的数据。
* **标志**：共3位。R、DF、MF三位。目前只有后两位有效，DF位：为1表示不分片，为0表示分片。MF：为1表示“更多的片”，为0表示这是最后一片。
* **分段偏移**：本分片在原先数据报文中相对首位的偏移位。（需要再乘以8）
* **生存时间（TTL，time-to-live）**：TTL字段设置了数据报可以经过的路由器的最大数量。TTL的初始值由源主机设置（通常是32或64），每经过一个路由器，TTL减1，当为0时，路由器将该数据报丢弃，并发送ICMP报文通知源主机。
* **协议**：指出IP报文携带的数据使用的是那种协议，以便目的主机的IP层能知道要将数据报上交到哪个进程（不同的协议有专门不同的进程处理）。和端口号类似，此处采用协议号，TCP的协议号为6，UDP的协议号为17。ICMP的协议号为1，IGMP的协议号为2.
* **首部校验和**：计算IP头部的校验和，检查IP报头的完整性。
* **源IP地址**：标识IP数据报的源端设备。
* **目的IP地址**：标识IP数据报的目的地址。

#### 3.2 TCP报文格式

<img src="https://pic3.zhimg.com/80/v2-3a375a2372db9d0df5191e8e48781cb2_720w.jpg" style="width:50%;" />

* **源端口和目的端口**：各自占用2字节，16位，可以表示的最大端口号是2^16=65535，这两个值加上IP首部中的源端IP地址和目的端IP地址唯一确定一个TCP连接。有时一个IP地址和一个端口号也称为socket（插口） 
* **序列号seq**：占4字节，序号范围是0~2^32-1，用来标记数据段的顺序：TCP把连接中发送的所有数据字节都编上一个序号，第一个字节数据的编号由本地随机产生，此后逐字节编号+1，序列号seq中保存的就是这个报文段中的第一个字节的数据编号。
* **确认应答号ack**：占4字节，序号范围是0~2^32-1，表示期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。
* **标志位**，共6个：ACK、SYN、FIN、URG、PSH、RST。重点了解前3个标志
  * **ACK**：占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效。TCP规定，在连接建立后所有的传送的报文段都必须把ACK置1。
  * **SYN**：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。
  * **FIN**：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放连接
  * URG：当URG=1时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送（相当于高优先级的数据），而不要按原来的排队顺序来传送。
  * PSH：当PSH=1时，接收方应该尽快将本报文段立即传送给其应用层。
  * RST：当RST=1时，表示出现连接错误，必须释放连接，然后再重建传输连接。复位比特还用来拒绝一个不法的报文段或拒绝打开一个连接；
* **窗口**：窗口值是【0，65535】之间的整数。窗口指的是发送本报文段的一方的接收窗口（而不是自己的发送窗口）。窗口值告诉对方： 从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。之所以要有这个限制，是因为收发数据双方的数据处理能力不一样，接搜房收到数据来不及处理时会存储到缓存中，而接收方的数据缓存空间是有限的。因此，窗口值作为接收方让发送方设置其发送窗口的依据（发送数据多少的依据）。并且窗口值是经常在动态变化着。
* **校验和**：检验和覆盖了整个TCP报文段：TCP首部和数据。这是一个强制性的字段，一定是由发端计算和存储，并由收端进行验证。
* **紧急指针**：只有当URG=1时紧急指针才有效。它指出本报文段中的紧急数据的字节数（紧急数据结束后就是普通数据）。
* **选项**：长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。

#### 3.3 UDP报文格式

UDP头部固定为64个字节，具体格式如下图：

<img src="https://pic4.zhimg.com/80/v2-5641cc6cd06186b33d7288e6e99709ff_720w.jpg" style="width:40%;" />

- **目标端口和源端口**：标识报文发送进程和接收进程，需要注意的是，**TCP的端口号和UDP的端口号值相互独立的**。
- **包长度**：标识了头部和数据的总长度
- **校验和**：校验报文的有效性，为保证可靠性而设计

### 4、三次握手、四次挥手

#### 4.1 TCP三次握手

<img src="https://pic4.zhimg.com/80/v2-a4aacd50cf732f894c94f1141c8ce987_720w.jpg" style="zoom:50%;" />

刚开始时，客户端和服务端都处于closed状态，先是服务端主动去监听某个端口，进入listen状态，等待客户端的连接

**1）请求端（通常是客户端）随机生成一个初始序列号client_isn，将该值放置于TCP首部的[序列号]字段，同时把SYN标志位改为1，表示SYN报文。接着把报文发送给服务端，表示向服务端发起连接请求，该报文不包含应用层数据，之后客户端处于SYN-SENT状态**。

**2）服务端收到来自客户端的SYN请求之后，同样也随机生成一个初始序列号server_isn并放置到[序列号]字段中，然后再把收到的SYN请求包的序号字段client_isn+1并将其放置在[确认应答号]中，接着把SYN和ACK标志改为1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于SYN-RCVD状态**。

**3）客户端收到服务端的响应报文段后，还要向服务端回应最后一个应答报文，把报文的首部ACK标志置为1，[应答序列号]字段填入server_isn+1，把报文发送给服务端。这次报文可以携带客户端发给服务端的数据，之后客户端进入established状态**。



#### 4.2 TCP四次挥手

<img src="http://image.easyblog.top/163186661640631692471-e150-4f70-a710-6975c6759d0d.png" style="width:55%;" />

**1）客户端主动关闭连接，向服务端发送一个FIN报文段，之后客户端进入FIN-WAIT-1的状态**。

**2）服务端接收到该FIN报文段后，向客户端返回一个ACK报文，并且进入CLOSE-WAIT状态**。

**3）服务器段收到客户端的ACK答复后，进入FIN_WAIT2状态。此后服务器任然可以向客户端发送数据，但客户端却只能接受数据了**。

**4）等服务端也把完数据发送完毕之后，主动给客户端发送一个FIN报文，之后服务端进入LAST_ACK状态**。

**5）客户端收到FIN报文后，回一个ACK应答报文，之后进入 2MSL 时间长度的 TIME_WAIT状态**。

**6）服务端收到ACK应答报文之后，进入CLOSED状态**。

**7）客户端在TIME_WAIT状态等待2MSL时间之后，自动进入CLOSED状态**。



#### 4.3 TCP三次握手&四次挥手的一些其他拓展问题

**（1）建立连接为什么需要三次握手？两次或四次不行吗？**

先说明为什么不能两次？

TCP有一个超时重传机制，如果客户端发出SYN包之后，由于网络原因，服务器没能立即响应SYN+ACK包，那么client会再次发起syn包， 这一点， 已经有过多次实验验证。

如果第二次SYN包正常达到且与server端建立了TCP连接， server端维护了一个连接， 一次貌似OK, 但别忘了， 第一次那个syn包可能就在此时达到server端了， 于是server端又要维护一个连接， 而这个连接是无效的， 可以认为是死连接。 而一个进程打开的socket是有限度的， 维护这些死连接非常耗费资源。

所以， **二次握手， 服务端有较大隐患， 容易因为建立过多无效连接将服务器的资源耗尽而崩溃**。

而三次握手既可以解决这个问题，经过三次握手客户端和服务器双方都可以确认对方具有收发数据的能力，从而不会存在无效连接。

为什么不采用四次、五次或更多次？

这个问题就更简单了，三次握手就可以确认客户端和服务器双方都可以确认对方具有收发数据的能力了，再增加握手， 并不能显著提高可靠性， 而且也没有必要。

**（2）为什么建立连接是三次握手，但是关闭连接需要四次挥手？**

因为在建立连接的时候，当客户端向服务器发送SYN数据包，请求建立连接被服务器接收到之后，服务器可以立即发送SYN+ACK报文同意并证明自己可以正常收发数据了（SYN用于同步，ACK用于确认应答，表示同意建立连接）。但是当关闭连接的时候，当客户端向服务器发送FIN报文之后，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，"你发的FIN报文我收到了"。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

说的通俗点就是：一方发送FIN只表示自己发完了数据，但是对方有可能还需要发送数据，此时另一方就不能立即回应FIN，而是需要等到把数据发完了再回应FIN。建立连接的过程不存在这些问题，只要可以正常收到数据包并作出正确回应，就可以立即建立连接。

**（3）在关闭阶段，为什么客户端要经历一个2MSL的TIME-WAIT阶段？**

虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是当网络不可靠的时候，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。

具体的工作原理就是：

客户端会在发送出ACK之后进入到TIME_WAIT状态。客户端会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么客户端会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个报文片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，客户端都没有再次收到FIN，那么客户端推断ACK已经被成功接收，则结束TCP连接。

**（4）如果已经建立了连接，但是客户端突然出现故障了怎么办？**

TCP设值有一个**保活计时器**（显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源）。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75s发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

### 5、TCP粘包概念及解决

#### 5.1 TCP粘包的概念

TCP是面向字节流传输数据的，因此发送的时候发的是一个流，数据没有头尾之分，这正是导致TCP粘包的重要原因：**发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾**，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

**（1）发送方原因**

TCP默认会使用**Nagle算法**（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

1. 上一个分组得到确认，才会发送下一个分组
2. 收集多个小分组，在一个确认到来时一起发送

Nagle算法造成了发送方可能会出现粘包问题

**（2）接收方原因**

TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

#### 5.2 如何处理粘包现象？

（1）发送方

对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

（3）应用层

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成，但是如何判断每条数据的长度呢？

1. 格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。
2. 发送长度：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。

####  5.3 UDP会不会产生粘包问题呢？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。


### 6、TCP 流量控制

#### 6.1 滑动窗口

TCP的两端都有发送/接收缓存和发送/接收窗口。TCP的缓存是一个循环队列，其中发送窗口可以用3个指针表示。而发送窗口的大小受TCP数据报中窗口大小的影响，TCP数据报中的窗口大小是接收端通知发送端其还可以接收多少数据，所以发送窗口根据接收的的窗口大小的值动态变化。

以下的几张图片帮助大家理解一下滑动窗口的机制：

<center><img src="http://image.easyblog.top/16318728237290f5881d4-6445-424c-973d-c9337646df67.png" style="width:100%;" /><br/>图 6.1 根据B给出的值，A构造出自己的发送窗口</center>

<center><img src="http://image.easyblog.top/16318755949584fd73b52-d675-46e4-9642-3bbeb080c319.png" style="width:100%;" /><br/>图 2 A 发送了11字节数据</center>

注意上图中的3个指针P1、P2、P3！此时接收窗口中接收的数据可能是失序的，但是也先存储在接收缓存之中。发送确认号的时候依然发送31，表示B期望接收的下一个数据报的首字节序列号是31。

<center><img src="http://image.easyblog.top/163187721111164b8a3b5-3d3b-4cab-a5d3-fcb674a4dd94.png" style="width:100%;" /><br/>图 3 A收到新的确认号，发送窗口向前滑动</center>

当B收到31后连同之前接收到的数据报，发送确认号34，此时A的滑动窗口可以向前移动了。

![](http://image.easyblog.top/16318777602581d199072-f273-4d28-be0b-ec270e028808.png)

如果发送窗口中的数据报都属于已发送但未被确认的话，那么A就不能再继续发送数据，而需要进行等待。



###  7、TCP 拥塞控制

窗口控制解决了两台主机之间因传送速率而可能引起的丢包问题，在一定程度上保证了TCP数据传送的可靠性。然而如果网络非常拥堵，此时再发送数据就会加重网络负担，那么发送的数据段很可能超过了最大生存时间也没有到达接收方，就会产生丢包问题。为此TCP引入慢启动机制，先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多大的速度传送数据。



####  7.1 慢开始和拥塞避免

**（1）拥塞窗口**

此处引入拥塞窗口的概念，定义如下：

发送开始时定义拥塞窗口大小为1；每次收到一个ACK应答，拥塞窗口加1；而在每次发送数据时，发送窗口取拥塞窗口与接送段接收窗口最小者。

**（2）慢开始**

慢开始的算法思路是：发送窗口先设置cwnd = 1，发送第一个报文段，以后每收到一个报文段确认，拥塞窗口cwnd就加倍（即呈指数增长），当cwnd大于ssthresh阀值时，改用拥塞避免算法(加法增大)
假设增长到某个值（比如 24）网络出现超时，此时将ssthresh值变为值的一半(比如 12)(乘法减小)，然后将cwnd置1，重新采用慢开始算法，重复如上步骤。

**（3）拥塞避免**

拥塞避免算法的思路是：当拥塞窗口cwnd的值带到设定阈值ssthresh后，让拥塞窗口cwnd由之前的指数级增长变化到线性缓慢增长

<img src="https://img-blog.csdn.net/20150419112344942" style="zoom:70%;" />

#### 7.2 快重传和快恢复

快重传的算法思路是：要求接收方每收到一个时序的报文段后就立即发出重复确认，而不是等待发送数据时才进行捎带确认
发送方只要一连收到三个重复确认，就应当立即重传对方尚未收到的报文段，而不必等待设置的重传计时器到期

快恢复的算法思路是：当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始阀值ssthresh减半
接着不执行慢开始，而是从新阀值ssthresh开始执行拥塞避免算法(加法增大)

<img src="https://img-blog.csdn.net/20150419131338193" style="zoom:67%;" />

这样一来，也就是说rwnd和cwnd中较小的一个控制发送方发送数据的速率，**发送窗口的值 = Min[rwnd， cwnd]**



### 8、TCP的可靠性传输是如何保证的

* **最大消息长度**：在建立TCP连接的时候，双方约定一个最大的长度MSS作为方消息的基本单位，重传的时候也是一这个单位进行重传。
* **超时重传**：当TCP发出一个报文段之后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发此报文段。
* **序列号/确认应答**：当TCP收到发送TCP连接另一端的数据，他将发送一个确认。这个确认不是立即发送，通常会推迟几分之一秒。
* **校验和**：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。
* **滑动窗口机制**：滑动窗口解决了超时重传机制在实际应用中效率过于低下的问题。窗口的大小就是在无需等待确认包的情况下，发送端还能发送的最大数据量。这个机制的实现就是使用了大量的缓冲区，通过对多个数据段进行确认应答的功能。通过下一次的确认包可以判断接收端是否已经接收到了数据，如果已经接收了就从缓冲区里面删除数据。
* **拥塞控制机制**：解决了拥堵网络环境下数据传输可靠性问题。

### 8、ARQ协议和连续ARQ协议的概念

自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中[数据链路层](https://baike.baidu.com/item/数据链路层/4329290)的错误纠正协议之一。它包括停止等待、ARQ协议和连续ARQ协议，错误侦测（Error Detection）、正面确认（Positive Acknowledgment）、超时重传（Retransmission after Timeout）与负面确认继以重传（Negative Acknowledgment and Retransmission）等机制。

#### 8.1 ARQ协议

停止等待协议是为了实现可靠传输而出现的，它每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；

* 优点： **简单**

* 缺点： **信道利用率低，等待时间长**

1) 无差错情况：发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

2) 出现差错情况（超时重传）：停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 自动重传请求 ARQ 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续 ARQ 协议 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

3) 确认丢失和确认迟到

- 确认丢失 ：确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。
- 确认迟到 ：确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。



#### 8.2 连续ARQ协议

连续 ARQ 协议是为了提高信道利用率而提出的。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。一般TCP都会使用连续ARQ协议而不是ARQ协议。

优点： **信道利用率高，容易实现，即使确认丢失，也不必重传。**

缺点： **不能向发送方反映出接收方已经正确收到的所有分组的信息。**比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。



### 9、DNS解析过程

DNS查找过程如下：

1. **浏览器缓存** – 浏览器会缓存DNS记录一段时间。 如果操作系统没有告诉浏览器储存DNS记录的时间，这样不同浏览器会储存个自固定的一个时间（2分钟到30分钟不等）。

2. **系统缓存** – 如果在浏览器缓存里没有找到需要的记录，浏览器会做一个系统调用（windows里是gethostbyname），主要去查找了**系统中的hosts文件**。这样便可获得系统缓存中的记录。
3. **路由器缓存** – 接着，前面的查询请求发向路由器，查看路由器映射表，它一般会有自己的DNS缓存。
4. **本地DNS服务器** – 接下来要检查的就是ISP缓存DNS的服务器。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。这里一般都能找到相应的缓存记录。请求到达DNS服务器后,DNS服务器首先会查询他的缓存记录,如果有对应的ip地址,则返回,如果没有,本地DNS服务器向DNS根服务器发送查询请求.
5. 根服务器不会记录具体的域名和ip的对应关系,而是返回域服务器的地址.

6. 本地服务器会继续向域服务器发起请求.域服务器也没有记录域名和ip的对应关系,而是返回你的**域名的解析服务器的地址**.

7. 本地DNS服务器继续向域名解析服务器发出请求,这时会**收到域名对应的ip,**本地DNS服务器将ip返回给浏览器,并将ip存入缓存,方便下次访问,加快访问速度.

<img src="https://pic3.zhimg.com/80/v2-994cbf48c15784eafd254ce67449bd42_720w.jpg" style="zoom:80%;" />

### 10、从浏览器中输入URL到展现出页面中间发生了什么？

在地址栏中输入网址，回车之后将会发生如下事件：

**（1）首先是域名解析(DNS解析)**

**（2）浏览器与服务器建立TCP链接**：在拿到ip地址后,浏览器会向对应的web服务器(Nginx,Apache...)发起TCP连接请求,通过三次握手,建立TCP连接.

**（3）浏览器向服务器发送Http请求**：建立TCP连接后,浏览器向web服务器发送Http请求。HTTP请求报文格式：**请求行+请求头+空行+消息体**，请求行包括请求方式（GET/POST/DELETE/PUT）、请求资源路径（URL）、HTTP版本号；

**（4）服务器处理并响应Http请求**：HTTP响应报文格式：**状态行+响应头+空行+消息体，状态行包括HTTP版本号、状态码、状态说明**。

**（5）关闭TCP连接**：在这次数据传输完成后,为了避免服务器与客户端双方的资源占用和损耗,会经过四次挥手,关闭TCP连接.

**（6）浏览器解析资源并渲染显示**：后通过DOM树和CSS规则树生成渲染树。生成渲染树后,浏览器根据渲染树布局页面,同时计算css样式或js对Dom的动态样式改变,然后绘制出页面.

<img src="https://pic2.zhimg.com/80/v2-ebd3332361b2204683cd0dda9570c015_720w.jpg" style="zoom:67%;" />



### 11、GET和POST的区别？

1. GET请求的URL长度是有限制的（不同的浏览器和服务器限制不同），但是POST请求没有限制；

2. GET请求比POST请求更安全，因为GET请求的参数就在URL中，当时POST请求的请求参数在请求体中；

3. 对参数的数据类型，GET只接受ASCII字符，而POST没有限制；

4. GET请求参数会被完整保留在浏览器历史记录里；相反，POST请求参数不会被浏览器保留；

5. GET请求只能进行url编码（application/x-www-form-urlencoded），而POST支持多种编码方式；

6. GET请求会被浏览器主动缓存，而POST不会，除非手动设置；

7. GET在浏览器回退时是无害的，而POST会再次提交请求。

8. GET产生一个TCP数据包；POST产生两个TCP数据包。

   具体说就是：

   > 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；
   >
   > 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。



### 12、cookie和session的关系和区别

http请求是无状态的,即每次服务端接收到客户端的请求时，都是一个全新的请求，服务器并不知道客户端的历史请求记录。比如当用户从客户端请求一次登录后，登录成功，再次进行请求时，因为tomcat不能识别这两次会话都是来自同一个浏览器，即服务端不知道客户端的历史请求记录；就会再次弹出登录对话框。

为了解决这个问题，就出现了**会话跟踪技术，在服务端就是session，在客户端就是cookie**

##### cookie是什么

一个HTTP cookie的（网络Cookie，浏览器cookie）是一小片数据的一个服务器发送到用户的网络浏览器。浏览器可以存储它并将其与下一个请求一起发送回同一服务器。通常，它用于判断两个请求是否来自同一个浏览器 - 例如，保持用户登录。它记住[无状态](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview#HTTP_is_stateless_but_not_sessionless) HTTP协议的有状态信息。

##### Session是什么

客户端请求服务端，服务端（Tomcat）会为这次请求开辟一块内存空间，这个对象便是Session对象， 存储结构为ConcurrentHashMap。

session的目的：弥补HTTP无状态特性，服务器可以利用session存储客户端在同一个会话期间的一些操作记录。

##### session的实现机制

**（1）服务器如何判断客户端发送过来的请求属于同一个会话？**

用sessionId区分；sessionId 相同即认为是同一个会话；在tomcat中session id中用JSESSIONID来表示；

**（2）服务器、客户端如何获取sessionID?SessionID在期间是如何传输的？**

服务器第一次接收到请求时，开辟了一块Session空间（创建了Session对象），同时生成一个Session id，并通过响应头的Set-Cookie：“JSESSIONID=XXXXXXX”命令，向客户端发送要求设置cookie的响应； 客户端收到响应后，在本机客户端设置了一个JSESSIONID=XXXXXXX的cookie信息，该cookie的过期时间为浏览器会话结束；

接下来客户端每次向同一个网站发送请求时，请求头都会带上该cookie信息（包含Session id）； 然后，服务器通过读取请求头中的Cookie信息，获取名称为JSESSIONID的值，得到此次请求的Session id；

> **注意**：服务器只会在客户端第一次请求响应的时候，在响应头上添加Set-Cookie：“JSESSIONID=XXXXXXX”信息，接下来在同一个会话的第二第三次响应头里，是不会添加Set- Cookie：“JSESSIONID=XXXXXXX”信息的； 而客户端是会在每次请求头的cookie中带上JSESSIONID信息；



##### Cookie和Session的区别

（1）**数据存储位置**不同：cookie数据存放在**客户的浏览器**上，session数据放在**服务器**上。

（2）**安全性**：cookie**不是很安全**，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session。

（3）**对服务器性能的影响**：session会在一定时间内保存在服务器上。当访问增多，会比较占用服务器的性能

（4）**数据大小限制**：单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。



### 13、HTTP1.0、1.1、2.0之间的区别？

* http1.0支持的是短连接，相当于客户端每次发起的请求都需要进行tcp三次握手，特别消耗资源
* http1.1支持了长连接，客户端发起http请求的时候，通过tcp三次握手建立连接之后，后续的每次请求都不需要再次进行三次握手，除非过了设置的超时时间，虽然不需要再次进行三次握手，但是客户端的每次请求都只能按顺序接收处理，而不能同时将多个请求一次性发送服务器端并且同时响应返回给客户端接收。虽然有一个管道化的理论去解决这个问题，但是依旧只是处于理论的阶段，没有实际应用。
* http2基于http1.1的基础之上，支持将多个请求封装为一个请求，同时请求服务器，响应返回给客户端，http2在不改变原有传输的基础上，在传输层和应用层之间加入了一层逻辑层，这个逻辑层应用的是spd的原理，能够将请求实现封装一起传输。

##### 14、Http和Https的区别？

http协议和https协议的区别：传输信息安全性不同、连接方式不同、端口不同、证书申请方式不同

**一、传输信息安全性shu不同**

1、http协议：是超文本传输协议，信息是明文传输。如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息。

2、https协议：是具有安全性的ssl加密传输协议，为浏览器和服务器之间的通信加密，确保数据传输的安全。

<img src="https://iknow-pic.cdn.bcebos.com/d01373f082025aaf65da6a13f5edab64024f1a79?x-bce-process=image/resize,m_lfit,w_600,h_800,limit_1" style="zoom:67%;" />

**二、连接方式不同**

1、http协议：http的连接很简单，是无状态的。

2、https协议：是由SSL＋HTTP协议构建的可进行加密传输、身份认证的网络协议。

**三、端口不同**

1、http协议：使用的端口是80。

2、https协议：使用的端口是443．

**四、证书申请方式不同**

1、http协议：免费申请。

2、https协议：需要到ca申请证书，一般免费证书很少，需要交费。

### 15、HTTP常见状态码

> 200 （OK）：服务器成功处理了请求。
>
> 204（NOT Content）：服务器成功处理了请求，但没有返回任何内容
>
> 301（Moved Permanently）：永久性重定向。表示请求的资源已被分配了新的 URI。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置
>
> 302（Found）：临时性重定向。表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。和 301 Moved Permanently 状态码相似，但 302 Found 状态码代表资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URI 将来还有可能发生改变。
>
> 304（Not Modified）：表示客户端发送附带条件的请求时，服务器端允许请求访问的资源，但未满足条件的情况。
>
> 400（Bad Request）：表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。
>
> 401（Unauthorized）：请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。
>
> 403（Forbidden）：服务器拒绝请求
>
> 404（Not Found）：表明服务器上无法找到请求的资源。
>
> 405（Method Not Allowed ）：请求的资源不支持请求使用的方法
>
> 414 （Request-URI Too Large）：请求参数参数过长
>
> 500（Internal Server Error）：服务器内部错误，服务器在处理请求的时候出现错误。
>
> 501（Not Implemented） ：服务器不认识或不支持的请求使用的方法
>
> 502（Bad Gateway）：错误网关
>
> 503（Service Unavailable）：服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。
>
> 504（Gateway Timeout）：网关超时，由作为代理或网关的服务器使用，表示不能及时地从远程服务器获得应答。
>
> 505（HTTP Version Not Supported）：服务器不支持请求中所指明的HTTP版本。

### 16、Http请求报文&Http响应报文

客户端发送一个HTTP请求到服务器的请求消息包括以下格式：**请求行（request line）、请求头（request header）、空行（\r\n）和请求数据**。

![img](http://image.easyblog.top/1594992803918816c142b-0d07-47a0-8d52-e1c906104525.png)

HTTP响应数据也有4个部分：**状态行、消息头部、空行(\r\n)和响应正文**。

<img src="http://image.easyblog.top/15949935258818d62fa64-0525-40d0-bea6-10794f11ff3d.jpg" alt="img" style="zoom:80%;" />

### 17、Http缓存

浏览器缓存分为**强缓存和协商缓存**，浏览器加载一个页面的简单流程如下：

1. 浏览器先根据这个资源的http头信息来判断是否命中强缓存。如果命中则直接加在缓存中的资源，并不会将请求发送到服务器。
2. 如果未命中强缓存，则浏览器会将资源加载请求发送到服务器。服务器来判断浏览器本地缓存是否失效。若可以使用，则服务器并不会返回资源信息，浏览器继续从缓存加载资源。
3. 如果未命中协商缓存，则服务器会将完整的资源返回给浏览器，浏览器加载新资源，并更新缓存。

#### **17.1 强缓存**

命中强缓存时，浏览器并不会将请求发送给服务器。在Chrome的开发者工具中看到http的返回码是200，但是在Size列会显示为(from cache)。
![img](https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141536107-329179455.png)

强缓存是利用http的返回头中的Expires或者Cache-Control两个字段来控制的，用来表示资源的缓存时间。

**Expires**

缓存过期时间，用来指定资源到期的时间，是服务器端的具体的时间点。也就是说，Expires=max-age + 请求时间，需要和Last-modified结合使用。但在上面我们提到过，cache-control的优先级更高。 Expires是Web服务器响应消息头字段，在响应http请求时告诉浏览器在过期时间前浏览器可以直接从浏览器缓存取数据，而无需再次请求。

![](https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141609527-358000355.png)

该字段会返回一个时间，比如Expires:Thu,31 Dec 2037 23:59:59 GMT。这个时间代表着这个资源的失效时间，也就是说在2037年12月31日23点59分59秒之前都是有效的，即命中缓存。这种方式有一个明显的缺点，由于失效时间是一个绝对时间，所以当客户端本地时间被修改以后，服务器与客户端时间偏差变大以后，就会导致缓存混乱。于是发展出了Cache-Control。

**Cache-Control**

Cache-Control是一个相对时间，例如Cache-Control:3600，代表着资源的有效期是3600秒。由于是相对时间，并且都是与客户端时间比较，所以服务器与客户端时间偏差也不会导致问题。
Cache-Control与Expires可以在服务端配置同时启用或者启用任意一个，同时启用的时候Cache-Control优先级高。

Cache-Control 可以由多个字段组合而成，主要有以下几个取值：

1. **max-age** 指定一个时间长度，在这个时间段内缓存是有效的，单位是s。例如设置 Cache-Control:max-age=31536000，也就是说缓存有效期为（31536000 / 24 / 60 * 60）天，第一次访问这个资源的时候，服务器端也返回了 Expires 字段，并且过期时间是一年后。

 ![img](https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141638673-1917674992.png)

在没有禁用缓存并且没有超过有效时间的情况下，再次访问这个资源就命中了缓存，不会向服务器请求资源而是直接从浏览器缓存中取。

2. **s-maxage** 同 max-age，覆盖 max-age、Expires，但仅适用于共享缓存，在私有缓存中被忽略。

3. **public** 表明响应可以被任何对象（发送请求的客户端、代理服务器等等）缓存。

4. **private** 表明响应只能被单个用户（可能是操作系统用户、浏览器用户）缓存，是非共享的，不能被代理服务器缓存。

5. **no-cache** 强制所有缓存了该响应的用户，在使用已缓存的数据前，发送带验证器的请求到服务器。不是字面意思上的不缓存。

6. **no-store** 禁止缓存，每次请求都要向服务器重新获取数据。
7. **must-revalidate**指定如果页面是过期的，则去服务器进行获取。这个指令并不常用，就不做过多的讨论了。

#### **17.2 协商缓存**

若未命中强缓存，则浏览器会将请求发送至服务器。服务器根据http头信息中的Last-Modify/If-Modify-Since或Etag/If-None-Match来判断是否命中协商缓存。如果命中，则http返回码为304，浏览器从缓存中加载资源。

**Last-Modify/If-Modify-Since**

浏览器第一次请求一个资源的时候，服务器返回的header中会加上Last-Modify，Last-modify是一个时间标识该资源的最后修改时间，例如Last-Modify: Thu,31 Dec 2037 23:59:59 GM

<img src="https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141852114-1757065670.png" alt="img" style="zoom:67%;" />

当浏览器再次请求该资源时，发送的请求头中会包含If-Modify-Since，该值为缓存之前返回的Last-Modify。服务器收到If-Modify-Since后，根据资源的最后修改时间判断是否命中缓存。

<img src="https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141732879-1484228353.png" alt="img" style="zoom:67%;" />

如果命中缓存，则返回http 304，并且不会返回资源内容，并且不会返回Last-Modify。由于对比的服务端时间，所以客户端与服务端时间差距不会导致问题。但是有时候通过最后修改时间来判断资源是否修改还是不太准确（资源变化了最后修改时间也可以一致）。于是出现了ETag/If-None-Match。

**ETag/If-None-Match**

与Last-Modify/If-Modify-Since不同的是，Etag/If-None-Match返回的是一个校验码（ETag: entity tag）。ETag可以保证每一个资源是唯一的，资源变化都会导致ETag变化*。ETag值的变更则说明资源状态已经被修改。服务器根据浏览器上发送的If-None-Match值来判断是否命中缓存。

<img src="https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141918779-1206116367.png" alt="img" style="zoom:67%;" />





总结浏览器的请求过程：

第一次请求：

<img src="https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141945261-83532090.png" alt="img" style="zoom:67%;" />

浏览器再次请求时：

<img src="https://images2018.cnblogs.com/blog/940884/201804/940884-20180423141951735-912699213.png" alt="img" style="zoom:67%;" />

## 操系系统

##### 1、进程间通信的方式

<img src="http://image.easyblog.top/1600265954165fb34b8bf-fd31-4ad1-8605-f2576b31b249.jpg" alt="img" style="zoom:30%;" />

* **管道( pipe )**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
* **有名管道 (namedpipe)** ：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
* **信号量(semophore )** ：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
* **消息队列( messagequeue )** ：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
* **信号 (sinal )** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
* **共享内存(shared memory )** ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
* **套接字(socket )** ：套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。

##### 2、进程和线程的区别？

**进程**是资源（CPU、内存等）分配的基本单位，是具有一定功能的程序关于某个数据集合上的一次运行活动，是系统进行**资源分配的基本单位**。

**线程**是进程内的一个实体，是**独立运行和独立调度**的基本单位（CPU上真正运行的是线程），一个进程内至少有一个线程。线程自己基本上不拥有系统资源，但是它可与同属一个进程的其他的线程**共享进程所拥有的全部资源**。

总结就是： **进程是分配资源的基本单位，线程是执行的基本单位**。

##### 3、进程在自己的虚拟地址空间中都有什么？



##### 4、什么是僵尸进程？孤儿进程？

**孤儿进程：** 父进程退出，子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。

**僵尸进程：** 进程使用fork 创建子进程，如果子进程退出，而父进程并没有调用wait 或 waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。

**避免僵尸进程的方法：**

* fork 两次用孙子进程去完成子进程的任务
* 用wait()函数使父进程阻塞
* 使用信号量，在signal handler 中调用waitpid,这样父进程不用阻塞

##### 5、线程同步的实现方式（操作系统级别的）

- 锁机制：包括互斥锁、条件变量、读写锁
	互斥锁提供了以排他方式防止数据结构被并发修改的方法。
	读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
	条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

##### 6、进程调度算法

调度算法是指：根据系统的资源分配策略所规定的资源分配算法。常见的进程调度算法有：

*  **先来先去服务**：先来先去服务调度算法是一种最简单的调度算法，也称为先进先出或严格排队方案。当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。该算法既可以用于作业调度，也可以用于进程调度。先来先去服务比较适合于常作业（进程），而不利于段作业（进程）。

*  **时间片轮转法**：轮转法是基于适中的抢占策略的，以一个周期性间隔产生时钟中断，当中断发生后，当前正在运行的进程被置于就绪队列中，然后基于先来先去服务策略选择下一个就绪作业的运行。这种技术也称为时间片，因为每个进程再被抢占之前都给定一片时间。

*  **最短进程优先**：最短进程优先是一个非抢占策略，他的原则是下一次选择预计处理时间最短的进程，因此短进程将会越过长作业，跳至队列头。该算法即可用于作业调度，也可用于进程调度。但是他对长作业不利，不能保证紧迫性作业（进程）被及时处理，作业的长短只是被估算出来的。

*  **最短剩余时间优先**：最短剩余时间是针对最短进程优先增加了抢占机制的版本。在这种情况下，进程调度总是选择预期剩余时间最短的进程。当一个进程加入到就绪队列时，他可能比当前运行的进程具有更短的剩余时间，因此只要新进程就绪，调度程序就能可能抢占当前正在运行的进程。像最短进程优先一样，调度程序正在执行选择函数是必须有关于处理时间的估计，并且存在长进程饥饿的危险。

*  **最高响应比优先**：根据比率：R=(w+s)/s （R为响应比，w为等待处理的时间，s为预计的服务时间）

	　　如果该进程被立即调用，则R值等于归一化周转时间（周转时间和服务时间的比率）。R最小值为1.0，只有第一个进入系统的进程才能达到该值。调度规则为：当前进程完成或被阻塞时，选择R值最大的就绪进程，它说明了进程的年龄。当偏向短作业时，长进程由于得不到服务，等待时间不断增加，从而增加比值，最终在竞争中赢了短进程。和最短进程优先、最短剩余时间优先一样，使用最高响应比策略需要估计预计服务时间。

* 多级反馈队列算法【了解】：调度基于被抢占原则（按时间片）并使用动态优先级机制。当一个进程第一次进入系统中时，他被放置在一个优先级队列中，当第一次被抢占后并返回就绪状态时，它被放置在下一个低优先级队列中，在随后的时间里，每当被抢占时，他被降级到下一个低优先级队列中。一个短进程很快被执行完，不会在就绪队列中降很多级，一个长进程会逐渐降级。因此先到的进程和短进程优先于长进程和老进程。在每个队列中，除了优先级在最低的队列中之外，都是用简单的先来先去服务机制，一旦一个进程处于优先级最低的队列中，它就不可能在降级，但会重复的返回该队列，直到运行结束。因此，该队列课按照轮转方式调度。

* 多级反馈队列调度算法【了解】：

	多级反馈队列算法，不必事先知道各种进程所需要执行的时间，他是当前被公认的一种较好的进程调度算法。其实施过程如下：

	　　1)设置多个就绪队列，并为各个队列赋予不同的优先级。在优先权越高的队列中，为每个进程所规定的执行时间片就越小。

	　　2)当一个新进程进入内存后，首先放入第一队列的末尾，按照先来先去原则排队等候调度。如果他能在一个时间片中完成，便可撤离；如果未完成，就转入第二队列的末尾，同样等待调度.....如此下去，当一个长作业（进程）从第一队列依次将到第n队列（最后队列）后，便按第n队列时间片轮转运行。

	　　3)仅当第一队列空闲的时候，调度程序才调度第二队列中的进程运行；仅当第1到（i-1）队列空时，才会调度第i队列中的进程运行，并执行相应的时间片轮转。

	　　4)如果处理机正在处理第i队列中某进程，又有新进程进入优先权较高的队列，则此新队列抢占正在运行的处理机，并把正在运行的进程放在第i队列的队尾。

##### 7、死锁、银行家算法

死锁的概念：所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/10/java9-1603248043.png" alt="面试中常问的 10道操作系统 题目" style="zoom:67%;" />

**死锁产生的四个必要条件**：

- 互斥条件：一个资源每次只能被一个进程使用。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
- 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系



**防止和解决死锁问题**

**死锁的预防**

前面介绍了死锁发生时的四个必要条件，只要破坏这四个必要条件中的任意一个条件，死锁就不会发生。这就为我们解决死锁问题提供了可能。一般地，解决死锁的方法分为死锁的预防，避免，检测与恢复三种（注意：死锁的检测与恢复是一个方法）。我们将在下面分别加以介绍。

死锁的预防是保证系统不进入死锁状态的一种策略。它的基本思想是要求进程申请资源时遵循某种协议，从而打破产生死锁的四个必要条件中的一个或几个，保证系统不会进入死锁状态。

〈1〉打破互斥条件。即允许进程同时访问某些资源。但是，有的资源是不允许被同时访问的，像打印机等等，这是由资源本身的属性所决定的。所以，这种办法并无实用价值。

〈2〉打破不可抢占条件。即允许进程强行从占有者那里夺取某些资源。就是说，当一个进程已占有了某些资源，它又申请新的资源，但不能立即被满足时，它必须释放所占有的全部资源，以后再重新申请。它所释放的资源可以分配给其它进程。这就相当于该进程占有的资源被隐蔽地强占了。这种预防死锁的方法实现起来困难，会降低系统性能。

〈3〉打破占有且申请条件。可以实行资源预先分配策略。即进程在运行前一次性地向系统申请它所需要的全部资源。如果某个进程所需的全部资源得不到满足，则不分配任何资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性地将所申请的资源全部分配给该进程。由于运行的进程已占有了它所需的全部资源，所以不会发生占有资源又申请资源的现象，因此不会发生死锁。但是，这种策略也有如下缺点：

*    (1）在许多情况下，一个进程在执行之前不可能知道它所需要的全部资源。这是由于进程在执行时是动态的，不可预测的；
* （2）资源利用率低。无论所分资源何时用到，一个进程只有在占有所需的全部资源后才能执行。即使有些资源最后才被该进程用到一次，但该进程在生存期间却一直占有它们，造成长期占着不用的状况。这显然是一种极大的资源浪费；
* （3）降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数就必然少了。

〈4〉打破循环等待条件，实行资源有序分配策略。采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。这种策略与前面的策略相比，资源的利用率和系统吞吐量都有很大提高

##### 死锁的避免

**银行家算法**
        银行家算法（Banker’s Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。
　　在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。
　　银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。



**银行家算法的核心思想一句话总结**：当一个进程申请使用资源的时候，银行家算法通过先 **试探** 分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

<img src="https://img-blog.csdn.net/20180508204335770?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDE0Mjcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="è¿éåå¾çæè¿°" style="zoom:60%;" />

- 首先是银行家算法中的**进程**：包含进程Pi的需求资源数量（也是最大需求资源数量，MAX）；已分配给该进程的资源A（Allocation）；还需要的资源数量N（Need=M-A）
- Available为空闲资源数量，即资源池（注意：资源池的剩余资源数量+已分配给所有进程的资源数量=系统中的资源总量）

假设进程P1申请资源，银行家算法先**试探**的分配给它（当然先要看看当前资源池中的资源数量够不够），若申请的资源数量小于等于Available，然后接着判断分配给P1后剩余的资源，能不能使进程队列的某个进程执行完毕，若没有进程可执行完毕，则系统处于不安全状态（即此时没有一个进程能够完成并释放资源，随时间推移，系统终将处于死锁状态）。

若有进程可执行完毕，则假设回收已分配给它的资源（剩余资源数量增加），把这个进程标记为可完成，并继续判断队列中的其它进程，**若所有进程都可执行完毕，则系统处于安全状态，并根据可完成进程的分配顺序生成安全序列**（如{P0，P3，P2，P1}表示将申请后的剩余资源Work先分配给P0–>回收（Work+已分配给P0的A0=Work）–>分配给P3–>回收（Work+A3=Work）–>分配给P2–>······满足所有进程）。

如此就可避免系统存在潜在死锁的风险。

##### 死锁的检测与恢复

一般来说，由于操作系统有并发，共享以及随机性等特点，通过预防和避免的手段达到排除死锁的目的是很困难的。这需要较大的系统开销，而且不能充分利用资源。为此，一种简便的方法是系统为进程分配资源时，不采取任何限制性措施，但是提供了检测和解脱死锁的手段：能发现死锁并从死锁状态中恢复出来。因此，在实际的操作系统中往往采用死锁的检测与恢复方法来排除死锁。

死锁检测与恢复是指系统设有专门的机构，当死锁发生时，该机构能够检测到死锁发生的位置和原因，并能通过外力破坏死锁发生的必要条件，从而使得并发进程从死锁状态中恢复出来。

##### 8、虚拟内存

<img src="https://images2017.cnblogs.com/blog/918357/201711/918357-20171108185346513-1960234959.png" alt="一个使用虚拟寻址的系统_11.png-178.6kB" style="zoom:50%;" />

CPU 通过一个**虚拟地址（virtual address,VA）**来访问主存，这个虚拟地址在被送到主存之前会先转换成一个物理地址。将虚拟地址转换成物理地址的任务叫做**地址翻译（address translation）**。

地址翻译需要 CPU 硬件和操作系统之间的配合。 CPU 芯片上叫做**内存管理单元（Menory Management Unit, MMU）**的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。



**虚拟内存将主存看成是一个磁盘的高速缓存，主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。**

##### 9、常见的几种内存管理机制

简单的分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，比如**块式管理**。非连续分配管理方式允许一个程序内存分散，比如**页式管理、段式管理和段页式管理。**

**（1）块式管理：**远古时代的计算机操作系统的内存管理方式，将内存分为几个固定大小的块，每个块只包含一个进程，如果程序运行需要内存，操作系统就给它分配一块，如果程序运行只需要很小的空间，则分配的这块内存很大一部分就浪费了，这些在每个块中未被利用的空间，我们称为碎片。

**（2）页式管理：**把主存分为大小相等且固定的一页一页的形式，页比较小，相对于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。

**（3）段式管理：**页式管理虽然提高了内存利用率，但是其中的页没有任何实际意义，段式管理把主存分为一段一段 ，每一段的空间又比一页的空间小很多。但是段有实际意义，段式管理通过段表对应逻辑地址和物理地址。

**（4）段页式管理：**段页式管理机制结合了段式管理和页式管理的优点，就是把主存分为若干段，每个段又分为若干页，也就是说段页式管理机制中段和段之间以及段的内部都是离散的。

##### 10、快表和多级页表

 **单级页表的缺点**

为了提高内存的利用率，内存是分页管理的，并且有一个页表用来存储页号与页框的对应关系。这个思想理论上是没有问题的，但是实际使用的时候就不行了，为什么？

为了更好的提高内存的利用率，每一页就应该做得足够小，但是每一页都要在页表里面有一项与页框对应，也就是说页数越多页表也就会越大，页表如果很大的话就会对内存造成浪费，因为存放页表的这部分你内存是不能给程序使用的，并且一直存放在该进程的PCB里面。那么究竟会造成多大的浪费？假设页面尺寸为4K，地址是32位，那么就有220个页面，页表里面就有220个页表项，如果每个页表项是4个字节，2^20个就是4M；系统并发十个进程，需要40M内存。如果并发一百个就是400M内存，这无疑是一个很大的开销。

但是实际上大部分的逻辑地址根本不会用到。为什么？如果你跑一个小程序，可能只需要几M或者几十M，也就是说页表里面用到的项只占2^20的很小一部分，那么能不能把不需要的那些项给屏蔽掉呢，也就是不存储那些项。

**多级页表的提出**

**第一种尝试：页表里面只存放用到的页**

比如一个程序用到了第1，3，5，6页，那么页表里面只需要存储这四页对应的页框号，但是这样的话页表里面的项就不连续了，这样找某一页对应的页框就不能直接使用偏移量的形式了。比较好的方法是折半查找（因为页号是有顺序的）。但是即便使用折半查找耗费的时间也会比使用偏移量大很多倍。比如如果一个表项有210个，时间复杂度log(210)=10,也就是需要10次，而如果使用偏移量就只需要一次就好了。所以页表里面的页号必须是连续的。

 **第二种尝试：多级页表，页目录表+页表**

一个逻辑地址用10bits的页目录号+10bits的页号+12bits的偏移组成。页目录表的每一项对应一个页表，然后再根据页表找到对应的页。这种思想就类似与书本，目录的地方有一个章目录（页目录表）和节目录（页表），如果要查找某一节的内容首先找到这一章的地方，然后再查具体的某一节。我如果要找第五章的第4节，那么前面四章都不用看，直接找第五章就行了，这样除了第五章之外的页号对应的页框号的就不用存了。能节省大量内存；并且保证了章目录和节目录都是连续的，这就意味着可以使用偏移量的形式查找对应的章节。如下图：

<img src="https://img-blog.csdn.net/20181021115815384?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dpbGxpYW1nYXZpbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="å¨è¿éæå¥å¾çæè¿°" style="zoom:67%;" />

**多级页表的缺点**

但是这种方式也存在一个问题，每一次访问的时候都要根据章目录找到页目录再找到具体的页。也就是需要访问三次内存；cpu每一条指令执行的时间其实大部分都是浪费在访问内存上，cpu的执行速度是非常快的，比如访问内存的时间几乎可以忽略了；换言之，两级页表的形式虽然提高了控件效率，但是在时间上其实是变成了原来的3倍的；这还只是两级页表，如果是4级或者5级的，因为电脑不是32位的啊，现在基本上都是64位的了。



 **相连快速存储TLB（快表）**

在CPU与内存访问之间加一层TLB，TLB是一组寄存器，用来存放最近使用过的页对应的页框号；这样如果CPU需要访问某一页首先在TLB里面找，如果TLB里面有就不用访问内存了，因为TLB是寄存器，cpu访问寄存器的速度远大于对内存的访问速度。这样就可以提升时间性能了。可以看到提升时间性能最主要的因素就是可以在TLB里面直接找到该页对应的页框号。那么如何提升命中率的，首先TLB肯定是越大越好，但是TLB材料很贵，不会做得很大。TLB的大小大概是[64,1024]。为什么TLB里面存放这么少的项就能实现“近似访存1次”？**因为程序的局部性原理**。程序的局部性原理在用户程序里面对应的就是循环。TLB也被称为快表。

总结一下：为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即TLB）的概念，快表利用的是程序的局部性原理。

##### 11、页面置换算法

-  **FIFO先进先出算法**：在操作系统中经常被用到，比如作业调度（主要实现简单，很容易想到）；
-  **LRU（Least recently use）最近最少使用算法**：根据使用时间到现在的长短来判断；
-  **LFU（Least frequently use）最少使用次数算法**：根据使用次数来判断；
-  **OPT（Optimal replacement）最优置换算法**：理论的最优，理论；就是要保证置换出去的是不再被使用的页，或者是在实际内存中最晚使用的算法。

##### 12、磁盘调度算法

磁盘 I/ 0 调度的主要目标就是减少请求队列中对应的平均柱面定位时间。目前常用的磁盘调度算法有:
**（1）先来先服务( First Come First Served, FCFS)**：这是一种最简单的磁盘调度算法，它根据进程请求访问磁盘的先后次序进 行调度。此算法的优点是公平、简单，且每个进程的请求都能依次得到处理，不会出现某一进程的请求长期得不到满足的情况。但此算法由于未对寻道进行优化，致使平均寻道时间可能很长。当用户提出的访问请求比较均匀地遍布整个盘面，而不具有某种集中倾向时（通常是这样），该算法策 略导致了随机访问模式，即无法对访问进行优化。在对盘的访问请求比较多的情况 下，此策略将降低设备服务的吞吐量、增加响应时间，但各进程得到服务的 响应时间的变化幅度较小。该算法适用于访问请求不是很多，磁盘 I/0 负载较轻且每次读写多个连续扇区的情况，其算法实现最简单。
**（2）最短寻道时间优先( Shortest Seek Time First, SSTF)**：考虑磁盘 I/ 0 请求队列中各请求的磁头定位位置，选择从当前磁头位置出发，移动距离或时间最少的磁盘 I/ 0 请求。该算法的目标是使每次磁头移动时间最少。它不一定是最短平均柱面定位时间，但比先来先服务算法有更好的性能。该策略可以得到比较好的吞吐矗，有较低的平均响应时间。其缺点是对用户的服务请求的响应机会不是均等的，可能会有进程处于饥饿状态。对中间磁道的访问请求一般会得到最好的服务 ，对内、外两侧磁道的服务随偏离中心磁道的距离而越远越差 ，因而导致响应时 间的变化幅度很大，在服务 请求很多的情况下，对内 、外边缘磁道的请求将会无限期地被延迟，因而有些请求的响应时间将不可预期 。
**（3）扫描算法( SCAN ) **：由于这种算法中磁头移动的规律像电梯的运行，所以又称为电梯调度算法。电梯算法考虑两个因素：

- 首先方向一致，其次距离最短。即先响应其请求方向与电梯移动方向一致的请求；
- 在方向一致的请求中，先响应电梯最先经其所在楼层的请求者。例如电梯在升到三楼时检测到四个请求：二楼、四楼和六楼有人上楼，五楼有人要下楼，那么在假定未超出电梯容釐而且暂时没有其他新请求出现的情况下，电梯的响应次序是 ：四 楼、六楼、五楼、二楼。
- 选择在磁头前进方向上从当前位置移动最少的磁盘 I/ 0 请求执行 ，没有前进方向上的请求时才改变方向。该算法是对 SSTF 算法的改进，磁盘 I/ 0 性能较好，且没有进程会饿死。
- 该算法不仅考虑到欲访问的磁道与当前磁道的柱面距离 ，更优先考虑磁头的当前移动方向。即当磁头正在自里向外运动时，该算 法要选择的下一访问对象是其欲访问的磁道在当前磁道之外，又是距离最近的。直至再无更外的磁道需要访问时，才将磁臂换向，自外向里运动。从而避免了饥饿 现象的出现。

**（4）循环扫描算法( Circular Scan, CSCAN )**：循环扫描是指总在一个方向上使用扫描算法，当到达边沿时直接移动到另一边沿的第一个位置。该算法可改进扫描算法对中间磁道的偏好。实验表明， 该算法在中负 载或重负 载时 ，磁盘 I/ 0 性能比扫描算法好。循环扫描算法实 际上可以看成源于 C RT 电子束扫描线法。循环扫描策略与基本扫描策略不同之处在于循环扫描是单向反复地扫描。当磁臂向内移动时 ，它对本次移动开始前到达的各访问要求，自外向内地依次给予服务，直到对最内柱面上的访问要求满足后，磁臂直接向外移动，使磁头停在 所有新的访问要求的最外边的柱面上。然后再对本次移动前 到达的各访问要求依次给予服务。它之所以被称为循环扫描策略，是因为将磁盘各磁道视为一个环形缓 冲区似的构造一 首尾相连，最后一个磁道与第一个相接。若有磁头能立即折返的驱动器则此算法才更有意义。

##### 13、Linux下的五种I/O模型

Linux下有5中I/O模型，分别是：

1)阻塞I/O（blocking I/O）
2)非阻塞I/O （nonblocking I/O）
3) I/O复用(select /poll/epoll) （I/O multiplexing）
4)信号驱动I/O （signal driven I/O (SIGIO)）
5)异步I/O （asynchronous I/O (the POSIX aio_functions)）

前四种都是同步，只有最后一种才是异步IO。

##### 13.1 阻塞I/O模型

应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待….数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。

**阻塞I/O模型图：**在调用recv()/recvfrom（）函数时，发生在内核中等待数据和复制数据的过程。

<img src="https://image.easyblog.top/1334216532_9745.jpg" style="zoom:67%;" />

<font color=red>**当调用recv()函数时，系统首先查是否有准备好的数据。如果数据没有准备好，那么系统就处于等待状态。当数据准备好后，将数据从系统缓冲区复制到用户空间，然后该函数返回。在套接应用程序中，当调用recv()函数时，未必用户空间就已经存在数据，那么此时recv()函数就会处于等待状态。**</font>

##### 13.2 非阻塞IO模型

非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回.

**阻塞I/O模型图：**我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，**不要将进程睡眠**，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。

<img src="https://image.easyblog.top/1334216607_3004.jpg" style="zoom:67%;" />

##### 13.3 IO复用模型

 I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。

<img src="https://image.easyblog.top/1334216620_6310%20(1).jpg" style="zoom:60%;" />

##### 13.4 信号驱动I/O

首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。

<img src="https://image.easyblog.top/1334216632_6025.jpg" style="zoom:50%;" />

##### 13.5 异步IO模型

当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作

<img src="https://image.easyblog.top/1334216641_7821.jpg" style="zoom:50%;" />



##### 14、IO多路复用,讲下select、poll、epoll

select，poll，epoll都是IO多路复用的机制。**I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作**。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

**（1）select：**

```c
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

1、 单个进程可监视的fd数量被限制，即能监听端口的大小有限。   一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.

2、 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

3、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大



**（2）poll：**

```c
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
```

不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。

```c
struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：

1、大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。                                                                   2、poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。



**（3）epoll:**

epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

**epoll操作过程需要三个接口，分别如下：**

```c
int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

**1. int epoll_create(int size);**
创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，`参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议`。
当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

**2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event \*event)；**
函数是对指定描述符fd执行op操作。
\- epfd：是epoll_create()的返回值。
\- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
\- fd：是需要监听的fd（文件描述符）
\- epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：

**epoll支持水平触发(LT)和边缘触发(ET)**，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知

```c
struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};

//events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
```

**3. int epoll_wait(int epfd, struct epoll_event \* events, int maxevents, int timeout);**
等待epfd上的io事件，最多返回maxevents个事件。
参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。

**epoll工作模式**

　epoll对文件描述符的操作有两种模式：**LT（level trigger）**和**ET（edge trigger）**。LT模式是默认模式，LT模式与ET模式的区别如下：
　　**LT模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序可以不立即处理该事件`。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
　　**ET模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序必须立即处理该事件`。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

##### 1. LT模式

LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。

##### 2. ET模式

ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)

ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

**epoll的优点：**

<font color=red>**1、没有最大并发连接的限制，**</font>能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）； 
<font color=red>**2、效率提升**</font>，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数； 
    即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 

<font color=red>**3、 内存拷贝**</font>，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 

**select、poll、epoll 区别总结：** 

**1、支持一个进程所能打开的最大连接数**

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210116185346.png"  />

**2、FD剧增后带来的IO效率问题**

![](https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210116185356.png)


**3、 消息传递方式**

![](https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210116185414.png)

**总结：**

综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。

1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。

2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善



#### MySQL(数据库)

##### 1、讲一下数据库范式

数据库范式也分为1NF，2NF，3NF，BCNF，4NF，5NF。一般在我们设计关系型数据库的时候，最多考虑到BCNF就够。符合高一级范式的设计，必定符合低一级范式，例如符合2NF的关系模式，必定符合1NF。

**第一范式（1NF）**：符合1NF的关系中的每个属性都不可再分

**第二范式（2NF）**：2NF在1NF的基础之上，消除了非主属性对于码的部分函数依赖。

**第三范式（3NF）** 3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖。

**BCNF范式**：每个表中只有一个候选键。

**第四范式（4NF）**：满足3NF,消除表中的多值依赖

##### 2、主键是什么？

主键也称为主码或主关键字，用于可以惟一地确定一个元组的属性或属性组(复合主码)称为主键。每个关系都有一个并且只有一个主码。

##### 3、INNER JOIN、LEFT JOIN、RIGHT JOIN、FULL OUTER JOIN

 **INNER JOIN**：内连接是最常见的一种连接，只连接匹配的行。

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/03/java2-1585449630.png" alt="SQL的各种连接Join详解，都需要熟练掌握！" style="zoom:60%;" />

inner join语法：

```sql
select column_name(s)
from table 1
INNER JOIN table 2
ON
table 1.column_name=table 2.column_name
```



**LEFT JOIN**：LEFT JOIN返回左表的全部行和右表满足ON条件的行，如果左表的行在右表中没有匹配，那么这一行右表中对应数据用NULL代替。

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/03/java10-1585449630.png" alt="SQL的各种连接Join详解，都需要熟练掌握！" style="zoom:60%;" />

LEFT JOIN 语法

```sql
select column_name(s)
from table 1
LEFT JOIN table 2
ON table 1.column_name=table 2.column_name
```

注释：在某些数据库中，LEFT JOIN 称为LEFT OUTER JOIN



**RIGHT JOIN**：RIGHT JOIN返回右表的全部行和左表满足ON条件的行，如果右表的行在左表中没有匹配，那么这一行左表中对应数据用NULL代替。

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/03/java7-1585449630.png" alt="SQL的各种连接Join详解，都需要熟练掌握！" style="zoom:60%;" />

RIGHT JOIN语法

```sql
select column_name(s)
from table 1
RIGHT JOIN table 2
ON table 1.column_name=table 2.column_name
```

注释：在某些数据库中，RIGHT JOIN 称为RIGHT OUTER JOIN



**FULL OUTER JOIN**：FULL JOIN 会从左表 和右表 那里返回所有的行。如果其中一个表的数据行在另一个表中没有匹配的行，那么对面的数据用NULL代替

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/03/java6-1585449631.png" alt="SQL的各种连接Join详解，都需要熟练掌握！" style="zoom:60%;" />

FULL OUTER JOIN语法

```sql
select column_name(s)
from table 1
FULL OUTER JOIN table 2
ON table 1.column_name=table 2.column_name
```



##### 4、union和union all的区别

UNION和UNION ALL关键字都是将两个结果集合并为一个。

UNION在进行表连接后会筛选掉重复的记录，所以在表连接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。

而UNION ALL只是简单的将两个结果合并后就返回。

由于UNION需要排序去重，所以 UNION ALL 的效率比 UNION 好很多。

#####  5、TRUNCATE 与 DELETE 区别

TRUNCATE 是DDL语句，而 DELETE 是DML语句。

TRUNCATE 是先把整张表drop调，然后重建该表。而 DELETE 是一行一行的删除，所以 TRUNCATE 的速度肯定比 DELETE 速度快。

TRUNCATE 不可以回滚，DELETE 可以。TRUNCATE 执行结果只是返回0 rows affected，可以解释为没有返回结果。

TRUNCATE 会重置水平线（自增长列起始位），DELETE 不会。TRUNCATE 只能清理整张表，DELETE 可以按照条件删除。

一般情景下，TRUNCATE性能比DELETE好一点。

##### 6、MySQL架构

MySQL官方给出的系统逻辑架构分为4层，如下图所示：

<img src="http://image.easyblog.top/15876123716456454af44-aa1c-41ac-88d1-10274207417e.png" alt="img" style="zoom:40%;" />

这四层自顶向下分别是**连接层，服务层（核心层），存储引擎层，系统文件层**。我们自顶向下开始讲解。

##### 6.1、连接层

最上层是一些客户端和连接服务，包含本地 sock 通信和大多数基于客户端/服务端工具实现的类似于 tcp/ip 的通信。**主要完成一些类似于连接处理、授权认证、及相关的安全方案**。在该层上使用了**线程池**技术，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于 SSL 的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

##### 6.2、服务层

第二层服务层是MySQL的核心，MySQL的核心服务层都在这一层：**查询解析，SQL执行计划分析，SQL执行计划优化，查询缓存**。以及跨存储引擎的功能都在这一层实现：存储过程，触发器，视图等。重要的组件的功能如下图所示：

| Management Serveices & Utilities | 系统管理和控制工具                                           |
| -------------------------------- | ------------------------------------------------------------ |
| **SQL Interface**                | **SQL 接口。接受用户的 SQL 命令，并且返回用户需要查询的结果。比如`select \* from xxx`就是调用 SQL Interface** |
| **Parser**                       | **SQL解析器。 SQL 命令传递到解析器的时候会被解析器验证和解析** |
| **Optimizer**                    | **SQL查询优化器。 SQL 语句在查询之前会使用查询优化器对查询进行优化，比如有where 条件时，优化器来决定先投影还是先过滤。** |
| **Cache 和 Buffer**              | **查询缓存。如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key 缓存，权限缓存等** |

在这一层就是SQL语句被执行的一层，接下来我们**分析一下SQL语句的执行过程**：

（1）**mysql客户端通过协议和mysql服务器连接，发送查询语句，首先会检查查询缓存(query cache)，如果命中，直接返回结果，否则进行语句解析** 。 **查询缓存(query cache)**——它存储 SELECT 语句以及相应的查询结果集。如果某个查询结果已经位于缓存中，服务器就不会再对查询进行解析、优化、以及执行。它仅仅将缓存中的结果返回给用户即可，这将大大提高系统的性能。

（2）语法解析器和预处理：**首先mysql解析器会将SQL语句根据关键字进行解析，并生成一颗"解析树"。语法解析器会根据mysql语法规则对解析树进行语法检查；预处理器则根据一些 mysql 规则进一步检查解析数是否合法**。

（3）**当解析树被认为是合法的了，会通过查询优化器将其转化成执行计划**。通常一条查询可以有很多种执行方式，最后都返回相同的结果。优化器的作用就是找到这其中最好的执行计划。

（4）**在完成语法解析和优化之后，mysql会生成执行计划。查询执行引擎根据执行计划给出的指令调用存储引擎的结构得到结果**。在查询到结果后除了返回给客户端外，还会将结果缓存一份到查询缓存中。

##### 6.3、存储引擎层

存储引擎层，**存储引擎真正的负责了 MySQL 中数据的存储和提取，服务器通过 API 与存储引擎进行通信**。MySQL采用插件式的存储引擎。MySQL为我们提供了许多存储引擎，每种存储引擎有不同的特点。我们可以根据不同的业务特点，选择最适合的存储引擎。如果对于存储引擎的性能不满意，可以通过修改源码来得到自己想要达到的性能。

这里需要说明的是：**存储引擎是针对于表的而不是针对库的（一个库中不同表可以使用不同的存储引擎），服务器通过API与存储引擎进行通信，用来屏蔽不同存储引擎之间的差异**。

在MySQL中常用的存储引擎有3个：**InnoDB、MyISAM以及Memory**。

##### 6.4、系统文件层

**该层主要是将数据库的数据存储在文件系统之上，并完成与存储引擎的交互。**

###### MyISAM文件格式

MyISAM在磁盘存储上有三个文件，每个文件名以表名开头，扩展名指出文件类型：

- `.frm文件`：用于存储表结构的定义
- `.MYD文件`：用于存放数据，可以及理解为MyISAM Data===>MYD
- `.MYI文件`：用于存放表索引，可以理解为MYISAM Index===>MYI

MyISAM引擎还支持三种不同类型的存储格式：静态表、动态表、压缩表

###### InnoDB文件格式

InnoDB属于索引组织表，InnoDB有两种存储方式：**共享表空间和独享表空间存储**。两种存储方式的表结构信息和MyISAM一样，以表名开头，扩展名是`.frm`。

`.frm`文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等。

`.ibd/.ibdata`文件：存放innodb表的数据文件。

- **独享表空间存储方式使用.ibd文件格式。**
- **共享表空间存储方式使用.ibdata存储方式**，所有的表共同使用一个ibdata文件，即所有的数据文件都存在一个文件中。决定使用哪种表的存储方式可以通过mysql的配置文件中 `innodb_file_per_table`选项来指定。

**InnoDB默认采用的是独享表空间存储数据，这种方式的好处是当数据库产生大量文件碎片的时，整理磁盘碎片对线上运行环境的影响较小**。

##### 7、什么是索引？使用索引有哪些优缺点？

MySQL 官方对索引的定义为：**索引（Index）是帮助 MySQL 高效获取数据的数据结构**。从官方的定义可以得到索引的本质：**索引是数据结构**，可以简单理解为索引就是一种数据结构，它可以帮助我们快速的从数据库查询到数据。索引就类似于一本书的目录，通过目录可以快速找到需要查找对内容。

###### 优势

- **提高查询效率**：提高对数据的检索效率，降低数据库的IO成本。
- **天生排序**：通过索引对数据进行排序，降低数据的排序成本，从而降低了CPU的消耗。

###### 劣势

- **降低更新表的速度**：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。因此，如果你的表`INSERT/UPDATE/DELETE`操作比较多的话还是不建议使用索引，这样反而会降低数据库的速度。
- **占用额外的空间**：实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以**索引列也是要占用空间的**。

##### 8、MySQL索引的数据结构有哪些

索引是在MySQL的**存储引擎层**实现的，所以每种存储引擎支持的缩影都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型，MySQL目前提供了以下4中数据类型的索引：

- **B+树索引**：最常见的索引类型，大部分存储引擎都支持BTREE索引。
- **Hash索引**：只有Memory引擎支持，使用场景比较简单。
- **R-tree索引（空间索引）**：空间索引是MyISAM引擎的一个特殊索引类型，通常使用较少。
- **Full-text索引（全文索引）**：全文索引也是MyISAM支持的一种特殊索引类型，主要用于全文索引，InnoDB从MySQL5.6开始也支持全文索引。

##### 9、什么是聚集索引和非聚集索引？有什么区别？

**聚簇索引**

**聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据**，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。

Innodb通过主键聚集数据，如果没有定义主键，innodb会选择非空的唯一索引代替。如果没有这样的索引，innodb会隐式的定义一个主键来作为聚簇索引。

**非聚簇索引** 

非聚簇索引就是以非主键构建的B+树，非聚簇索引访问数据总是需要二次查找。**非聚簇索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行**。

##### 10、说说你知道的MySQL的索引类型，并分别简述一下各自的场景

* 单值索引：即一个索引只包含单个列，一个表可以有多个单列索引。

* 唯一索引：使用UNIQUE参数可以设置唯一索引。创建该索引时，索引列的值必须唯一，但允许有空值。通过唯一索引，用户可以快速地定位某条记录，主键索引是一种特殊的唯一索引。

* 主键索引：**特殊的唯一索引，不允许有空值。设定为主键后数据库会自动建立索引**，innodb为聚簇索引。主键索引会随着表的创建而创建

* 复合索引：两个或更多个列上组合而成的索引被称作复合索引，复合索引又叫联合索引。在mysql建立复合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从复合索引的最左边开始匹配。简单来说复合索引有以下几个好处：

	（1）建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。减少磁盘空间的开销。

	（2）可以使用上**覆盖索引**，对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。覆盖索引是主要的提升性能的优化手段之一。

	（3）**效率高：**索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql `select from table where col1=1 and col2=2 and col3=3`，假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出`1000W * 10%=100w`条数据，然后再回表从100w条数据中找到符合`col2=2 and col3= 3`的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出`1000w * 10% * 10% * 10%=1w`，效率得到明显提升。

> ##### 什么是覆盖索引？
>
> 覆盖索引（covering index）指一个查询语句的执行只用从索引页中就能够取得（如果不是聚集索引，叶子节点存储的是主键+列值，最终还是要回表，也就是要通过主键再查找一次），避免了查到索引后，再做回表操作，减少I/O提高效率。
>
> ##### 最左前缀原则？
>
> 在 MySQL 建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边的索引开始匹配。MySQL 会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

##### 11、MySQL索引使用时有哪些注意点？

**（1）选择唯一性索引**

**唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录**。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。

**（2）为经常需要排序、分组和联合操作的字段建立索引**

经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。

**（3）为常作为查询条件的字段建立索引**

如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。

**（4）限制索引的数目**

索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。

**（5）尽量使用数据量少的索引**

如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间肯定要比对CHAR(10)类型的字段需要的时间要多。

**（6）尽量使用前缀来索引**

如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。

**（7）删除不再使用或者很少使用的索引**

表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。

**（8）最左前缀匹配原则，非常重要的原则。**

mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a 1=”” and=”” b=”2” c=”“> 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

**（9）=和in可以乱序。**

比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式

**（10）尽量选择区分度高的列作为索引。**

区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就 是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条 记录

 **（11）索引列不能参与计算，保持列“干净”**。

比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，B+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本 太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);

**（12）尽量的扩展索引，不要新建索引。**

比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可

>  注意：选择索引的最终目的是为了使查询的速度变快。上面给出的原则是最基本的准则，但不能拘泥于上面的准则。根据应用的实际情况进行分析和判断，选择最合适的索引方式。 

##### 12、MySQL有哪些存储引擎？讲一下InnoDB和MyISAM之间的区别？

Oracle、SqlServer等数据库只支持一种存储引擎。MySQL提供了插件式的引擎结构，可以根据需求使用不同的存储引擎，甚至可以自定义编写存储引擎。

 MySQL5.0支持的存储引擎包括：InnnoDB、MyISAM、MEMORY、BDB、MERGE、EXAMPLR、NDB CLUSTER、ARCHIVE、CSV等，其中InnoDB和BDB提供事务安全表，其他存储引擎是非事务安全表。

在mysql命令行，可以使用`show engines;`命令查看当前数据库支持的存储引擎，如下图所示：

![img](http://image.easyblog.top/15877912409579b4892f5-8d6c-4ac5-8f42-dfb703d4ddff.png)

常用的两种数据库引擎分别是InnoDB和MyISAM，InnoDB和MyISAM之间的区别如下：

**MyISAM：**

- 不支持事务，但是每次查询都是原子的；
- 支持表级锁，即每次操作对整个表加锁；
- 存储表的总行数；
- 一个MYISAM表有三个文件：索引文件、表结构文件、数据文件；
- 采用非聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。

**InnoDb：**

- 支持ACID的事务，支持事务的四种隔离级别；
- 支持行级锁及外键约束：因此可以支持写并发；
- 不存储总行数；
- 一个InnoDb引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为2G），受操作系统文件大小的限制；
- 主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。

**两者的适用场景：**

因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统读多，写少。对原子性要求低。那么MyISAM最好的选择。且MyISAM恢复速度快。可直接用备份覆盖恢复。

如果系统读少，写多的时候，尤其是并发写入高的时候。InnoDB就是首选了。

<font color=red>**扩展问题：myisam与innodb引擎下select count(\*)哪个更快，为什么？**</font>

##### 13、讲一下B-Tree？B+-Tree？

**B-Tree**

<img src="https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbueZlk5yA7Mw02rbGf4rSqoDGibKb8CPnmt1iaC7zoCuZq4MNNUshdrRZAvPgvkG9csf67DOTr1ckxOQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:40%;" />

B-Tree，平衡多路查找树，如果每个节点，最多有N个孩子，那么这样的树就叫N阶B-Tree，
每个节点中主要包含关键字和指向孩子的指针，最多能有几个孩子，取决于节点的容量和数据库的相关配置，通常情况下这个N是很大的。

B-Tree作为一种数据结构，有如下特征：

1. 根节点至少包含两个孩子
2. 树中每个节点至多含有N个孩子（N>=2)
3. 除根节点和叶节点外，其它每个节点至少有ceil(N/2)个孩子。（ceil表示取上限，例如1.2的上限为2，1.1的上限也为2，非四舍五入）
4. 所有叶子节点都位于同一层，即叶子节点的高度都是一样的。
5. 假设每个非终端节点包含n个关键字信息（P0,P1…Pn,k1…kn）

**B+ -Tree（MySQL）**

<img src="https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbueZlk5yA7Mw02rbGf4rSqoDloNUluQPIiavNrzJ1k8CIvFk8DGL8nsFvwveCyfzCgao9pUfmRJFu7w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

B+ -Tree是B-Tree的一个变体，其定义基本与B树相同，特别之处如下:

1. 非叶子节点的子树指针与关键字个数相同，其表明B+树能存储更多的关键字
2. 非叶子节点的子树指针P[i]，指向关键字值[K[i],K[i+1])的子树。
3. 非叶子节点仅用来做索引，数据到保存在叶子节点中。（B+树的所有检索都是从根部开始，直到搜索到叶子节点结束。）
4. 所有叶子节点均有一个链指针，指向下一个叶子节点。（方便直接在叶子节点直接做范围统计）

**B+树相较于B树的优势：**

1. **B+树的磁盘读写代价更低。**B+树有利于磁盘的IO，因为他的层高基本不会因为数据扩大而增高（三层树结构大概可以存放两千万数据量。）
2. **B+树的查询效率更加稳定。**B+树的所有数据都在叶子节点上，所以B+树的查询效率稳定，一般都是查询3次。
3. **B+树更有利于对数据库的扫描**。由于叶子节点上存放了所有的数据，并且有指针相连，每个叶子节点在逻辑上是相连的，所以对于范围查找比较友好。

##### 14、索引用B+树而不用红黑树的原因？

**AVL 数和红黑树基本都是存储在内存中才会使用的数据结构**。在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**而造成磁盘IO读写过于频繁，进而导致效率低下的情况。

要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据**磁盘查找存取的次数往往由树的高度所决定**，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。

**数据库系统的设计者巧妙利用了磁盘预读原理**，将一个节点的大小设为等于一个页的大小（16k），这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

##### 15、Hash索引和B+树索引的优劣分析？

- 哈希索引没办法利用索引完成排序
- 不支持最左匹配原则
- 在有大量重复键值情况下，哈希索引的效率也是极低的---->哈希碰撞问题。
- 不支持范围查询

以上这些问题，B+树都可以和好的解决

##### 16、 什么是数据库事物

事务（Transaction）是访问和更新数据库的程序执行单元；事务中可能包含一个或多个sql语句，这些语句要么都执行成功，要么全部执行失败。

##### 17、事务的四大特性（ACID）

* **原子性（Atomicity，或称不可分割性）**：**一个事务必须被视为一个不可分割的最小工作单元，整个事务中所有的操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事务的原子性**
* **一致性（Consistency）**：**数据库总是从一个一致性的状态转换到另外一个一致性的状态，在事务开始之前和之后，数据库的完整性约束没有被破坏。**比如，用户A和B转账，他两的的账户总额是1000，那么不管A和B之间如何转账，转账几次，事物结束后A和B两个用户的账户总额还是1000，这就是事物的一致性。
* **隔离性（Isolation）**：**隔离性是指，一个事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰。严格的隔离性，对应了事务隔离级别中的Serializable (可串行化)，但实际应用中出于性能方面的考虑很少会使用可串行化。**
* **持久性（Durability）**：**持久性是指事务一旦提交，它对数据库的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。**

##### 18、数据库并发事物带来的问题

* **丢失修改**：两个事物T1和T2同一时间读入同一个数据进行修改，晚一步提交的T2破坏了T1提交的结果，导致T1的修改丢失了。

* **不可重复读**：不可重复度有三种情况：

	（1）事物T1读取某一数据后，事物T2对其进行了修改，当T1以同样的条件再次读取该值时候，得到了与之前不一致的结果（值内容变了）

	（2）事物T1读取某一个数据后，事物T2删除了其中某些数据，当事物T1再以相同条件读取数据时发现某些记录神秘的消失了。

	（3）事物T1读取某一个数据后，事物T2插入了一些记录，当事物T1再以相同条件读取数据时发现多了一些数据。

	上面（2）（3）的情况又被称为**幻读**

* **脏读**：事物T1修改某一数据并写会磁盘，但是还未提交事物，这时事物T2读取到同一数据后，事物T1由于某种原因回滚了，此时T2读取到的数据就是脏数据.

##### 19、MySQL的四种隔离级别？

* **读未提交（READ UNCOMMITTED）**：在这个隔离级别下，事务的修改即使没有提交，对其他事务也是可见的。事务可以读取未提交的数据，这也被称之为`脏读`。这个级别会带来很多问题，从性能上来说，`READ UNCOMMITTED`不会比其他的级别好太多，但是却会带来很多问题，除非真的有非常必要的理由，在实际应用中一般很少使用。
* **读已提交（REDA COMMITED）**：大多数数据系统的默认隔离级别都是`REDA COMMITED`（MySql不是），`REDA COMMITED`满足前面提到的隔离性的简单定义：一个事务开始时，只能看到已经提交的事务所做的修改。换句话说，一个事物从开始直到提交前，所做的修改对其他事务不可见。这个级别有时候也叫做`不可重复读`，因为执行两次相同的查询可能会得到不同的结果。
* **可重复读（REPEATABLE READ）**：`REPEATABLE READ`解决了`脏读`以及`不可重复度的问题`。该级别保证了同一个事务多次读取同样记录的结果是一致的。但是理论上，可重复度还是无法解决另外一个`幻读`的问题。所谓幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，就会产生幻行。
* **可串行化（SERIALIZABLE）**：`SERIALIZABLE`是最高的隔离级别，它通过强制事务串行执行，避免前面说的幻读。简单来说`SERIALIZABLE`会在读取的每一行数据上都加锁，所以可能会导致大量的超时和锁争用的问题。实际应用中也很少使用这个隔离级别，只有在非常需要确保数据一致性而且可以接受没有并发的情况下，才考虑此级别。

RC和RR的实现原理可以参考MVCC的实现原理，可串行化完全就是通过数据库锁实现的。

##### 20、乐观锁和悲观锁了解吗？

**悲观锁**

正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。

读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。

 **乐观锁**

相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。

何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。

此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

MySQL、ORACLE、PostgreSQL等都是使用了以乐观锁为理论基础的MVCC（多版本并发控制）来避免不可重复读和幻读,MVCC的实现没有固定的规范，每个数据库都会有不同的实现方式，这里讨论的是InnoDB的MVCC。



##### 21、MVCC(多版本并发控制)的原理

**MySQL中RC和RR两个隔离级别就是通过MVCC机制实现的**。MVCC全称Multiple Version Concurrency Control，也就是**多版本并发控制**，实现的逻辑就是读不加锁，写加锁，读写不冲突。

**（1）版本链（undo log）**

根据行为的不同，undo log可以分为两种：insert undo log 和 update undo log

**insert undo log**

是在insert操作中产生的undo log。因为insert操作的记录只对事务本身可见，对于其他事务此几率是不可见的，所以insert undo log可以在事务提交之后而不需要进行purge操作

**update undo log**

是update或delete操作中产生的undo log，因为会对已经存在的记录产生影响，为了提供MVCC机制，因此update undo log不能在事务提交时就直接删除，而是在事务提交时放入history list上，等待purge线程进行最后的删除操作。

在MySQL中每条记录除了有我们定义的字段之外，他还为我们默认生成了是三个隐式字段： **trx_id、roll_pointe和row_id**

<img src="http://image.easyblog.top/16016474568581772bea7-d973-4aca-8a10-9e5c36db75f8.png" alt="img" style="zoom:57%;" />

- **trx_id**代表这条记录版本是被哪个事务创建的，数据库有一个全局的事务ID分配器，它一定是递增的，新的事务ID一定不会和旧的事务ID重复。
- **roll_pointer**是连接版本链的指针。
- **row_id**不是必须的，他的作用和数据记录的主键一样。当数据库字段有指定主键时，Mysql会选取唯一字段作为主键，如果没有唯一字段，那就生成一个6字节的row_id来作为主键。

在MVCC中，每条记录都有多个版本，串成了一个版本链，也就是说，记录被UPDATE时并不是In Place Update，而是将记录复制然后修改存一份到版本链，被DELET时，也不是马上从文件删除，而是将记录标记为被删除，它也是版本链的一环。

```sql
#Transcation 50
BEGIN:
INSERT INTO product(ID,product_name,price) VALUE(1001,"笔记本",5000);
#未提交
#Transcation 100
BEGIN:
UPDATE product(ID,product_name,price) VALUE(1001,"笔记本"，6000);
UPDATE product(ID,product_name,price) VALUE(1001,"笔记本"，4000);
#未提交
```

上面一系列操作执行后undo log如下：

<img src="http://image.easyblog.top/1601648857291a7d3ee3f-8e8d-42b4-bd50-1c75c3f3847d.png" alt="img" style="zoom:50%;" />

**（2）Read View**

MVCC中最常听到的概念就是**快照**，其实快照只是最终结果，而不是实现方式，**快照 = 版本链 + Read View**。 **首先要明确只有SELECT操作需要ReadView，换句话说进行读操作时SELECT语句读取到的到底是哪个版本的数据，取决于ReadView**。Read View保存着当前活跃事务的ID，具体有以下信息：

<img src="http://image.easyblog.top/1601653728491a22d6edf-14fc-4fde-8ab8-7a366c96bcff.png" alt="Read View" style="zoom:50%;" />

**ReadView什么时候产生？**

这个问题对于RC和RR的实现是不同的：

- RC：在每个事务中的每个SELECT语句执行的时候实时产生一个全新的ReadView
- RR：在一个事务中，只会在第一个SELECT语句执行的时候产生一个ReadView，之后的SELECT语句复用这个ReadView

**ReadView可不可用如何判断？**

Read View结合版本链使用，当事务读取某条记录时，会根据此事务的Read View判断此记录的哪个版本是这个事务可见的：

1. **如果记录的trx_id与当前事物id相同，则代表这个版本是此事务创建的，可以读取**。
2. **如果记录的trx_id小于最小事物id，代表这个版本是此事务生成Read View之前就已经创建的，可以读取**。
3. **如果记录的trx_id大于等于最大事物id，代表这个记录版本是此事务生成Read View之后创建的，不能被读取**。
4. **如果记录的trx_id处于最小事物id与最大事物id之间，则判断trx_id是否在m_ids中，如果不在，则代表这个版本是此事务生成Read View时已经提交的，可以读取，否则就不可以读取**。

**MVCC的局限性**

* **MVCC不可以避免幻读**
* **无法避免Read Skew与Write Skew**
* **无法避免丢失更新**

##### 21、MySQL中的锁机制（InnoDB）

总的来说，InnoDB共有七种类型的锁：

- **共享/排它锁(Shared and Exclusive Locks)**

	- 共享锁（Share Locks，记为S锁），读取数据时加S锁
	- 排他锁（eXclusive Locks，记为X锁），修改数据时加X锁

	使用的语义为：

	- 共享锁之间不互斥，简记为：读读可以并行
	- 排他锁与任何锁互斥，简记为：写读，写写不可以并行

- **意向锁(Intention Locks)**

	InnoDB为了支持多粒度锁机制(multiple granularity locking)，即允许行级锁与表级锁共存，而引入了意向锁(intention locks)。意向锁是指，未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向。

	1.意向锁是一个表级别的锁(table-level locking)；

	2.意向锁又分为：

	- 意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁；
	- 意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁；

- **记录锁(Record Locks)**：记录锁，它封锁索引记录。例如：SELECT * FROM `test` WHERE `id`=1 FOR UPDATE;它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行

- **间隙锁(Gap Locks)**：间隙锁，它封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围

	<img src="http://image.easyblog.top/16016937543872e4613f8-a021-462f-8b02-1c726335238c.png" alt="Gap Lock不锁记录，只向前锁间隙" style="zoom:50%;" />

- **临键锁(Next-key Locks)**：临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。

	默认情况下，innodb使用next-key locks来锁定记录。但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围

	<img src="http://image.easyblog.top/1601695007173f486e073-6240-4637-8fba-589ac83ba70f.png" alt="img" style="zoom:50%;" />

- **插入意向锁(Insert Intention Locks)**：插入意向锁，是间隙锁(Gap Locks)的一种（所以，也是实施在索引上的），它是专门针对insert操作的。多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。

- **自增锁(Auto-inc Locks)**：自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入AUTO_INCREMENT类型的列。最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。

**总结**

以上总结的7种锁，个人理解可以按两种方式来区分：

**1.按锁的互斥程度来划分，可以分为共享、排他锁；**

- 共享锁(S锁、IS锁)，可以提高读读并发；
- 为了保证数据强一致，InnoDB使用强互斥锁(X锁、IX锁)，保证同一行记录修改与删除的串行性；

**2.按锁的粒度来划分，可以分为：**

- 表锁：意向锁(IS锁、IX锁)、自增锁；
- 行锁：记录锁、间隙锁、临键锁、插入意向锁；

其中InnoDB的细粒度锁(即行锁)，是实现在索引记录上的(我的理解是如果未命中索引则会失效)；**记录锁锁定索引记录**；**间隙锁锁定间隔，防止间隔中被其他事务插入；临键锁锁定索引记录+间隔，防止幻读**；InnoDB使用插入意向锁，可以提高插入并发；**间隙锁(gap lock)与临键锁(next-key lock)只在RR以上的级别生效，RC下会失效**；

##### 22、explain讲一下

使用explain关键字可以模拟SQL优化器执行SQL语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析你的查询语句或是表结构的性能瓶颈。

使用方法十分简单，只用在需要分析的sql语句前面加上`explain`关键字即可，执行后会有如下表格输出：

![img](http://image.easyblog.top/15878844478789374ad01-9a3b-40a3-aa25-2b36865ad187.png)

* **id列**：该列的值是select 查询的序列号,包含一组数字，表示查询中执行 select 子句或操作表的顺序。id 相同，执行顺序由上至下；id 不同，如果有子查询，id 的序号会递增，**id 值越大优先级越高，越先被执行**；d相同和不同都有时，先执行序号大的，先从下而上执行。遇到序号相同时，再从上而下执行。

* **select_type**：select_type 代表查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询。

	| select_type 属性         | 含义                                                         |
	| ------------------------ | ------------------------------------------------------------ |
	| **SIMPLE**               | 简单的select查询，查询中不包含任何子查询或UNION              |
	| **PRIMARY**              | 查询中若包含任何复杂的子部分，最外层主查询则被标记为 Primary |
	| **DERIVED**              | 在 FROM 列表中包含的子查询被标记为 DERIVED(衍生)MySQL 会递归执行这些子查询, 把结果放在临时表里。 |
	| **SUBQUERY**             | 在SELECT或WHERE列表中包含了子查询                            |
	| **DEPEDENT SUBQUERY**    | 在SELECT或WHERE列表中包含了子查询,子查询基于外层             |
	| **UNCACHEABLE SUBQUERY** | 无法使用缓存的子查询                                         |
	| **UNION**                | 若第二个SELECT出现在UNION之后，则被标记为UNION；若UNION包含在FROM子句的子查询中,外层SELECT将被标记为：DERIVED |
	| **UNION RESULT**         | 从UNION表获取结果的SELECT                                    |

* **type**：type 是查询的访问类型。是较为重要的一个指标，结果值从最好到最坏依次是：**system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index>ALL** ，一般来说，**得保证查询至少达到 range 级别，最好能达到 ref**。

* **possible_keys**：显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上若存在索引，则该索引将被列出， 但不一定被查询实际使用，如果没有就是NULL。

* **key**：使用到的索引，如果没用索引就是NULL。

* **key_len**：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。 key_len 字段能够帮你检查是否充分的利用上了索引。ken_len 越长，说明索引使用的越充分。

* **ref**：显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值

*  **extra**：其他的额外重要的信息。常见的信息有以下几种：

	| 信息                         | 含义                                                         |
	| ---------------------------- | ------------------------------------------------------------ |
	| Using filesort               | 表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现。 |
	| Using temporary              | 使了用临时表保存中间结果,MySQL 在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by。 |
	| Using index                  | Using index 代表表示相应的 select 操作中使用了覆盖索引(Covering Index)，避免访问了表的数据行，效率不错！如果同时出现 using where，表明索引被用来执行索引键值的查找;如果没有同时出现 using where，表明索引只是用来读取数据而非利用索引执行查找。 |
	| Using where                  | 表明使用了 where 过滤。                                      |
	| Using join buffer            | 使用了连接缓存。                                             |
	| impossible where             | where 子句的值总是 false，不能用来获取任何元组。             |
	| select tables optimized away | 在没有 GROUPBY 子句的情况下，基于索引优化 MIN/MAX 操作或者对于 MyISAM 存储引擎优化 COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 |

##### 23、数据库主从复制、分库分表

**主从复制**

MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。**MySQL 默认采用异步复制方式**，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。

**MySQL中主从复制原理**

<img src="http://image.easyblog.top/1588141533774102ae3fe-8384-4106-8e8d-48bca3198a52.png" alt="img" style="zoom:70%;" />

MySQL的主从复制主要分为三步：

- master会在事务提交后将数据变化记录到二进制日志文件binlog中。这些记录过程叫做二进制日志事件，binary log events，这一过程主要由主节点的`log dump`线程执行
- 当savle结点上执行`start savle`执行之后，slave会创建一个I/O线程连接主节点，请求主库中的二进制日志文件，并拷贝数据到本地的中继日志文件（Relay log）中。
- salve结点的SQL线程读取中继日志中记录的事件，并把改变记录到自己的数据库中。MySQL的复制显然是异步并且是串行化的。

**分库分表**（Sharding-JDBC插件）

**为什么要分库分表：**当一张表的数据达到几千万时，你查询一次所花的时间会变多，如果有联合查询的话，我想有可能会死在那儿了。分表的目的就在于此，减小数据库的负担，缩短查询时间。

mysql中有一种机制是表锁定和行锁定，是为了保证数据的完整性。表锁定表示你们都不能对这张表进行操作，必须等我对表操作完才行。行锁定也一样，别的sql必须等我对这条数据操作完了，才能对这条数据进行操作。

数据分片的拆分方式又分为**垂直分片和水平分片**。

**（1）垂直拆分**

按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的**核心理念是专库专用**。在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。如下图

<img src="http://image.easyblog.top/1588588369693b492d10a-353e-41f1-9f2d-3730de08c0d6.png" alt="img" style="zoom:37%;" />

垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平拆分来进一步处理。

**（2）水平拆分**

水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。 例如：根据主键分片，偶数主键的记录放入0库（或表），奇数主键的记录放入1库（或表），如下图：

<img src="http://image.easyblog.top/158858854357802a9a8f0-ff2d-4e9c-9f92-7558e0c4c162.png" alt="img" style="zoom:37%;" />

水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。

#### Redis

##### 1、Redis有哪些常见的数据结构？底层都是如何实现的？

Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求

| 数据类型 | 可以存储的值           | 操作                                                         | 应用场景                                                     |
| :------- | :--------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| String   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 | 做简单的键值对缓存                                           |
| List     | 列表                   | 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 | 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据 |
| Set      | 无序集合               | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 | 交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集 |
| Hash     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 | 结构化的数据，比如一个对象                                   |
| ZSet     | 有序集合               | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 | 去重但可以排序，如获取排名前几名的用户                       |

**底层实现**

##### **Redis对象头—redisObject**

Redis使用对象头来存储键和值，在Redis中，每个对象都是由redisObject结构表示。redisObject结构主要包括三个属性：type、encoding、和类型指针ptr

redisObject，其结构体如下：

```c
typedef struct redisObject {
    // 类型
    unsigned type:4;
    // 编码
    unsigned encoding:4;
    // 指向数据的指针
    void *ptr;

    // 记录对象最后一次被程序访问时间，用于计算空转时长(当前时间-lru)
    unsigned lru:22; /* lru time (relative to server.lruclock) */
    // 引用计数，用于内存回收
    int refcount;
} robj;
```

* **type**：类型，即一个redisObject的类型，常见类型有string、list、hash、set和zset

* **encoding**：编码，即redis底层有8种数据结构编码，如下表所示：

	<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210119145416.png" alt="img" style="zoom:40%;" />

* **ptr**：*ptr 属性指向了对象的底层数据结构，而这些数据结构由 encoding 属性决定。

##### **字符串(string)**

<img src="http://image.easyblog.top/16019837308461a918545-ccd9-4388-9f3a-a43679ba9b3b.jpg" alt="img" style="zoom:80%;" />

**字符串对象的编码可以是int、raw或者embstr**。

**如果一个字符串的内容可以转换为int，那么该字符串就会被转换成为int类型，对象的ptr就会指向该int，并且对象类型也用int类型表示**。

**普通的字符串有两种，embstr和raw**。embstr应该是Redis 3.0新增的数据结构,在2.8中是没有的。**如果字符串对象的长度小于39字节，就用embstr对象**。

使用场景：

1. **缓存功能**：字符串最经典的使用场景，redis做为缓存层，Mysql作为储存层，绝大部分请求数据都是redis中获取，由于redis具有支撑高并发特性，所以缓存通常能起到加速读写和降低 后端压力的作用。
2. **计数器**：许多运用都会使用redis作为计数的基础工具，他可以实现快速计数、查询缓存的功能，同时数据可以一步落地到其他的数据源。如：视频播放数系统就是使用redis作为视频播放数计数的基础组件。
3. **共享session**：出于负载均衡的考虑，分布式服务会将用户信息的访问均衡到不同服务器上，用户刷新一次访问可能会需要重新登录，为避免这个问题可以用redis将用户session集中管理，在这种模式下只要保证redis的高可用和扩展性的，每次获取用户更新或查询登录信息都直接从redis中集中获取。
4. **限速**：处于安全考虑，每次进行登录时让用户输入手机验证码，为了短信接口不被频繁访问，会限制用户每分钟获取验证码的频率。

##### **list**

<img src="http://image.easyblog.top/160198386696952aadd7f-8115-4a34-a62e-b8f52935c1a6.jpg" alt="img" style="zoom:80%;" />

**list对象的编码可以是ziplist或者linkedlist**。

ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储。但当数据量过大时就ziplist就不是那么好用了。因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。

当list对象同时满足以下两个条件时，列表对象使用ziplist编码：

（1）**列表对象保存的所有字符串元素的长度都小于64字节**

（2）**列表对象保存的元素数量小于512个**

当有任一条件 不满足时将会进行一次转码，使用linkedlist。

使用场景：

1. **消息队列**： redis的lpush+brpop命令组合即可实现阻塞队列，生产者客户端是用lupsh从列表左侧插入元素，多个消费者客户端使用brpop命令阻塞时的“抢”列表尾部的元素，多个客户端保证了消费的负载均衡和高可用性

#####  **hash**

<img src="http://image.easyblog.top/1601983995008c47d3829-d39a-4327-a676-283f4208eb44.jpg" alt="img" style="zoom:80%;" />

哈希对象的底层实现可以是ziplist或者hashtable。

**zipList编码的哈希对象使用压缩列表作为底层实现,每当有新的健值对要加入到哈希对象时,程序会先将保存了key的压缩列表节点推入到压缩列表尾,然后再将保存了value的压缩节点推入到压缩列表尾**，因此：**保存了同一key:vlaue对的两个节点总是紧挨在一起,保存key的节点在前,保存value的节点在后**，如下图所示：

<img src="http://image.easyblog.top/1601986990892c8bf061e-5204-4c01-babd-19e458d63871.png" alt="img" style="zoom:80%;" />

当对象数目不多且内容不大时，这种方式效率是很高的。此时redis会使用哈希表（hashtable）作为底层数据结构

hashtable编码的哈希独享使用字典作为底层实现,**哈希对象中的每个键值对都使用一个字典健值对来保存。字典的每个键(key)和每个值(value)都是一个字符串对象,对象中保存了键或值。这种结构的时间复杂度为O(1)，但是会消耗比较多的内存空间**。

当哈希对象可以同时满足以下两个条件时,哈希对象使用ziplist编码，否者将会使用hashtable编码:

- 当键的个数小于hash-max-ziplist-entries（默认512）
- 当所有值都小于hash-max-ziplist-value（默认64）

使用场景：

1. 哈希结构相对于字符串序列化缓存信息更加直观，并且在更新操作上更加便捷。所以常常用于**用户信息**等管理，但是哈希类型和关系型数据库有所不同，哈希类型是稀疏的，而关系型数据库是完全结构化的，关系型数据库可以做复杂的关系查询，而redis去模拟关系型复杂查询，开发困难，维护成本高。

**set**

<img src="http://image.easyblog.top/160198394292566226036-2515-499c-b1ee-f2bc96123003.jpg" alt="img" style="zoom:80%;" />

**set对象的编码可以是intset或者hashtable。**

intset编码使用的条件:

（1）**集合对象保存的元素全部都是整数**

（2）**集合对象保存的元素不超过512个**

不满足以上条件，集合对象需要使用hashtable

**注：第二个条件的上限可以修改，set-max-intset-entries默认值为512。表示如果entry的个数小于此值，则可以编码成REDIS_ENCODING_INTSET类型存储，节约内存。否则采用dict的形式存储。**

使用场景：

1. **标签（tag）**：集合类型比较典型的使用场景，如一个用户对娱乐、体育比较感兴趣，另一个可能对新闻感兴趣，这些兴趣就是标签，有了这些数据就可以得到同一标签的人，以及用户的共同爱好的标签，这些数据对于用户体验以及曾强用户粘度比较重要。（用户和标签的关系维护应该放在一个事物内执行，防止部分命令失败造成数据不一致）
2. sadd=tagging（标签）
3. 生成随机数，比如抽奖：spop/srandmember=random item
4. sadd+sinter=social Graph(社交需求)

**zset**

<img src="http://image.easyblog.top/16019838048817e95cd42-0be9-4149-8209-963303dd58a4.jpg" alt="img" style="zoom:80%;" />

**zset的编码有两种，一种是ziplist，另一种是skiplist与dict的结合**。

**ziplist编码的压缩对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存,第一个节点保存元素的成员（member），而第二个原属则保存元素的分值（score）**

**压缩列表内的集合原属按分值从小到大进行排序,分值较小的元素放置在靠近表头的方向,而分值较大的元素则放置在靠近表位的方向**

<img src="http://image.easyblog.top/160198799949601fdb12e-d910-48fc-bf3e-56919be74078.jpg" alt="img" style="zoom:40%;" />

ziplist编码的使用条件:

（1）**有序集合保存的元素数量小于128个**

（2）**有序集合保存的所有元素成员长度小于64字节**

上限值可以根据配置文件中的配置进行调整

skiplist是一种跳跃表，它实现了有序集合中的快速查找，在大多数情况下它的速度都可以和平衡树差不多。但它的实现比较简单，可以作为平衡树的替代品。它的结构比较特殊。

使用场景：

1. **排行榜**：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

##### 2、Redis为什么要采用渐进式rehash？

rehash是发生在reids哈希表数据结构中的一个操作，redis中hash表结构是这个样子的：

<img src="http://image.easyblog.top/16019764714675c7fff68-7dd4-41d4-9aab-ab00d8a7b26b.png" alt="img" style="zoom:50%;" />

蓝色部分很好理解，数组就是bucket，一般不同的key首先会定位到不同的bucket，若key重复，就用链表把冲突的key串起来。熟悉HashMap的同学应该不陌生，这个结构和HashMap的结构几乎一样，就连处理冲突的的方式都是采用一样的方式：拉链法。

再来看看哈希表总体图中左边橘黄色的部分，其中有两个关键的属性：**ht和 rehashidx**。ht是一个只包含两个元素的数组，数组中每一项都是一个dictht哈希表。其中，**ht[0]存放的是redis中正在使用的哈希表，而ht[1]与哈希表的扩容有关，具体来说，ht[1]用于hash表的扩容操作**。

除了ht[1]之外，是有一个属性与hash表的扩容有关，他就是rehashidx，他记录的是当前rehash的进度，如何当前没有扩容，那么他的值是-1。

redis计算哈希值和索引值得仿佛如下：

```c
//计算键的哈希值
hash=dict->type->hashFunction(key);
//使用hash值和哈希表的sizemask属性计算哈希值
//根据情况不同，ht[x]可以是ht[0]或ht[1]
index=hash&dict->ht[x].sizemask;
```



**rehash**

随着操作不断执行，哈希表保存的键值会原越来越多，为了让哈希表负载因子（**加载因子（load factor）=ht[0].used/ht[0].size**）在合理的范围内，需要适当的对hash表进行扩容和收缩。

扩容和收缩的步骤如下：

* 1）为字典的ht[1]哈希表分配空间，新hash表的空间大小取决于要执行的操作，以及ht[0]所包含的的键值对数量：

	* 扩容：第一个大于等于 ht[0].used*2的 2^n(2的n次方幂)。

	* 收缩：第一个大于等于 ht[0].used的 2^n(2的n次方幂)。

* 2）将保存在ht[0]中的所有键值对rehash到ht[1]上，
* 3）当ht[0]所包含的的所有键值对都 迁移到ht[1]上之后(ht[0]变成空表)，释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]创建一个空白hash表为下次扩容做准备。



**扩容和收缩触发的时机**

扩容：

- 没有执行BGSAVE和BGREWRITEAOF指令的情况下，哈希表的 加载因子大于等于1。
- 正在执行BGSAVE和BGREWRITEAOF指令的情况下，哈希表的 加载因子大于等于5。

收缩:

- 加载因子小于0.1时，程序自动开始对哈希表进行收缩操作。



**渐进式rehash**

上面说到，扩容或者收缩哈希表时需要将ht[0]中的所有键值对迁移到ht[1]中，如果ht[0]中的数据量不是很大，几十几百甚至几万个，对于redis来说都不是大问题；但是，如果hash表中存储的键值对数量是几百万、几千万甚至上亿的数据，那么要一次性将这些键值对迁移到ht[1]中，庞大的数据可能会使redis服务器在一段时间内停止服务。

因此为了**避免rehash对服务器性能造成影响，服务器不会一次将ht[0]中的数据迁移到ht[1]中，而是分多次，渐进式的完成**。

以下是哈希表渐进式rehash的详细步骤：

* 1）**为ht[1]分配空间，让字段同事持有ht[0]和ht[1]两个hash表**。
* 2）**在字典中维持一个索引计数器变量rehashidx,并将他的值设置为0，表示rehash开始**。
* 3）**在rehash期间，每次对ht[0]字典执行添加、删除、查找或者更新操作时，程序除了执行指定操作外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对迁移到ht[1]上，完成后，rehashidx值+1**。
* 4）**随着字典操作不断进行，最总在某个时间点上，ht[0]上的所有键值对都将会被rehash到ht[1]，这是程序设置rehashidx为-1,表示rehash操作完成**。



##### 3、Redis中zset的内部实现为跳跃表，讲一下skiplist？

**skiplist是一种基于有序列表发展而来的数据数据结构，他可以支持平均O(logN)，最坏O(N)的时间复杂度**。大部分情况下，skiplist的效率可以和平衡树相媲美，而且skiplist的实现更加简单，只要你能熟练操作链表，就能轻松实现一个 skiplist。

**有序表的搜索**

考虑一个有序表：

![img](https://image.easyblog.top/151151293294032.jpg)

从该有序表中搜索元素 < 23, 43, 59 > ，需要比较的次数分别为 < 2, 4, 6 >，总共比较的次数为 2 + 4 + 6 = 12 次。有没有优化的算法吗?  链表是有序的，但不能使用二分查找。类似二叉搜索树，我们把一些节点提取出来，作为索引。得到如下结构：

![img](https://image.easyblog.top/151151540794271.jpg)

 这里我们把 < 14, 34, 50, 72 > 提取出来作为一级索引，这样搜索的时候就可以减少比较次数了。

 我们还可以再从一级索引提取一些元素出来，作为二级索引，变成如下结构：

![img](https://image.easyblog.top/151152187209308.jpg)

元素越多skiplist的优势就越明显



**skiplist**

<img src="https://image.easyblog.top/ab38e55851b64dffbfa590db3624d89a.png" alt="img" style="zoom:67%;" />

跳表具有如下性质：

* (1) 由很多层结构组成，支持平均O(logN)，最坏O(N)的时间复杂度
* (2) 每一层都是一个有序的链表
* (3) 最底层(Level 1)的链表包含所有元素
* (4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
* (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

**插入操作**

上图所示的skiplist有9个结点，一共4层，可以说是理想的跳跃表了，不过随着我们对跳跃表进行插入/删除结点的操作，那么跳跃表结点数就会改变，意味着跳跃表的层数也会动态改变。

这里我们面临一个问题，就是**新插入的结点应该跨越多少层？**

这个问题已经有大牛替我们解决好了，采取的策略是通过**抛硬币来决定新插入结点跨越的层数**：每次我们要插入一个结点的时候，就来抛硬币，如果抛出来的是**正面**，则继续抛，直到出现**负面**为止，统计这个过程中出现正面的**次数**，这个次数作为结点跨越的层数。

例如，我们要插入结点 3，4，通过抛硬币知道3，4跨越的层数分别为 0，2 (层数从0开始算)，则插入后skiplist如下：

<img src="https://image.easyblog.top/6ccd5ec56ac54ab99588b08600115704.png" alt="img" style="zoom:67%;" />

**删除操作**

解决了插入之后，我们来看看删除，删除就比较简单了，例如我们要删除4，那我们直接把4及其所跨越的层数删除就行了

<img src="https://image.easyblog.top/37692853b9fe4caf9ff3051a5295e262.png" alt="img" style="zoom:67%;" />



##### 4、Redis支持事物吗？

Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的

1）MULTI命令用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。

2）EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。

3）通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。

4）WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。

Redis会将一个事务中的所有命令序列化，然后按顺序执行。但是：

1. redis 不支持回滚“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。
2. 如果在一个事务中的命令出现错误，那么所有的命令都不会执行；
3. 如果在一个事务中出现运行错误，那么正确的命令会被执行。

注：redis的discard只是结束本次事务,正确命令造成的影响仍然存在.

##### 5、Redis是单线程的还是多线程的？为什么这么设计？

Redis6之前是单线程的，这么设计是因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。

既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！），其次Redis利用队列技术将并发访问变为串行访问

1）绝大部分请求是纯粹的内存操作（非常快速）

2）采用单线程,避免了不必要的上下文切换和竞争条件

3）非阻塞IO（IO多路复用）优点：

- 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
- 支持丰富数据类型，支持string，list，set，sorted set，hash
- 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
- 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除如何解决redis的并发竞争key问题

##### 6、单线程的Redis为什么可以这么快？

Redis采用的是基于内存的采用的是**单进程单线程**模型的 **KV 数据库**，**由C语言编写**,下图是Redi官方给出的一个在不同连接数下Redis吞吐量的曲线，横纵表示连接数，纵轴表示是吞吐量（q/s）：

<img src="http://image.easyblog.top/15925806440640d0eef02-f152-4f71-9607-2edc9201a8c4.png" alt="img" style="zoom:50%;" />

这张图反映了一个数量级，希望大家在面试的时候可以正确的描述出来，不要问你的时候，你回答的数量级相差甚远！几个关键的数量级：**最大QPS：100万+，30_0000连接：60_0000QPS，60_0000连接：50_0000万QPS**

- 1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；
- 2、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 3、使用多路 I/O 复用模型，非阻塞 IO；

##### 7、缓存穿透、缓存击穿、缓存雪崩的概念以及解决方法

**7.1、缓存穿透**

缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。

**解决办法：**

* 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

* 另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。

**7.2、缓存击穿**

缓存击穿，是指当某个key在过期的瞬间，有大量的请求并发访问过期的键，这类数据一般是热点数据，由于缓存过期了，会同时访问数据库来查询数据，并写回缓存，从而导致数据库瞬间压力过大。

 **解决方法**：

- **设置热点数据永不过期**
- 使用**redis的setnx互斥锁**先进行判断，这样其他线程就处于等待状态，保证不会有大并发操作去操作数据库

**7.3、缓存雪崩**

缓存雪崩是指设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，导致所有的查询同一时刻都落到了数据库上，造成了数据库压力过大。缓存雪崩与缓存击穿的区别在于这里针对很多key同时失效，前者则是针对某一个热点key失效。

**解决方案：**

（1）不同的key，设置不同的过期时间，让缓存失效的时间尽量均匀

（2）在缓失效后，通过分布式锁或者分布式队列的方式控制数据库写缓存的线程数。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。（和缓存击穿中使用互斥锁类似）

（3）如果是因为某台缓存服务器宕机，可以考虑做主备，比如：redis主备，但是双缓存涉及到更新事务的问题，update可能读到脏数据，需要好好解决。

##### 8、Redis的过期键删除策略以及内存淘汰策略

 **8.1 Redis 过期键策略**

Redis键的过期时间都保存在过期字典中，过期键的删除策略有3种：

**（1）定时删除**

优点：对内存友好，通过定时器可以保证过期键过期键会尽可能快的删除，并释放过期键占用的空间。

缺点：1）cpu不友好，在过期键比较多的情况下，删除过期键可能会占用相当一部分cpu时间；在内存不紧张cpu紧张的情况下，将cpu时间用在删除和当前任务无关的过期键上，无疑会对服务器响应时间和吞吐量造成影响。2）创建定时器需要Redis服务器中的时间事件，而现在时间事件的实现方式是无序链表，查找一个事件的时间复杂度为O(N)，并不能高效的处理大量时间事件。

**（2）惰性删除**

优点：1）对cpu友好，程序只在取出键时才对建进行过期检查，删除的目标仅限于当前处理的键。

缺点：1）对内存不友好，当数据库中有大量的过期键，而这些键又没有被访问到，那么他们也许会永远不会被删除。

**（3）定期删除**

**定期删除是前两种删除策略的一种折中。会每隔一段时间执行一次删除过期键操作，并通过限制操作执行的时长和频率来减少删除操作对cpu时间的影响。**

**定期删除策略的难点是确定删除操作执行的时长和频率**：

- 如果删除操作执行得太频繁，或者执行的时间太长，定期删除策略就会退化成定时删除策略，以至于将CPU时间过多地消耗在删除过期键上面
- 如果删除操作执行得太少，或者执行的时间太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况

Redis中同时使用了**惰性过期和定期过期两种过期策略**。

定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。

于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。

**8.2 内存淘汰策略**

Redis采用的是**定期删除+惰性删除策略**并不是一种完全精准的删除，就还是会存在key没有被删除掉的场景，如果大量过期key堆积在内存里，导致redis内存块耗尽了，怎么办？所以就需要内存淘汰策略进行补充，内存淘汰策略就是当redis使用的内存到达了最大内存阈值之后移除键的一种策略。Redis有如下几种内存淘汰策略:

* **volatile-lru**：从所有设置了过期时间的key中，选择删除最近最少使用的key
* **allkeys-lru**：从所有的key中选择删除最近最少使用的key
* **volatile-lfu**：从所有设置了过期时间的key中，选择删除使用频率最低的key
* **allkeys-lfu**：从所有key中选择删除使用频率最低的key
* **volatile-random**：从所有设置了过期时间的key中，随机选择删除key
* **allkeys-random**：从所有key中随机选择删除key
* **volatile-ttl**：从设置过期时间的数据集(server.db[i].expires)中挑选将要过期的数据淘汰，ttl值越大越优先被淘汰。
* **noeviction**：当内存达到阈值的时候，新的写入操作报错

##### 9、Redis的持久化机制？

Redis的持久化机制有两种：**RDB和AOF**，可以单独使用其中一种或将二者结合使用。

**RDB**

**RDB持久化是Redis默认使用的持久化方式，它是将当前Redis进程中的数据生成快照保存到硬盘，默认会在当前工作目录下生成`dump.rdb`文件，当Redis重启的时候会自动读取快照文件来恢复数据**。

Redis提供了多种创建RDB文件的方法，用户既可以使用SAVE命令或BGSAVE命令手动创建RDB文件，也可以在redis.conf配置文件中设置save来配置选项让服务器在满足指定条件后自动触发BGSAVE命令。

<img src="https://i.loli.net/2019/09/25/bQkG8CoUIPJz4Lr.png" alt="img" style="zoom:50%;" />

SAVE命令和BGSAVE命令都可以生成RDB文件。SAVE和BGSAVE的区别是：

- **SAVE**：接收到SAVE命令后，Redis服务器将遍历数据库包含所有数据库，并将各个数据库包含的键值对全部记录到RDB文件中。在SAVE命令执行期间，Redis服务器将阻塞，直到RDB文件创建完毕为止。如果在创建RDB文件时已经有了对应的RDB文件，那么服务器将会新创建RDB文件代替已有的RD文件。
- **BGSAVE**：BGSAVE是SAVE命令的异步版本，当Redis服务器收到BGSAVE命令是，将会执行以下操作： 1）创建一个子进程（拷贝一份父进程）。 2）子进程执行SAVE命令，创建RDB文件。 3）RDB文件创建完毕之后，子进程退出并通知Redis服务器进程（父进程）RDB文件已经创建完毕。

常见的配置有：

```conf
# Redis默认设置， save m n 表示m秒内数据集存在n次修改时，自动触发bgsave。
save 900 1
save 300 10
save 60 10000

# 如果持久化出错，主进程是否停止写入
stop-writes-on-bgsave-error yes

# 是否压缩，如果开启，则消耗更多的CPU，否则消耗更多硬盘
rdbcompression yes

# 使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗
rdbchecksum yes

# 快照文件名称
dbfilename dump.rdb

# 快照文件保存路径
dir ./
```

除了手动或自动执行SAVE或BGSAVE命令可以产生RDB快照文件之外，一下情况也会出发BGSAE命令生成RDB快照文件：

- 在主从复制场景下，如果从结点执行全量复制操作，则主结点会执行BGSAVE命令，并将dump.rdb文件发送给从结点。
- 在执行`shutdown`命令时，会自动执行RDB持久化，这一点通过redis的日志看到

**RDB优缺点总结**

<img src="https://i.loli.net/2019/09/25/WxMBlUYPZVfGtI6.png" alt="img" style="zoom:33%;" />

**AOF（Append Only File）**

与全量式的RDB持久化功能不同，AOF提供的是增量式持久化功能，这种持久化的核心原理在于：**服务器每次执行完写命令之后，都会将命令追加到AOF文件尾部。这样一来服务器停机之后，只要重新执行AOF文件中保存的Redis命令，就可以将数据恢复值停机之前的状态**。与RDB相比较AOF具有更好的实时性，也是当前主流的持久化方案.

Redis服务器默认只开启了RDB持久化方式，要开启AOF，需要在redis.conf中修改`appendonly`为`yes`

<img src="https://i.loli.net/2019/09/25/1G8R9KUSt6XZ2Ad.png" alt="img" style="zoom:50%;" />

AOF的执行流程包括：

- **命令追加（append）**:将Redis的写操作追加到缓冲区aof_buf
- **文件写入（write）和文件同步（sync）**:根据不同的同步策略将aof_buf中的内容同步带硬盘
- **文件重写（rewrite）**：当AOF文件过大的时候重写AOF文件，达到压缩的目的。

**命令追加(append)**

Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。 命令追加的格式是Redis命令请求的协议格式，它是一种纯文本格式，具有兼容性好、可读性强、容易处理、操作简单避免二次开销等优点。在AOF文件中，除了用于指定数据库的select命令（如select 0 为选中0号数据库）是由Redis添加的，其他都是客户端发送来的写命令。

**文件写入（write）和文件同步（sync）**

Redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数：

- `write函数`：为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失
- `fsync函数`：为了解决write函数数据丢失的问题，因此系统提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性。

为了消除操作系统的写缓存机制带来的不确定性，Redis向用户提供了appendfsync选项，以此来控制系统写AOF的频率：

```css
 appendfsync <value>
```

appendfsync选项拥有always、no、everysec 3个值可选，他们代表的含义分别为：

**always**

命令写入aof_buf后立即调用系统的fsync函数同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。

<img src="http://image.easyblog.top/1602140956161850d2bcc-d707-4d2d-b535-663198716770.jpg" alt="img" style="zoom:60%;" />

**no**

命令写入aof_buf后调用系统的wirte函数，不对AOF文件做fsync同步，同步操作由系统负责，通常同步周期为30s。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。

<img src="http://image.easyblog.top/1602141074794391823c2-a12b-422f-9f94-6fb171544d70.jpg" alt="img" style="zoom:60%;" />

**everysec**

命令写入aof_buf后调用系统的write函数，write完成后返回，fsync同步文件操作，有专门的线程每一秒调用一次。**everysec是前面两种策略的折中，兼顾了性能和数据安全，也是Redis的默认配置。**

<img src="http://image.easyblog.top/1602141049474f14d7f4b-7734-45e3-b530-d14cc4325cd1.jpg" alt="img" style="zoom:60%;" />

**AOF文件重写**

AOF文件重写主要的作用就是对AOF文件进行压缩，减小AOF文件的体积。需要注意的是，<font color=red>AOF重写只会把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作。</font>

![img](http://image.easyblog.top/160214138177270bf8603-58a3-41c3-a183-a189355835a2.jpg)

**为什么文件重写可以压缩AOF文件？**

- 1. 过期的数据不需要再写入文件
- 1. 无效的命令不再写入文件
- 1. 多条命令可以合并为一条命令，比如`sadd stu v1`, `sadd stu v2` ,`sadd stu v2`，这三条操作可以合并为一条`sadd stu v1 v2 v3`。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义

总之压缩的原理就是通过重写减小命令的数量从而减少了文件的大小。

**文件重写的触发**

用户可以通过执行BGREWRITEAOF命令或者在配置文件中设置对应的选项来触发AOF文件重写操作。

**BGREWRITEAOF命令**

用户可以通过在Redis客户端**手动指定BGREWRITEAOF命令显式的触发AOF操作**，该命令是一个无参数命令。BGREWRITEAOF命令是一个异步命令，Redis服务器在接收到命令后会创建一个子进程，由他扫描数据库并生成新的AOF文件。当新的AOF文件生成完毕，子进程就会退出并通知主进程，然后主进程会使用新的AOF文件代替旧旧的AOF文件。

另外还可以通过配置选项自动的触发BGREWRITEAOF命令重写，主要配置的参数如下：

```css
auto-aof-rewrite-min-size <value>：执行AOF重写时，文件体积最小体积，默认为64MB。 
auto-aof-rewrite-percentage <value>：执行AOF重写时，当前AOF大小和上一次重写AOF大小的比值，默认大小100。这些参数都可通过`config get 参数`来查看。
```

其中 auto-aof-rewrite-min-size 用于设置自动触发BGREWRITEAOF命令的最小AOF文件体积，当AOF文件的体积喜小于给定值时，服务器将不会自动执行BGREWRITEAOF命令。默认值是64MB，含义就是如果AOF文件的体积超过64MB后就会自动触发BGREWRITEAOF命令执行AOF重写。

另一个选项 auto-aof-rewrite-percentage 它控制的是触发自动AOF文件重写所需的文件体积增大比例。默认值是100，表示如果当前AOF文件的体积比最后一次AOF文件重写后的体积增大了一倍（100%），那将自动触发BGREWRITEAOF命令执行AOF重写。如果之前还没有执行过重写，那么服务器启动时的AOF文件大小会被当做最后AOF重写的体积。



##### 10、AOF重写过程

<img src="http://image.easyblog.top/160214175256541f70d5e-d028-4f8f-9b41-b38579fb3df7.jpg" alt="img" style="zoom:50%;" />

对照上图，可以总结出**AOF文件的重写流程**如下：

1. Redis父进程首先判断当前是否存在正在执行 bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。
2. 父进程执行fork操作创建子进程，这个过程中会阻塞Redis主进程。
3. 父进程fork后，执行bgrewriteaof命令返回后不再阻塞父进程，此时Redis主进程恢复可以响应其他命令。Redis的所有写命令依然写入AOF缓冲区（`aof_rewrite_buf`），并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确。由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区(图中的aof_rewrite_buf)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。
4. 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。
5. 子进程重写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过info persistence查看。 接着父进程把AOF重写缓冲区（`aof_rewrite_buf`）的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。

**AOF优缺点总结**

<img src="https://i.loli.net/2019/09/25/hAz3CgHd8mYGa4v.png" alt="img" style="zoom:50%;" />

##### 11、Redis主从复制

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave),数据的复制是单向的，只能由主节点到从节点。

默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。

##### 主从复制启用

从节点开启主从复制，有3种方式：

1. 配置文件： 在从服务器的配置文件中加入：slaveof <masterip> <masterport>
2. 启动命令： redis-server启动命令后加入 --slaveof <masterip> <masterport>
3. 客户端命令： Redis服务器启动后，直接通过客户端执行命令：slaveof <masterip>
	<masterport>，则该Redis实例成为从节点。

> 通过  info replication 命令可以看到复制的一些信息

##### 主从复制原理

主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。

在从节点执行 slaveof 命令后，复制过程便开始运作，下面图示大概可以看到，
从图中可以看出复制过程大致分为6个过程

<img src="https://i.loli.net/2019/09/27/BsvoUViN4lRFhYD.png" alt="img" style="zoom:67%;" />

**step1：保存主节点信息** 从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。(用`info replication`命令就可以查看)

**slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。**

**step2：建立socket连接**    **从节点（slave）每秒1次调用复制定时函数replicationCron()，**如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。 如果连接成功： * 从节点（slave）：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。

- 主节点（master）：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，**并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。**

**step3：发送ping命令**    从节点（slave）成为主节点（master）客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： * （1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。

- （2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。
- （3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。

**step4：身份验证** 如果从节点中设置了requirepass 选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。

从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的requirepass 的值。

如果主节点设置密码的状态，与从节点requirepass 的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。

**step5：发送从节点端口信息** 身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的`slave_listening_port`字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。

**step6：持续复制阶段**   主从节点之间的连接建立以后，便可以开始进行数据同步，根据主从节点当前状态的不同，可以分为**全量复制和部分复制**。

* **全量复制**：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，这是一个非常耗费资源的操作。
* **增量复制**：当从节点正在复制主节点时，如果出现网络闪断和其他异常，从节点会让主节点补发丢失的命令数据，主节点只需要将复制缓冲区的数据发送到从节点就能够保证数据的一致性，相比较全量复制，成本小很多。**需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行增量复制，仍使用全量复制。**

 **心跳机制**

<img src="https://i.loli.net/2019/09/28/avIJg2bnUZCD1z9.png" alt="img" style="zoom:70%;" />

主从节点在建立复制后，他们之间维护着长连接并彼此发送心跳命令。

心跳的关键机制如下：

1. 主从都有心跳检测机制，各自模拟成对方的客户端进行通信，通过 client list 命令查看复制相关客户端信息，主节点的连接状态为 flags = M，从节点的连接状态是 flags = S。
2. 主节点默认每隔 10 秒对从节点发送 ping 命令，可修改配置 `repl-ping-slave-period` 控制发送频率。
3. 从节点在主线程每隔一秒发送`replconf ack{offset}` 命令，给主节点上报自身当前的复制偏移量。
4. 主节点收到 replconf 信息后，判断从节点超时时间，如果超过 repl-timeout 60 秒，则判断节点下线。

##### 12、Redis哨兵机制

 Sentinel(哨兵)是用于监控redis集群中Master状态的工具，是Redis 的高可用性解决方案。Sentinel可以让redis实现主从复制，当一个集群中的master失效之后，sentinel可以选举出一个新的master用于自动接替master的工作，集群中的其他redis服务器自动指向新的master同步数据。一般建议sentinel采取奇数台，防止某一台sentinel无法连接到master导致误切换。其结构如下:

<img src="https://i.loli.net/2019/09/28/KEx2r4tBuJ1GIPQ.png" alt="img" style="zoom:67%;" />

**优点：**

- 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都有。
- 主从可以自动切换，系统更健壮，可用性更高

**缺点：**

- redis较难支持在线扩容，在集群容量达上限时在线扩容变的很复杂。

##### 哨兵的工作方式：

1. 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个redis集群中的master主服务器、slave从服务器以及其他的Sentinel（哨兵）进程发送一个ping命令。
2. 如果一个实例距离最后一次有效回复ping命令的时间超过down-after-milliseconds选项所指定的值则这个实例会被Sentinel标记为主观下线（SDOWN）。
3. 如是是master主服务器被标记为SDOWN，则正在监控这个服务器的所有Sentinel都要以每秒一次的频率确认服务器是否真的已经进入SDOWN(主观下线状态)。
4. 当有足够数量（≥配置文件配置值）的Sentinel在指定的时间内确认了master进入了SDOWN状态，则master被标记为ODOWN(客观下线状态)。
5. 在一般情况下，每个Sentinel会每10秒向redis 主服务器和从服务器发送Info命令。但是当master被标记为客观下线时，频率改为1秒一次。
6. 若没有足够数量的Sentinel同意master服务器下线，则master的SDOWN状态被移除，若master重新向Sentinel发送ping命令返回了有效回复，则master的SDOWN状态被移除。

##### 哨兵机制的原理

1. Sentinel集群通过给定的配置文件发现master，启动时会监控master。通过向master发送info信息获得该服务下面的所有从服务器。
2. Sentinel集群通过命令连接向被监控的主从服务器发送hello信息（每秒一次），该信息包括Sentinel本身的ip、端口、id等内容，以此来向其他Sentinel宣告自己的存在。
3. Sentinel集群通过订阅连接接收其他Sentinel发送的hello信息，以此来发现监视同一个主服务器的其他Sentinel；集群之间会互相创建命令连接用于通信，因为已经有主从服务器作为发送和接收hello信息的中介，Sentinel之间不会创建订阅连接。
4. Sentinel集群使用Sentinel命令来检测实例的状态，如果指定的时间内（down-after-milliseconds）没有回复或者返回错误回复，那么该实例被判为主观下线SDOWN。
5. 当failover主备切换被触发后，failover并不会马上进行，还需要Sentinel集群中另外**quorum**个其他Sentinel授权，成功后进入ODOWN客观下线状态，之后再进行failover。
6. Sentinel向选为master的slave发送slaveof no one 命令，选择slave的条件是首先会根据slave的优先级来排序，优先级越小排名越靠前。如果相同，则查看复制的下标，哪个接收master的复制数据越多哪个越靠前，如果两个都一样就选择进程ID较小的。
7. Sentinel被授权后会获得宕机的master的一份最新配置版本号（config-epoch）当failover结束后，这个版本号将会用于最新的配置，通过广播的形式通知其他Sentinel，其它的Sentinel则更新对应的master配置。

**1-3是自动发现机制**

- 以10秒一次的频率，向被监控的master发送Info命令，根据回复获取当前master信息。
- 以1秒一次的频率，向所有的redis服务器包括 Sentinel 发送ping命令，通过回复判断服务器是否在线
- 以2秒一次的频率，通过 向所有被监控的master，slave服务器发送的当前Sentinel，master信息的消息。

 **4、是检测机制，5、6是failover机制，7是更新配置机制**。

**注意：**

- 因为redis采用的是异步复制，没有办法避免数据的丢失。但可以通过以下配置来使得数据不会丢失：min-slaves-to-write 1 ； min-slaves-max-lag 10。
- 一个redis无论是master还是slave，都必须在配置中指定一个slave优先级。
- 要注意到master也是有可能通过failover变成slave的。
- 如果一个redis的slave优先级配置为0，那么它将永远不会被选为master，但是它依然会从master哪里复制数据。

##### 13、Redis集群了解吗，讲一下

redis最开始使用主从模式做集群，若master宕机需要手动配置slave转为master；后来为了高可用提出来**哨兵**模式，该模式下有一个哨兵监视master和slave，若master宕机可自动将slave转为master，但它也有一个问题，就是不能动态扩充；所以在3.x提出cluster集群模式。

Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。

<img src="https://upload-images.jianshu.io/upload_images/12185313-0f55e1cc574cae70.png?imageMogr2/auto-orient/strip|imageView2/2/w/275/format/webp" alt="img" style="zoom:67%;" />

**其结构特点**：

* 1）所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。
* 2）节点的fail是通过集群中超过半数的节点检测失效时才生效。
* 3）客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。
* 4）redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配）,cluster 负责维护node<->slot<->value。
* 5）Redis集群预分好16384个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384的值，决定将一个key放到哪个桶中。 

**Redis cluster节点分配**
 现在我们是三个主节点分别是：A, B, C 三个节点，它们可以是一台机器上的三个端口，也可以是三台不同的服务器。那么，采用哈希槽 (hash slot)的方式来分配16384个slot 的话，它们三个节点分别承担的slot 区间是：

- 节点A覆盖0－5460;

- 节点B覆盖5461－10922;

- 节点C覆盖10923－16383.

	获取数据:
	 如果存入一个值，按照redis cluster哈希槽的[算法](http://lib.csdn.net/base/datastructure)（redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot）： CRC16('key')%·6384 = 6782。 那么就会把这个key 的存储分配到 B 上了。同样，当我连接(A,B,C)任何一个节点想获取'key'这个key时，也会这样的算法，然后内部跳转到B节点上获取数据

	新增一个主节点:
	 新增一个节点D，redis cluster的这种做法是从各个节点的前面各拿取一部分slot到D上，我会在接下来的实践中实验。大致就会变成这样：

- 节点A覆盖1365-5460

- 节点B覆盖6827-10922

- 节点C覆盖12288-16383

- 节点D覆盖0-1364,5461-6826,10923-12287

同样删除一个节点也是类似，移动完成后就可以删除这个节点了。

**Redis Cluster主从模式**
 redis cluster 为了保证数据的高可用性，加入了主从模式，一个主节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉取数据备份，当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉

上面那个例子里, 集群有ABC三个主节点, 如果这3个节点都没有加入从节点，如果B挂掉了，我们就无法访问整个集群了。A和C的slot也无法访问。

所以我们在集群建立的时候，一定要为每个主节点都添加了从节点, 比如像这样, 集群包含主节点A、B、C, 以及从节点A1、B1、C1, 那么即使B挂掉系统也可以继续正确工作。

B1节点替代了B节点，所以Redis集群将会选择B1节点作为新的主节点，集群将会继续正确地提供服务。 当B重新开启后，它就会变成B1的从节点。

不过需要注意，如果节点B和B1同时挂了，Redis集群就无法继续正确地提供服务了。

##### 14、Redis分布式锁如何实现？

一个合格的分布式锁应该具备哪些特性：

- 1、在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；
- 2、高可用的获取锁与释放锁；
- 3、高性能的获取锁与释放锁；
- 4、具备可重入特性；
- 5、具备锁失效机制，防止死锁；
- 6、具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败。

当前业内公认的实现分布式锁有三套方案：

（1） 基于数据库实现分布式锁
（2）基于缓存（Redis等）实现分布式锁（重点）
（3）基于Zookeeper实现分布式锁



**Redis实现分布式锁**

SETNX key value
功能：当且仅当 key 不存在，将 key 的值设为 value ，并返回1；若给定的 key 已经存在，则 SETNX 不做任何动作，并返回0。

##### 15、一致性hash算法原理

一致性hash算法将2^32个数分布在一个圆上，一个整数就是一个点，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆，示意图如下：

<img src="http://image.easyblog.top/15927320649367459ef72-d0b8-4b6c-bb14-571ce86d2a23.png" alt="img" style="zoom:50%;" />

圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32^-1,也就是说0点左侧的第一个点代表2^32^-1,我们把这个由2^32^个点组成的圆环称为**hash环**。

有了这个Hash环之后，我们首先按照一定的规则把服务节点通过普通的hash算法把结点记录到hash环的结点上，如下图所示：

<img src="http://image.easyblog.top/1592732949538da56c612-62cb-48f8-868d-9dde16c69766.png" alt="img" style="zoom:50%;" />

之后对数据的key同样做hash运算，拿到key的hash值，那么这个key必然就会在hash环上有一个“落点”,我们不要求它能一次性命中缓存结点，只需要顺着落点顺时针遍历每一个结点，当遍历到下一个缓存结点时就把值发入这个缓存结点后从这个缓存结点获取值。当一个key顺着hash环遍历到2^32^-1时又从0开始遍历，知道找到下一个结点。示意图如下：

<img src="http://image.easyblog.top/15927336993255796bd2f-8173-4709-8bb3-d4af50dc8740.png" alt="img" style="zoom:50%;" />

增加服务节点node4后：

<img src="http://image.easyblog.top/1592734541224d9219b56-ba95-47d4-9727-13f11e2a8727.png" alt="img" style="zoom:50%;" />

此时我们可以按照Hash一致性算法的原理分析不难看出：添加结点后可能产生问题的地方就在node3到node4之间，因为这个区间的数原本应该是映射到node1的，但是现在都要映射到node4新节点上去了，不过相对于简单的hash取余，这个方法使得动态增加或减少结点之后数据的可用性提升了不少。

**一致性Hash算法改进**

使用Hash一致性算法可以很轻松的解决分布式缓存带来的问题。然而，我们的分析还只是一种过于理想化的模型，即服务节点均匀的分布在Hash环的4周，假如结点没有均匀分布呢？我们来看看下面的示意图：

<img src="http://image.easyblog.top/1592735992820430ed7c9-eb11-48e1-9fc9-3d5b2448b7de.png" alt="img" style="zoom:45%;" />

当结点没有均匀分布时，一旦添加新的结点，仍然会有大部分数据会失效，这肯定不行啊！那么与上面办法解决这个问题呢？目前常用的解决办法就是**使用虚拟结点来解决服务节点分布不均匀的问题** ，具体原理是：

**给每个真实的物理结点增加一组虚拟结点，将虚拟结点也放置到Hash环上，这样当一个key遍历到虚拟结点了也就表示找到了真实的物理结点**。还是用示意图来说明：

<img src="http://image.easyblog.top/15927377089190b5e3861-58df-49c9-ae70-17af7947cf5e.png" alt="img" style="zoom:45%;" />

通过示意图可以直观的看出来，增加虚拟结点之后，我们人为的让有限的物理结点均匀分布了，这样一来当添加新结点之后受影响的数据很少。

通过分析我们不难得出结论：**对于每个物理节点对应的虚拟节点越多，各个物理节点之间的负载越均衡，新加入物理服务器对原有的物理服务器的影响越保持一致（这就是一致性Hash这个名称的由来)**。 那么在实践中，一台物理服务器虚拟为多少个虚拟服务器节点合适呢？太多会影响性能，太少又会导致负载不均衡，一般说来，经验值是150，当然根据集群规模和负载均衡的精度需求，这个值应该根据具体情况具体对待。

##### 16、Redis缓存和数据库的数据如何保证一致性

##### 方案一、先淘汰缓存，再更新数据库

1、在正常情况下，A、B两个线程先后对同一个数据进行读写操作：
  A线程进行写操作，先淘汰缓存，再更新数据库
  B线程进行读操作，发现缓存中没有想要的数据，从数据库中读取更新后的新数据
此时没有问题
2、在并发量较大的情况下，采用同步更新缓存的策略：
  A线程进行写操作，先成功淘汰缓存，但由于网络或其它原因，还未更新数据库或正在更新
  B线程进行读操作，发现缓存中没有想要的数据，从数据库中读取数据，但此时A线程还未完成更新操作，所以读取到的是旧数据，并且B线程将旧数据放入缓存。注意**此时是没有问题的**，因为数据库中的数据还未完成更新，所以数据库与缓存此时存储的都是旧值，数据没有不一致
  在B线程将旧数据读入缓存后，A线程终于将数据更新完成，**此时是有问题的**，数据库中是更新后的新数据，缓存中是更新前的旧数据，数据不一致。如果在缓存中没有对该值设置过期时间，旧数据将一直保存在缓存中，数据将一直不一致，直到之后再次对该值进行修改时才会在缓存中淘汰该值。此时可能会导致cache与数据库的数据一直或很长时间不一致

3、**在并发量较大的情况下，采用异步更新缓存的策略**：
  A线程进行写操作，先成功淘汰缓存，但由于网络或其它原因，还未更新数据库或正在更新
  B线程进行读操作，发现缓存中没有想要的数据，从数据库中读取数据，但B线程只是从数据库中读取想要的数据，并不将这个数据放入缓存中，所以并不会导致缓存与数据库的不一致
  **A线程更新数据库后，通过订阅binlog来异步更新缓存**
此时数据库与缓存的内容将一直都是一致的

**进一步分析：**
如果采取同步更新缓存的策略，即如果缓存中没有数据，就读取数据库并将数据直接放入缓存，可能会导致数据长时间的不一致
在这种情况下，可以用一些方法来进行优化：
**1、用串行化的思路**
  即保证对同一个数据的读写严格按照先后顺序串行化进行，避免并发较大的情况下，多个线程同时对同一数据进行操作时带来的数据不一致性。可以考虑使用分布式锁等
**2、延时双删+设置缓存的超时时间**
  不一致的原因是，在淘汰缓存之后，旧数据再次被读入缓存，且之后没有淘汰策略，所以解决思路就是，在旧数据再次读入缓存后，再次淘汰缓存，即淘汰缓存两次(延迟双删)
引入延时双删后，执行步骤变为下面这种情形：
  A线程进行写操作，先成功淘汰缓存，但由于网络或其它原因，还未更新数据库或正在更新
  B线程进行读操作，从数据库中读入旧数据，共耗时N秒
  在B线程将旧数据读入缓存后，A线程将数据更新完成，此时数据不一致
  A线程将数据库更新完成后，休眠M秒(M比N稍大即可)，然后再次淘汰缓存，此时缓存中即使有旧数据也会被淘汰，此时可以保证数据的一致性
  其它线程进行读操作时，缓存中无数据，从数据库中读取的是更新后的新数据

利用延迟双删，可以很好的解决数据不一致的问题，其中A线程休眠的M秒，需要根据业务上读取的时间来衡量，只要比正常读取消耗的实际稍大就可以。但是个人感觉实际业务中需要根据场景来设置休眠的时间，这个不好确定。

**引入延时双删后，存在两个新问题：**
  1、A线程需要在更新数据库后，还要休眠M秒再次淘汰缓存，等所有操作都执行完，这一个更新操作才真正完成，降低了更新操作的吞吐量
解决办法：用“异步淘汰”的策略，将休眠M秒以及二次淘汰放在另一个线程中，A线程在更新完数据库后，可以直接返回成功而不用等待。
  2、如果第二次缓存淘汰失败，则不一致依旧会存在
解决办法：用“重试机制”，即当二次淘汰失败后，报错并继续重试，直到执行成功个人

**“异步淘汰”策略：**
![_2](https://imgconvert.csdnimg.cn/aHR0cHM6Ly95cWZpbGUuYWxpY2RuLmNvbS8yNWE3ZTMwYjMzODA1NDZiYjk5ZTY3Y2IzZjQ3OTU5N2NiNTQ4M2RjLnBuZw?x-oss-process=image/format,png)
A线程执行完步骤2不再休眠Ms，而是往消息总线esb发送一个消息，发送完成之后马上就能返回

**【小结】**
在单节点下，用“先删缓存，再更新”的策略，如果采用同步更新缓存的策略，可能会导致数据长时间的不一致，可以通过一些方法来尽量避免不一致；如果采用异步更新缓存的策略，就不会导致数据不一致

##### 方案二、先更新数据库，再淘汰缓存

在正常情况下：
  A线程进行写操作，更新数据库，淘汰缓存
  B线程进行读操作，从数据库中读取新的数据
不会有问题

在并发较大的情况下，情形1：
  A线程进行写操作，更新数据库，还未淘汰缓存
  B线程从缓存中可以读取到旧数据，***此时数据不一致\***
  A线程完成淘汰缓存操作
  其它线程进行读操作，从数据库中读入最新数据，此时数据一致
不过这种情况并没有什么大问题，因为***数据不一致的时间很短，数据最终是一致的\***

在并发较大的情况下，情形2：
  A线程进行写操作，更新数据库，但更新较慢，缓存也未淘汰
  B线程进行读操作，读取了缓存中的旧数据
但这种情况没什么问题，毕竟更新操作都还未完成，数据库与缓存中都是旧数据，没有数据不一致

在并发较大的情况下，情形3：
  A线程进行读操作，缓存中没有相应的数据，将从数据库中读数据到缓存，
此时分为两种情况，还未读取数据库的数据，已读取数据库的数据，不过由于网络等问题数据还未传输到缓存
  B线程执行写操作，更新数据库，淘汰缓存
  B线程写操作完成后，A线程才将数据库的数据读入缓存，对于第一种情况，A线程读取的是B线程修改后的新数据，没有问题，对于第二种情况，A线程读取的是旧数据，***此时数据会不一致\***
***不过这种情况发生的概率极低，因为一般读操作要比写操作要更快\***
万一担心存在这种可能，可以用“延迟双删”策略，在A线程读操作完成后再淘汰一次缓存

**【小结】**
在该方案下，无论是采用同步更新缓存(从数据库读取的数据直接放入缓存中)，还是异步更新缓存(数据库中的数据更新完成后，再将数据同步到缓存中)，都不会导致数据的不一致
该方案主要只需要担心一个问题：如果第二步淘汰缓存失败，则数据会不一致
解决办法之前也提到过，用“重试机制”就可以，如果淘汰缓存失败就报错，然后重试直到成功

#### Java基础

##### 1、Java有几种数据类型，分别是什么？String是基本数据类型吗？

有八种基本数据类型。

| 数据类型 | 大小/字节 | 默认值   |
| :------- | :-------- | :------- |
| byte     | 1         | 0        |
| short    | 2         | 0        |
| int      | 4         | 0        |
| long     | 8         | 0        |
| float    | 4         | 0.0f     |
| double   | 8         | 0.0d     |
| char     | 2         | '\u0000' |
| boolean  | 4         | false    |

各自有几个字节也需要记忆一下

##### 基本类型对应的包装类型—让基本类型也具有对象的特征

为了让基本类型也具有对象的特征，就出现了包装类型（如我们在使用集合类型Collection时就一定要使用包装类型而非基本类型）因为容器都是装object的，这是就需要这些基本类型的包装器类了。

| 基本类型 | 包装器类型 |
| :------- | :--------- |
| boolean  | Boolean    |
| char     | Character  |
| int      | Integer    |
| byte     | Byte       |
| short    | Short      |
| long     | Long       |
| float    | Float      |
| double   | Double     |

##### 自动装箱&自动拆箱

自动装箱：`new Integer(6);`，底层调用:`Integer.valueOf(6)`

自动拆箱: `int i = new Integer(6);`，底层调用`i.intValue();`方法实现。

```java
Integer i  = 6;
Integer j = 6;
System.out.println(i==j);
```

答案在下面这段代码中找：

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210116125302.png" style="zoom:60%;" />

##### 二者的区别：

1. 声明方式不同：基本类型不使用new关键字，而包装类型需要使用new关键字来在**堆中分配存储空间**；
2. 存储方式及位置不同：基本类型是直接将变量值存储在栈中，而包装类型是将对象放在堆中，然后通过引用来使用；
3. 初始值不同：基本类型的初始值如int为0，boolean为false，而包装类型的初始值为null；
4. 使用方式不同：基本类型直接赋值直接使用就好，而包装类型在集合如Collection、Map时会使用到。

##### 2、final、static、this、super关键字讲一下？

* **final**：final用于修饰类、成员变量和成员方法。final修饰的类，不能被继承（String、StringBuilder、StringBuffer、Math，不可变类），其中所有的方法都不能被重写(这里需要注意的是不能被重写，但是可以被重载)，所以不能同时用abstract和final修饰类（abstract修饰的类是抽象类，抽象类是用于被子类继承的，和final起相反的作用）；final修饰的方法不能被重写，但是子类可以用父类中final修饰的方法；Final修饰的成员变量是不可变的，如果成员变量是基本数据类型，初始化之后成员变量的值不能被改变，如果成员变量是引用类型，那么它只能指向初始化时指向的那个对象，不能再指向别的对象，但是对象当中的内容是允许改变的。

* **static**：static用于修饰类、成员方法、成员变量，另外可以编写static代码块来优化程序性能。 

	**成员方法**：static修饰的方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都必须依赖具体的对象才能够被调用。

	**成员变量**：static修饰的变量也称为静态变量，静态变量和非静态变量的区别是：静态变量被所有对象共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。另外如果一个成员变量被static和final同时修饰的话，那么这就是个常量了，将会在方法区中给他开辟空间。

	**static代码块**：static关键字还有一个比较重要的作用就是用来形成静态代码块以优化程序性能。static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来依次执行每个static块，并且只会执行一次。

##### 3、final、finally、finalize有什么区别？

* **final**：final是一个修饰符，具体参考`final、static、this、super关键字讲一下？`
* **finally**：一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。
* **finalize**：Object类的一个方法，而Object类是所有类的父类，该方法一般由垃圾回收器来调用，一般调用时机不确定，程序员无法控制这个方法的执行。

##### 4、String、StringBuffer、StringBuilder的区别？

**数据可变和不可变**

* `String`底层使用一个不可变的字符数组`private final char value[];`所以它内容不可变。
* `StringBuffer`和`StringBuilder`都继承了`AbstractStringBuilder`底层使用的是可变字符数组：`char[] value;`

**线程安全**

- `StringBuilder`是线程不安全的，效率较高；而`StringBuffer`是线程安全的，效率较低。通过他们的`append()`方法来看，`StringBuffer`是有同步锁，而`StringBuilder`没有

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210116130209.png" style="zoom:70%;" />

##### 3. 相同点

`StringBuilder`与`StringBuffer`有公共父类`AbstractStringBuilder`。

最后，操作可变字符串速度：`StringBuilder > StringBuffer > String`

##### 5、equals方法重写时为什么一定要重写hashCode方法？

首先明确的是这两个方法都是Object类中的方法，因此每个Java对象中都有着两个方法，

**首先解释一下hashCode方法的作用：**

通过调用对象的hashCode方法，可以得到该对象的hashCode值。对象的hashCode值默认为是其本身属性经哈希函数变换后得到的一个值，**这个值并不等于该对象的内存地址，但决定了该对象内存地址的分配**。因此，不同引用地址的对象的hashCode值绝对是不相等的，除非发生了极小概率的哈希碰撞情况。

**equals**

在Object类源码中，其底层是使用了“==”来实现，也就是说通过比较两个对象的内存地址是否相同判断是否是同一个对象。但是在实际应用中，该方法不能满足的我们的需求。因为我们认为两个对象即使不是指向的同一块内存，只要这两个对象的各个字段属性值都相同，那么就认为这两个对象是同一个对象。**所以就需要重写equals（）方法，即如果两个对象指向内存地址相同或者两个对象各个字段值相同，那么就是同一个对象。**

两者有关系如下：

1. **如果两个对象equals比较返回true，那么它们的hashCode值一定要相同；**
2. **如果两个对象equals比较返回false，那么它们的hashCode值可能相同也可能不同；**
3. **如果两个对象的hashCode相同（存在哈希冲突），那么它们可能相同也可能不同(即equals比较可能是false也可能是true)**
4. **如果两个对象的hashCode不同，那么他们肯定不同(即用equals比较返回false)**

**为什么官方建议我们重写equals后替丁要重写hashCode呢？**

对于对象集合的判重，如果一个集合含有10000个对象实例，仅仅使用equals()方法的话，那么对于一个对象判重就需要比较10000次，随着集合规模的增大，时间开销是很大的。但是同时使用哈希表的话，就能快速定位到对象的大概存储位置，并且在定位到大概存储位置后，后续比较过程中，如果两个对象的hashCode不相同，也不再需要调用equals（）方法，从而大大减少了equals()比较次数。
所以从程序实现原理上来讲的话，既需要equals()方法，也需要hashCode()方法。那么既然重写了equals（），那么也要重写hashCode()方法，以保证两者之间的配合关系。

其实这个问题应该是有个前提，就是你需要用到HashMap,HashSet等Java集合。用不到哈希表的话，其实仅仅重写equals()方法也可以吧。而工作中的场景是常常用到Java集合，所以Java官方建议 重写equals()就一定要重写hashCode()方法。

##### 6、==和equals方法的区别？

- `==`比较的是两个引用在内存中指向的是不是同一对象（即同一内存空间），也就是说在内存空间中的存储位置是否一致。如果两个对象的引用相同时（指向同一对象时），“==”操作符返回true，否则返回flase。
- `equals`是Object中的一个方法，在没有被重写时他的作用和`==`的作用类似，但是重写后一般用来比较**某些特征**是否一样。我们平时用的String类等的equals方法都是重写后的，实现比较两个对象的内容是否相等。

我们来看看String重写的equals方法：它不止判断了内存地址，还增加了字符串是否相同的比较

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210116125900.png" style="zoom:40%;" />



##### 7、接口和抽象类的区别？

**抽象类**：在Java中被abstract关键字修饰的类称为抽象类，被abstract关键字修饰的方法称为抽象方法，抽象方法只有方法的声明，没有方法体。抽象类的特点：

a、抽象类不能被实例化只能被继承；

b、包含抽象方法的一定是抽象类，但是抽象类不一定含有抽象方法；

c、抽象类中的抽象方法的修饰符只能为public或者protected，默认为public；

d、一个子类继承一个抽象类，则子类必须实现父类抽象方法，否则子类也必须定义为抽象类；

e、抽象类可以包含属性、方法、构造方法，但是构造方法不能用于实例化，主要用途是被子类调用。

**接口：**Java中接口使用interface关键字修饰，特点为:

a、接口可以包含变量、方法；变量被隐士指定为public static final，方法被隐士指定为public abstract（JDK1.8之前）；

b、接口支持多继承，即一个接口可以extends多个接口，间接的解决了Java中类的单继承问题；

c、一个类可以实现多个接口；

d、JDK1.8中对接口增加了新的特性：（1）、默认方法（default method），即接口中可以有方法实现了：JDK 1.8允许给接口添加非抽象的方法实现，但必须使用default关键字修饰；定义了default的方法可以不被实现子类所实现，但只能被实现子类的对象调用；**如果子类实现了多个接口，并且这些接口包含一样的默认方法，则子类必须重写默认方法**；（2）、静态方法（static method）：JDK 1.8中允许使用static关键字修饰一个方法，并提供实现，称为接口静态方法。**接口静态方法只能通过接口调用**（接口名.静态方法名）。

##### 8、JDK，JRE，JVM之间的关系？

仅从传统意义上来看，Sun定义的Java技术体系包括：**Java程序设计语言**、**各种平台上的JVM**、**Class文件格式**、**Java API类库**、**来自商业机构和开源社区的第三方Java类库**。

- **JDK**全程为Java SE Development Kit（Java开发工具），是用于支持Java程序开发的最小环境，提供了编译和运行Java程序所需的各种资源和工具，包括：Java程序设计语言，Java API类库，JVM。
- **JRE**全称为Java runtime environment（Java运行环境），是支持Java程序运行的最小环境，包括：Java API类库中的SE API子集，JVM。
- **JVM**是运行Java程序的核心虚拟机，是Java环境的最底层部分，一般和OS打交道。

他们的关系可以用下图表示：

<img src="http://image.easyblog.top/1581233669380d5428dc2-ef36-4b0b-b287-59a715e2f3b7.jpg" alt="img" style="zoom:67%;" />



##### 9、深拷贝和浅拷贝

深拷贝增加了一个指针指向已存在的内存地址。

浅拷贝增加了一个指针并且申请了一个新的内存，并使指针指向新的内存。

深拷贝和浅拷贝的根本区别在于：是否真正获取了一个对象的复制实体，而不是引用。

##### 10、Java中为什么要有泛型？

##### 什么是泛型？

**Java泛型设计原则：只要在编译时期没有出现警告，那么运行时期就不会出现ClassCastException异常**.

泛型：**把类型明确的工作推迟到创建对象或调用方法的时候才去明确的特殊的类型**

参数化类型:

- **把类型当作是参数一样传递**
- **`<数据类型>`只能是引用类型**

相关术语：

- `ArrayList<E>`中的**E称为类型参数变量**
- `ArrayList<Integer>`中的**Integer称为实际类型参数**
- **整个称为`ArrayList<E>`泛型类型**
- **整个`ArrayList<Integer>`称为参数化的类型ParameterizedType**

##### 为什么需要泛型

**早期Java是使用Object来代表任意类型的，但是向下转型有强转的问题，这样程序就不太安全**

首先，我们来试想一下：没有泛型，集合会怎么样

- Collection、Map集合对元素的类型是没有任何限制的。**本来我的Collection集合装载的是全部的Dog对象，但是外边把Cat对象存储到集合中，是没有任何语法错误的。**
- 把对象扔进集合中，集合是不知道元素的类型是什么的，仅仅知道是Object。因此在get()的时候，返回的是Object。**外边获取该对象，还需要强制转换**

有了泛型以后：

- 代码更加简洁【不用强制转换】
- 程序更加健壮【只要编译时期没有警告，那么运行时期就不会出现ClassCastException异常】
- 可读性和稳定性【在编写集合的时候，就限定了类型】

##### 11、方法覆盖（重写）和方法重载的区别？

**重写**

在重写方法时，需要遵循以下的规则： 
(一) **父类方法的参数列表必须完全与被子类重写的方法的参数列表相同，否则不能称其为重写而是重载。**
(二) **父类的返回类型必须与被子类重写的方法返回类型相同，否则不能称其为重写而是重载。**
(三)**被子类重写的方法不能拥有比父类方法更加严格的访问权限。**编写过Java程序的人就知道，父类中的方法并不是在任何情况下都可以重写的，当父类中方法的访问权限修饰符为private时，该方法只能被自己的类访问，不能被外部的类访问，在子类是不能被重写的。如果定义父类的方法为public，在子类定义为private，程序运行时就会报错。

(四)**父类的访问权限修饰符的限制一定要大于被子类重写方法的访问权限修饰符**。所以如果某一个方法在父类中的访问权限是private，那么就不能在子类中对其进行重写。如果重新定义，也只是定义了一个新的方法，不会达到重写的效果。
(五) **在继承过程中如果父类当中的方法抛出异常，那么在子类中重写父类的该方法时，也要抛出异常，而且抛出的异常不能多于父类中抛出的异常(可以等于父类中抛出的异常)。**

**重载**

方法重载是让类以统一的方式处理不同类型数据的一种手段。调用方法时通过传递给它们的不同个数和类型的参数来决定具体使用哪个方法，这就是**多态性**。所谓方法重载是指在一个类中，多个方法的方法名相同，但是参数列表不同。参数列表不同指的是参数个数、参数类型或者参数的顺序不同。

方法的重载在实际应用中也会经常用到。不仅是一般的方法，构造方法也可以重载。在方法重载时，方法之间需要存在一定的联系，因为这样可以提高程序的可读性，一般只重载功能相似的方法。

重载是指我们可以定义一些名称相同的方法，通过定义不同的参数来区分这些方法，然后再调用时，Java虚拟机就会根据不同的参数列表来选择合适的方法执行。也就是说，当一个重载方法被调用时，Java用参数的类型或个数来决定实际调用的重载方法。因此，每个重载方法的参数的类型或个数必须是不同。虽然每个重载方法可以有不同的返回类型，但**返回类型并不足以区分所使用的是哪个方法**。

综上，在使用重载要注意以下的几点:

* 1）**在使用重载时只能通过不同的参数列表，必须具有不同的参数列表**。
* 2）**不能通过访问权限、返回类型、抛出的异常进行重载。**
* 3）**方法的异常类型和数目不会对重载造成影响。**
* 4）**可以有不同的返回类型，只要参数列表不同就可以了。**
* 5）**可以有不同的访问修饰符**。
* 6）**可以抛出不同的异常**。



综上，方法重载和方法重写区别如下图所示：

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210120141248.png" style="zoom:67%;" />



##### 12、Java类初始化顺序？

<img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Faliyunzixunbucket.oss-cn-beijing.aliyuncs.com%2Fjpg%2F64d2aa3bc68e73d79bf9dfe5ef52946f.jpg%3Fx-oss-process%3Dimage%2Fresize%2Cp_100%2Fauto-orient%2C1%2Fquality%2Cq_90%2Fformat%2Cjpg%2Fwatermark%2Cimage_eXVuY2VzaGk%3D%2Ct_100&refer=http%3A%2F%2Faliyunzixunbucket.oss-cn-beijing.aliyuncs.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1613725740&t=e6f3cab774478c06a19432cabb129a05" alt="img" style="zoom:80%;" />



##### 13、面向对象三大特性

面向对象的三大特征是**封装，继承，多态**。

**封装**

将类的某些信息隐藏在类内部，不允许外部程序直接访问，而是通过该类提供的方法来实现对隐藏信息的操作和访问。

好处：**1）只能通过规定的方法访问数据；2）隐藏类的实例细节，方便修改和实现。**　

封装实现步骤：

<img src="https://images2015.cnblogs.com/blog/1189312/201706/1189312-20170630170717493-357592353.png" alt="img" style="zoom:67%;" />

* 1）**将成员属性使用private修饰**
* 2）**给每个属性提供get/set方法**
* 3）**在get/set方法中加入属性访问控制语句**

**扩展**

**a. Java中的访问修饰符**

<img src="https://images2015.cnblogs.com/blog/1189312/201706/1189312-20170630174919274-1857293801.png" alt="img" style="zoom:67%;" />

**b. this关键字**

* 1）this关键字**代表当前对象**  this.属性 操作当前对象的属性；this.方法 调用当前对象的方法。

* 2）封装对象的属性的时候，经常会使用this关键字。

* 3）当get/set方法的参数名和成员变量名重合的时候，可以使用this区别。this就表示类中的成员变量，如：

	<img src="https://images2015.cnblogs.com/blog/1189312/201706/1189312-20170630180217524-833886832.png" alt="img" style="zoom:67%;" />

**继承**

继承是类与类的一种关系，是一种“is a”的关系。比如“狗”继承“动物”，这里动物类是狗类的父类或者基类，狗类是动物类的子类或者派生类。Java继承有如下特性：

* 1）Java中的继承是**单继承**，即**一个类只有一个父类。**

	为什么这么设计？（被问过）答：

	* 1）**为了防止二义性（钻石形继承问题）**；考虑一个类 A 有 foo() 方法, 然后 B 和 C 派生自 A, 并且有自己的 foo() 实现，现在 D 类使用多个继承派生自 B 和C，如果我们只引用 foo(), 编译器将无法决定它应该调用哪个 foo()。这也称为 Diamond 问题，因为这个继承方案的结构类似于菱形，见下图:

		<img src="https://img-blog.csdnimg.cn/img_convert/684f039340b04aafd595e094c8f1a7dc.png" alt="684f039340b04aafd595e094c8f1a7dc.png" style="zoom:67%;" />

	* 2）第二个也是更有说服力的理由是，**多重继承确实使设计复杂化并在强制转换、构造函数链接等过程中产生问题**

* 2）继承是单方向的，即派生类可以继承和访问基类中的成员 ，但基类则无法访问派生类中的成员。

* 3）派生类有父类的全部成员和方法（包括private修饰的），只是private修饰的子类无法访问。

* 4）子类可以重写父类的方法，也可以实现自己的方法。

**多态**

多态性指的是： 同一操作作用与不同类的实例，将产生不同的执行结果，即不同类的对象收到相同的消息时，将得到不同的结果。一句话总结就是：**事物在运行过程中存在不同的状态**。

**多态的存在有三个前提**:

* **1）要有继承关系**
* **2）子类要重写父类的方法**
* **3）父类引用指向子类**

**多态情况下成员访问的特点**：

* 1）**成员变量：编译看左边(父类),运行看左边(父类)**
* 2）**成员方法：编译看左边(父类)，运行看右边(子类)。动态绑定**
* 3）**静态方法：编译看左边(父类)，运行看左边(父类)。**

**多态的弊端**：**对象无法使用子类特有的成员属性和子类特有的成员方法。**

##### 14、多态的实现原理？

多态是面向对象编程语言的重要特性，它允许基类的指针或引用指向派生类的对象，而在具体访问时实现方法的动态绑定。**Java 对于方法调用动态绑定的实现主要依赖于方法表，但通过类引用调用(invokevitual)和接口引用调用(invokeinterface)的实现则有所不同**。

**方法表是实现动态调用的核心**。上面讲过方法表存放在方法区中的类型信息中。为了优化对象调用方法的速度，方法区的类型信息会增加一个指针，该指针指向一个记录该类方法的方法表，方法表中的每一个项都是对应方法的指针。这些方法中包括从父类继承的所有方法以及自身重写（override）的方法。

**Java** **的方法调用方式**

Java 的方法调用有两类，动态方法调用与静态方法调用。

- **静态方法调用是指对于类的静态方法的调用方式，是静态绑定的**
- **动态方法调用需要有方法调用所作用的对象，是动态绑定的。**

类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。

实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，也是多态要解决的核心问题。

JVM 的方法调用指令有四个，分别是 **invokestatic，invokespecial，invokesvirtual 和 invokeinterface**。前两个是静态绑定，后两个是动态绑定的。

##### 15、什么是内存泄漏？Java中存在内存泄漏吗？

内存泄露，广义并通俗的说，就是：**不再会被使用的对象的内存不能被回收，就是内存泄露。如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露。**

Java中存在内存泄漏，而且Java中导致内存泄露的原因很明确：**长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景**。

一般Java中造成内存泄漏的场景有以下几种：

* 1）**单例模式**。不正确使用[单例模式](https://www.baidu.com/s?wd=单例模式&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)是引起内存泄露的一个常见问题，单例对象在被初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部对象的引用，那么这个外部对象将不能被jvm正常回收，导致内存泄露。

	解决办法：最大限度的减少静态变量的使用；单例模式时，依赖于延迟加载对象而不是立即加载方式。

* 2）**各种连接，如数据库连接、网络连接和IO连接等**。在对数据库进行操作的过程中，首先需要建立与数据库的连接，当不再使用时，需要调用close方法来释放与数据库的连接。只有连接被关闭后，垃圾回收器才会回收对应的对象。否则，如果在访问数据库的过程中，对Connection、Statement或ResultSet不显性地关闭，将会造成大量的对象无法被回收，从而引起内存泄漏。

	解决办法：使用finally块关闭资源；关闭资源的代码，不应该有异常；jdk1.7后，可以使用try-with-resource块

* 3）**引用了外部类的内部类**。非静态内部内的初始化，总是需要外部类的实例；默认情况下，每个非静态内部类都包含对其包含内的隐式引用，如果我们在应用程序中使用这个内部类对象，那么即使在我们的包含类对象超出范围后，它也不会被垃圾收集。

	解决办法：如果内部类不需要访问包含的类成员，考虑转换为静态类。

* 4）**集合类**，如HashMap、LinkedList等等。如果这些容器为静态的，那么它们的生命周期与程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。简单而言，长生命周期的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但是因为长生命周期对象持有它的引用而导致不能被回收。

* 5）**常量字符串造成的内存泄露**。如果我们读取一个很大的String对象，并调用了inter(），那么它将放到字符串池中，位于PermGen中，只要应用程序运行，该字符串就会保留，这就会占用内存，可能造成OOM。

	解决办法：增加PermGen的大小，-XX:MaxPermSize=512m；升级Java版本，JDK1.7后字符串池转移到了堆中。

* 6）**不正确使用ThreadLocal造成内存泄露**。使用ThreadLocal时，每个线程只要处于存货状态就可保留对其ThreadLocal变量副本的隐式调用，且将保留其自己的副本。使用不当，就会引起内存泄露。

	一旦线程不在存在，ThreadLocals就应该被垃圾收集，而现在线程的创建都是使用线程池，线程池有线程重用的功能，因此线程就不会被垃圾回收器回收。所以使用到ThreadLocals来保留线程池中线程的变量副本时，ThreadLocals没有显示的删除时，就会一直保留在内存中，不会被垃圾回收。

	解决办法：不在使用ThreadLocal时，调用remove()方法，该方法删除了此变量的当前线程值。不要使用ThreadLocal.set(null)，它只是查找与当前线程关联的Map并将键值对设置为当前线程为null。

##### 16、讲一下Java的异常体系？

异常(Exception)是Java语言提出的一种**错误报告模型**，这种错误报告模型在程序和客户端之间传递异常问题。**使用异常处理(错误报告模型)的好处显而易见**：

- **无论何时，代码都能可靠运行，即使发生异常，程序也能执行而不是停止**；
- **异常处理使代码的阅读、编写和调试工作更加方便**。试想一下，如果一个方法内部会发生异常而没有对异常进行处理，那么调用方法的每个地方都需要格外小心，而如果我在发生异常的方法内部把异常处理掉，那么调用方法的地方就不需要担心是否会发生异常了，这进一步简化了代码的复杂度。

**异常的种类**

<img src="http://img.blog.csdn.net/20160331115514210" alt="img" style="zoom:67%;" />

Java把异常作为一种类，当做对象来处理。所有异常类的基类是**Throwable**类，两大子类分别是**Error**和**Exception**。

* **Error**：**由于Java程序导致JVM发生错误的错误用Error对象来表示**。这种情况仅凭程序自身是无法处理的，在程序中也不会对Error异常进行捕捉和抛出
* **Exception：有Java程序在编译或执行过程中产生的错误用Exception对象表示**

**RuntimeException&CheckedException**

异常（Exception）又分为RuntimeException(运行时异常)和CheckedException(检查时异常)，两者区别如下：

- RuntimeException：程序运行过程中才可能发生的异常。一般为代码的逻辑错误。例如：类型错误转换，数组下标访问越界，空指针异常、找不到指定类等等。常见的运行时异常有：**NullPointerException、ArrayIndexOutOfBoundException、UnkownTypeException、IllegalArgumentException、ClassNotFountException、ArrithmeticException**等
- CheckedException：编译期间可以检查到的异常，必须显式的进行处理（捕获或者抛出到上一层）。例如：IOException, FileNotFoundException等等。

**异常的处理**

**常用关键字：try、catch、throw（抛出一个异常，动词）、throws（声明一个方法可能抛出的异常）、finally。**

* 1）**throws（声明异常）**若方法中存在检查时异常，如果不对其捕获，那必须在方法签名中显式声明该异常，以便于告知方法调用者此方法有异常，需要进行处理。若声明多个异常，则使用逗号分割。

* 2）**try-catch（捕获异常）**若执行try块的过程中没有发生异常，则跳过catch子句。若是出现异常，try块中剩余语句不再执行。开始逐步检查catch块，判断catch块的异常类实例是否是捕获的异常类型。匹配后执行相应的catch块中的代码。如果异常没有在当前的方法中被捕获，就会被传递给该方法的调用者。这个过程一直重复，直到异常被捕获或被传给main方法（交给JVM来捕获）。

	try-ctach-fianally 中有return 时，会先执行return ，但是不会返回。在执行完 finally 后 进行返回。

	* return 的是基本类型数据时， fianlly 里面的语句不会影响 return 的值，
	* return 的是引用类型数据时，此时已经确定了要返回对象的地址（地址一），后面 fianlly 里面的可以通过修改前面地址一中的内容修改返回的内容，但是如果将对象指向另一个地址（地址二），则不会影响返回的内容。因为返回的对象地址已经确定为地址一，只能通过修改地址一对象的内容修改返回的信息。 

	* 3）**throw（抛出一个异常，动词）** throw关键字是用于方法体内部，用来抛出一个Throwable类型的异常。如果抛出了检查异常，则还应该在方法头部声明方法可能抛出的异常类型。该方法的调用者也必须检查处理抛出的异常。如果所有方法都层层上抛获取的异常，最终JVM会进行处理，处理也很简单，就是打印异常消息和堆栈信息。

##### 17、反射了解吗？有哪些应用场景？

**反射机制是指在程序运行过程中，对任意一个类都能获取其所有属性和方法，并且对任意一个对象都能调用其任意一个属性和方法。这种动态获取类和对象的信息，以及动态调用对象的方法的功能被称为Java语言的反射机制。**

在程序运行期间，Java运行时系统始终为所有对象维护一个运行时类型标识，这个信息会跟踪每个对象所属的类，虚拟机利用运行时类型信息选择要执行的正确方法。也可以使用一个特殊的Java类方法这些信息，保存这些信息的类名为Class。

**获取Class对象的三种方法**

- 使用Object类中的**getClass()**方法，该方法返回一个Class类型的实例。
- 使用静态方法**Class.forName(String className)**获得类名对应的Class对象。
- 如果T是Java类型，**T.class**将代表匹配的类对象。

**Member**

对于Member接口可能会有人不清楚是干什么的，但如果提到实现它的三个实现类，估计用过反射的人都能知道。我们知道类成员主要包括**构造函数，变量和方法**，Java中的操作基本都和这三者相关，而Member的这三个实现类就分别对应他们。

[java.lang.reflect.Field](https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Field.html) ：对应类变量
 [java.lang.reflect.Method](https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Method.html) ：对应类方法
 [java.lang.reflect.Constructor](https://docs.oracle.com/javase/8/docs/api/java/lang/reflect/Constructor.html) ：对应类构造函数

反射就是通过这三个类才能在运行时改变对象状态。下面就让我们通过一些例子来说明如何通过反射操作它们。

* **Field**：通过Field可以访问给定对象的类变量，包括获取变量的类型、修饰符、注解、变量名、变量的值或者重新设置变量值，即使变量是private的。
* **Method**：通过Method可以访问有关类的方法的修饰符，返回类型，参数，注释和引发的异常的信息。 它还可用于调用方法。
* **Constructor**：构造方法的名称、限定符、参数、声明的异常等获取方法都与Method类似，请参照Method

**反射的缺点**

没有任何一项技术是十全十美的，Java反射拥有强大功能的同时也带来了一些副作用。

- **性能开销**
	 反射涉及类型动态解析，所以JVM无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。
- **安全限制**
	 使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如Applet，那么这就是个问题了。
- **内部曝光**
	 由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用—代码有功能上的错误，降低可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。

##### 18、jdk动态代理的原理？

不同于静态代理直接创建一个代理类，动态代理是通过JDK的**Proxy类**和一个调用处理器**InvocationHandler接口**来实现的，**通过Proxy来生成代理类实例，而这个代理实例通过调用处理器InvocationHandler接收不同的参数灵活调用真实对象的方法**。

 所以我们使用jdk动态代理核心的工作就是创建调用处理器**InvocationHandler**的实现类。

**InvocationHandler接口**

InvocationHandler 内部只是一个 invoke() 方法，正是这个方法决定了怎么样处理代理传递过来的方法调用。

##### 19、Arrays.sort()的实现？

##### 20、Java8有哪些新特性？

(1)Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性。Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。使用Lambda 表达式可以使代码变的更加简洁紧凑。

(2) 方法引用通过方法的名字来指向一个方法。方法引用可以使语言的构造更紧凑简洁，减少冗余代码。方法引用使用一对冒号 :: 。

(3) 函数式接口(FunctionalInterface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。函数式接口可以被隐式转换为lambda表达式。函数式接口可以现有的函数友好地支持 lambda。

(4) Java 8 新增了接口的默认方法。简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。我们只需在方法名前面加个default关键字即可实现默认方法。

(5) Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。Stream使用一种类似用SQL语句从数据库查询数据的直观方式来提供一种对Java集合运算和表达的高阶抽象。Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。

(6) Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。Optional 类的引入很好的解决空指针异常。

(7) jjs是个基于Nashorn引擎的命令行工具。它接受一些JavaScript源代码为参数，并且执行这些源代码。

(8) Java 8通过发布新的Date-Time API (JSR 310)来进一步加强对日期与时间的处理。

(9) 在Java8中，Base64编码已经成为Java类库的标准。Java 8 内置了 Base64 编码的编码器和解码器。

##### 21、Java创建对象的几种方式？

Java中创建对象的5种方式

* 1）**用new语句创建对象，这是最常见的创建对象的方法。**
* 2）**运用反射手段,调用java.lang.Class或者java.lang.reflect.Constructor类的newInstance()实例方法。**
* 3）**调用对象的clone()方法。**
* 4）**运用反序列化手段，调用java.io.ObjectInputStream对象的 readObject()方法。**
* 5）**Unsafe中提供allocateInstance(Class clazz)方法**，这是一种非常规的创建对象的方法，仅通过Class对象就可以创建此类的实例对象，而且不需要调用其构造函数、初始化代码、JVM安全检查等。它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化，只需提类对象即可创建相应的对象。由于这种特性，allocateInstance在java.lang.invoke、Objenesis（提供绕过类构造器的对象生成方式）、Gson（反序列化时用到）中都有相应的应用。

##### 22、注解的原理？元注解？自定义注解？

**注解（Annotation）是代码中的特殊标记。这些标记可以在编译、类加载、运行时（对应Rentention三种级别）被读取，并执行相应的处理。**

**元注解**

元注解就是可以加解到注解上修饰注解的注解，它们是一种java的基本注解。Java提供的元标签有 **@Retention、@Documented、@Target、@Inherited、@Repeatable 5 个**。

* **@Rentention**：可以用于设置一个注解的生命周期，他的取值有以下3个：

	- **RetentionPolicy.SOURCE** 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽
	- **RetentionPolicy.CLASS** 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中
	- **RetentionPolicy.RUNTIME** 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。

	SOURCE和CLASS级别需要继承AbstractProcessor并实现process方法来寻找并处理自定义注解，RUNTIME是我们日常使用最多的，无需继承AbstractProcessor，配合Java反射机制就可以处理自定义注解。

* **@Documented**：能够将注解中的元素包含到 Javadoc 中去

* **@Target**：指定了注解运用的地方。当一个注解被 @Target 注解时，这个注解就被限定了运用的场景。比如**ElementType.ANNOTATION_TYPE**（在注解上使用）、**ElementType.FIELD**（在成员变量上使用）、**ElementType.METHOD**（在方法上使用）、**ElementType.TYPE**（在类、接口、枚举类等头上使用）等等

* **@Inherited**：如果一个超类被 @Inherited 注解过的注解进行注解的话，那么如果它的子类即使没有被任何注解修饰，那么这个子类也拥有超类的注解。

* **@Repeatable**：@Repeatable 是 Java 1.8 才加进来的，所以算是jdk1.8的一个新的特性。他的含义是说明这个注解可以在同一个Element上多次标记。



##### 23、Java I/O的种类？

<img src="https://img-blog.csdnimg.cn/20200620002834512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoYWRvd19fX2g=,size_16,color_FFFFFF,t_70" alt="å¨è¿éæå¥å¾çæè¿°" style="zoom:67%;" />

Java所有有关IO流的类如图所示，分为两大部分。

- **字节流**，读数据以字节为基本单位。(byte),当我们用记事本打开一个文件的时候，这个文件乱码，我们读不懂时候，这个文件就用字节流读取输入。处理二进制文件和数据
- **字符流**，读数据以字符为基本单位。（char）当我们用记事本打开一个文件的时候，我们读的懂，不乱码，一般使用字符流处理这个文件。处理文本文件和数据。

##### 扩展：Java IO流使用了哪些设计模式？

**适配器模式**:

**由于InputStream是字节流不能接受到字符流读取字符那么便捷的功能,因此借助 InputStreamReader将其转为Reader子类,因此可以拥有便捷操作文本文件方法。**

 **装饰者模式**:

**将InputStream字节流包装为BufferedReader过程就装饰的过程,一开始 InputStream只有read一个字节的方法,包装为Reader之后拥有read一个字符的功能,在包装BufferedReader之后就拥有read一行字符串功能。**

其实这个问题重点是回答你对设计模式的熟悉程度。

##### 24、怎么实现序列化和反序列化？

**什么是序列化？**

java序列化是指把java对象转换为字节序列的过程，而java反序列化是指把字节序列恢复为java对象的过程

* 1）序列化：对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。序列化后的字节流保存的java对象的状态以及相关的描述信息。序列化机制的核心作用就是对象状态的保存与重建。）

* 2）反序列化：客户端从文件中或网络上获得序列化后的对象字节流后，根据字节流中所保存的对象状态及描述信息，通过反序列化重建对象。

**序列化的好处**

* 1）永久性保存对象，保存对象的字节序列到本地文件或者数据库中，实现了数据的持久化，通过序列化可以把数据永久的保存到硬盘上，

* 2）利用序列化实现远程通信，可以在网络上传送对象的字节序列。

* 3）在进程间传递对象

**Java 如何实现序列化和反序列化**

Java序列化和反序列化数据，是通过**ObjectOutputStream**和**ObjectInputStream**这两个类来实现的，并且只有实现了**Serializable或Externalizable接口**的对象才能被序列化，否则抛出异常！

* **java.io.ObjectOutputStream**: 表示输出对象流。它的writeObject(Object obj)方法可以对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中；

* **java.io.ObjectInputStream**:表示对象输入流。它的readObject()方法源输入流中读取字节序列，再把它们反序列化成为一个对象，并将其返回

**JDK类库中序列化的步骤**

（1）创建一个对象输出流，它可以包装一个奇特类型的目标输出流，如文件输出流：

objectOutputStream oos=new objectOutputStream(new FileOutStream(c:\\object.out));

（2）通过对象输出流writeObject()方法写对象：

oos.writeObject(new a("xiaoxiao","145263","female"));

 

**JDK类库中反序列化的步骤**

（1）创建一个对象输入流，它可以包装一个其他类型输入流，如文件输入流：

objectInputStream ois=new ObjectInputStream(new FileInputStream("object.out"));

（2）通过对象输出流的readObject()方法读取对象：

a aa=(a)ois.readObject();

（3）为了正确读数据，完成反序列化，必须保证向对象输出流写对象的顺序与从对象输入流中读对象的顺序一致

##### 25、Object类中的方法有哪些，讲一下作用？

（1）clone方法

保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。

主要是JAVA里除了8种基本类型传参数是值传递，其他的类对象传参数都是引用传递，我们有时候不希望在方法里讲参数改变，这是就需要在类中复写clone方法。

（2）getClass方法

final方法，获得运行时类型。

（3）toString方法

该方法用得比较多，一般子类都有覆盖。

（4）finalize方法

该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。

（5）equals方法

该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。

（6）hashCode方法

该方法用于哈希查找，可以减少在查找中使用equals的次数，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。

一般必须满足obj1.equals(obj2)==true。可以推出obj1.hash- Code()==obj2.hashCode()，但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。

如果不重写hashcode(),在HashSet中添加两个equals的对象，会将两个对象都加入进去。

（7）wait方法

wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。

调用该方法后当前线程进入睡眠状态，直到以下事件发生。

（1）其他线程调用了该对象的notify方法。

（2）其他线程调用了该对象的notifyAll方法。

（3）其他线程调用了interrupt中断该线程。

（4）时间间隔到了。

此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。

（8）notify方法

该方法唤醒在该对象上等待的某个线程。

（9）notifyAll方法

该方法唤醒在该对象上等待的所有线程。

##### 26、为什么匿名内部类访问局部变量时，局部变量要加final关键字

为了确保数据一致性，因为内部类访问局部变量时，是拷贝局部变量的值，而不是引用。添加final关键字后这个引用变量的地址值不会发生变化，所以这个引用变量就不会再指向其他对象了（一直会复制这个对象的值，数据一致性就有保证了）。

#### Java集合

##### 1、List、Set、Map三者的区别？

Java 容器分为 Collection 和 Map 两大类，Collection集合的子接口有Set、List、Queue三种子接口。我们比较常用的是Set、List，Map接口不是Collection的子接口。

Collection集合主要有List和Set两大接口

* **List**：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有 ArrayList、LinkedList 和 Vector。
* **Set**：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性。Set 接口常用实现类是 HashSet、LinkedHashSet 以及 TreeSet。

Map是一个键值对集合，存储键、值和之间的映射。Key无序，唯一；value 不要求有序，允许重复。Map没有继承于Collection接口，从Map集合中检索元素时，只要给出键对象，就会返回对应的值对象。

##### 2、ArrayList和LinkedList的区别？

1、ArrayList的实现是基于数组（可以动态扩容的数组），LinkedList的实现是基于双向链表。

2、对于随机访问，ArrayList优于LinkedList

3、对于插入和删除操作，LinkedList优于ArrayList

4、LinkedList比ArrayList更占内存，因为LinkedList的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。的效率更高，因为ArrayList是数组，所以在其中进行增删操作时，会对操作点之后所有数据的下标索引造成影响，需要进行数据的移动。

##### 3、HashMap的原理讲一下（初始化、put方法、get方法、扩容方法、红黑树、1.8做了哪些优化）

**jdk1.7及以前采用的存储结构是采用了数组+链表，jdk1.8的存储结构是数组+链表+红黑树**

在jdk1.7以前HashMap的底层数据结构是**数组+链表**的存储结构：

<img src="http://image.easyblog.top/1586849928362f35d5a18-44eb-4977-8fbd-e798979df482.png" alt="img" style="zoom:40%;" />

在jdk1.8以后采用了**数组+链表+红黑树**的存储结构：

<img src="http://image.easyblog.top/1586850016202043831b9-f1dd-40b6-8386-7f9d3561cb11.jpg" alt="img" style="zoom:20%;" />

HashMap的数组里存储着Key-Value这样的实例，在jdk1.7以前叫**Entry**，jdk1.8以后叫的**Node**，名字变了，但是本质一样。每一个节点都会保存自身的hash、key、value、以及下个节点，我看看Node的源码。

<img src="http://image.easyblog.top/1586941641344431b0c7b-89ad-4c38-9e4c-7ec7524d906a.png" alt="img" style="zoom:50%;" />

**HashMap的重要属性**

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121192225.png" style="zoom:50%;" />

**HashMap的构造方法和初始化**

<img src="C:\Users\Administrator\Pictures\QQ截图\QQ截图20210121190301.png" style="zoom:40%;" />

从HashMap的构造方法中可以看到，它并没有直接给HashMap分配hash桶数组的空间，而只是做了一下参数的检查、加载因子的赋值以及下一次扩容阈值的计算，真正的空间空间分配在第一次put值得时候由resize()方法实现的

**put()操作**

每次put操作都会检查hash桶数组是否为null，当第一次put的时候由于hash数组还未初始化，因此需要调用resize()方法执行初始化操作

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121191002.png" style="zoom:40%;" />

**resize()初始化操作**

resize()方法在jdk1.8中有两个用处：（1）初始化HashMap；（2）给HashMap进行扩容

下图所展示的代码就是初始化HashMap的逻辑，主要就是通过判断并计算得到各种情况下数组容量newCap、扩容阈值newThr之后直接new了一个Node数组

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121191147.png" style="zoom:55%;" />

**put操作**

<img src="http://image.easyblog.top/1595906622836ec54ae6a-5de9-4539-993b-ed0da8a52845.png" alt="img" style="zoom:40%;" />

putVal()方法的逻辑：

- （1）通过put()方法传入key-vlaue，并调用hash函数计算出key的hash值，jdk1.8中的hash函数是如果**key是null，那么hash=0**,即key为null的元素将存储在Hash表的第一个位置；否则**hash=(h=key.hashCode())^(h>>>16)**

	（2）调用到**putVal(...)**方法中，首先判断当前Hash表是否初始化了，如果没有初始化则会调用resize()方法执行初始化，否则进入下一步；

	（3）根据hash值计算出key-value键值对的槽位（**i=(n-1)&hash**），如果槽位table[i]还没有元素，那就直接新添加的key-value键值对实例化成Node添加到哈希表中；如果槽位table[i]已经有元素了，那就进入下一步；

	（4）如果发生了hash冲突，那就要还要判断此时处理冲突的情况是什么

	 - 如果哈希表中的key和待插入的新元素的key相等并且它们的equals()方法相等，那么就会执行元素值替换操作；
- 否则如果此时槽位已近变成了红黑树了，那就调用**putTreeValur()**把值插入到红黑树中
	
	- 若此时的数据结构是链表，从链表头遍历每个结点，如果key相等并且equals()方法相等那就执行值替换操作，否则执行尾插，在链表尾部插入新元素，插入之后判断链表的长度是否大于等于树化阈值8，如果达到了树化阈值将会调用treeifyBin()执行树化逻辑，最后能不能树化，还需要看当前哈希数组的长度是否大于最小树化容量64，如果达不到那就不会执行树化逻辑而是执行扩容逻辑；

**红黑树简单介绍**

红黑树（Red Black Tree）是一个**自平衡**的二叉查找树，但是每个节点上增加一个存储位表示**节点的颜色**（红色或黑色），红黑树的查找、删除、插入操作最坏的时间复杂度都可以达到O(lgn)。 红黑树除了符合二叉查找树的基本特性外，还具有以下几个特性：

1. **红黑树的结点是红色的或黑色的**；
2. **红黑树的根节点是黑色的**；
3. **叶子节点（NULL结点）都是黑色的**；
4. **每个红色节点的两个子节点都为黑色（红黑树不会出现相邻的红色节点）**；
5. **从任意节点出发，到其每个叶子节点的路径中包含相同数量的黑色节点**；
6. **新加入到红黑树的节点为红色节点**。

**get操作**

<img src="http://image.easyblog.top/1586925134687d1b7a20d-15bf-4dbc-9f31-b0e2cdc39b0f.png" alt="img" style="zoom:67%;" />

- 首先判断当前哈希表是否为空，如果为空直接返回null；
- 如果哈希表不空，就会计算key的桶位table[(n-1)&hash]，如果桶位为空还是会返回null；
- 如果哈希表不为空并且key在HashMap中存在，那就首先检查一下hash表中的这个元素是不是要找的值（判定的标准是equals方法返回true），如果是就直接返回vlaue,如果不是还会在判断一下是否存在后继结点，如果不存在直接返回null
- 如果存在后继结点，那么首先判断一下是红黑树还是链表，如果是红黑树那就到红黑树中取值，如果是链表那就从头开始遍历链表找到值后返回。

**resize()扩容操作**

HashMap扩容的触发是在插入元素之后，判断数组的使用大小如果大于了阈值，就会调用resize()进行扩容操作

<img src="http://image.easyblog.top/158692285801818d425f7-b84c-4e96-acbe-819797abefa5.png" alt="img" style="zoom:40%;" />

**核心逻辑：遍历老哈希表，没有元素的槽位不管，只处理有元素的槽位**；处理有元素的槽位的逻辑分为三大部分：

1）如果这个槽位没有后继结点了（没有形成链表），就重新计算元素移动到新的哈希表中位置并直接移动过去，重新计算桶位的算法还是：`e.hash&(newCap-1)`

2）如果槽位有后继结点并且已近树化了（已经是红黑树了），那就将红黑树拆分后，在新的哈希表中重新hash并散列到新的Node数组中

3）如果槽位有后继结点但是没有树化（已经是链表了），那就还是用尾插法把元素移动到新的哈希表中，需要注意的是：

- A：扩容后，**若e.hash&oldCap=0，那么元素在新hash数组的位置=原始位置(newTab[j] = loHead)**
- B：扩容后，**若hash&oldCap!=0，那么元素在新hash数组的位置=原始位置+旧数组大小( newTab[j + oldCap] = hiHead)**。



##### 4、HashMap链表转红黑树的条件是什么，为什么要这么设计？

触发转化的两个条件是：**一个是链表的长度达到8个，一个是数组的长度达到64个**

**链表的长度达到8个**

理想情况下使用随机的哈希码，容器中节点分布在hash桶中的频率遵循泊松分布(具体可以查看http://en.wikipedia.org/wiki/Poisson_distribution)，按照泊松分布的计算公式计算出了桶中元素个数和概率的对照表，可以看到链表中元素个数为8时的概率已经非常小，再多的就更少了，所以原作者在选择链表元素个数时选择了8，是根据概率统计而选择的

##### 5、多线程下HashMap put方法可能会发生的安全问题？

①JDK1.8之前，链表结点的插入使用头插法，在多线程操作的时候可能会产生链表死循环问题。②JDK1.8起，链表结点的插入改为尾插法，不会形成环，但是多线程操作时可能会存在值丢失的问题。

##### 6、ConcurrentHashMapde 实现原理？

**jdk1.7 ConcurrentHashMap**

jdk1.7 的ConcurrentHashMap的底层数据结构是**数组+链表**，ConcurrentHashMap是主要由**Segment**数组结构和 **HashEntry**数组结构组成。如下图所示。

<center>
    <img src="http://image.easyblog.top/159644773828433282a13-3339-454f-9b01-89cdea86b3b6.jpg" alt="img" style="zoom:80%;"/>
<img src="http://image.easyblog.top/15871165823029516dde5-34b4-4739-b145-7e673ab3189f.jpg" alt="img" style="zoom:80%;" />
</center>


整个ConcurrentHashMap 由一个个 **Segment** 组成，Segment 代表“部分” 或 “一段”的意思，所以很多地方都会将其描述为分段锁。

简单的理解，ConcurrentHashMap 是一个 Segment数组，Segment 通过继承 ReentrantLock来进行加锁，所以每次需要加锁的操作锁住的是一个 Segment，这样只要保证每个 Segment是线程安全的，也就实现了全局的线程安全性。每个Segment中维护了一个HashEntry数组，它用于存储键值对。

- **Segment继承了ReentrantLock，是一个可重入的锁，它在ConcurretnHashMap中扮演锁的角色**；
- **HashEntry则用于存储键值对**。它们之间的关系是：一个ConcurrentHashMap包含了一个Segment数组，一个Segment里维护了一个HashEntry数组，HashEntry数组和HashMap结构类似，是一种**数组+链表**的结构，当一个线程需要对HashEntry中的元素修改的时候，必须先获得Segment锁。



**Segment内部类**

首先先来熟悉一下Segment，Segment是ConcurrentHashMap的内部类，它在ConcurrentHashMap就是扮演锁的角色，主要组成如下：

<img src="http://image.easyblog.top/1596449481856c291c686-a3ec-4bf4-bb47-464da2d52590.png" alt="img" style="zoom:67%;" />

重要的即使那个HashEntry，HashEntry是一个和HashMap类似的数据结构，这里值的注意的是他被volatile修饰了。这里复习一下volatile的特性：

（1）可以保证共享变量在多线程之间的内存可见性，即一个线程修改了共享变量的值对于其他线程是这个修改后的是可见的；

（2）可以禁止指令重排序；

（3）volatile可以保证对单次读写操作的原子性；

这里使用volatile修饰HashEntry数组的目的当然是为了保证内存的可见性问题。为什么需要保证HashEntry数组的内存可见性呢？

在往下看源码就会发现，jdk1.7以前的CHM的get操作是不需要加锁的，即**可以并发的读**，只有在写数据的时候才需要加锁，因此为了保证不同线程之前对于一个共享变量的数据一致，使用volatile再好不过。

**初始化**

**initialCapacity**：初始容量，这个值指的是整个 ConcurrentHashMap的初始容量，实际操作的时候需要平均分给每个 Segment。

**loadFactor**：负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。

**concurrencyLevel**：并行级别、并发数、Segment 数。默认是16，也就是说 ConcurrentHashMap 默认有16个 Segment，所以理论上，最多同时支持16个线程并发写。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它就不可以扩容了。最大值受MAX_SEGMENTS控制，为65535个。

new ConcurrentHashMap()无参进行初始化以后：

（1）Segment数组的长度是16，并且segments[0]初始化了，其他segments[i]还是null，在使用之前需要调用ensureSegment()方法执行初始化

（2）segments[i]的默认大小是2，也即HashEntry的默认大小是2，负载因子为0.75，得出初始阈值为1.5，也就插入第一个元素不会触发扩容，插入第二个进行一次扩容。

**定位Segment**

ConcurrentHashMap使用了分段锁Segment来维护不同段的数据，那么在插入和获取元素的时候，必须先通过算法首先定位到Segment上之后才可以在具体的HashEntry用类似HashMap找元素的方法来定位一个元素。

**put()方法**

<img src="http://image.easyblog.top/1596464636809e8a0c99a-19f7-4b02-a40e-df25afb7672f.png" alt="img" style="zoom:67%;" />

**put流程梳理：** 

（1）首先检查value，如果value==null，抛出NPE；

（2）根据hash值定位到Segment，定位segments[j]的算法是：**j=(hash>>>sgmentShift)&sgmentMask**，其实j就是hash值的低4位

（3）获得到Segment后判断是否为null,如果是null，表示还没有初始化，那先调用ensureSegment()方法初始化Segment

（4）最后，调用Segment对象的put方法存入键值对。

* 4.1、首先通过父类ReentrantLock的tryLock()方法对每个Segment加锁，上锁成功之后继续执行，否则调用scanAndLockForPut()方法不断的调用tryLock()尝试获取锁，尝试的次数和CPU核数有关，单核CPU值尝试1次，多核CPU最多重试64次，如果重试结束还没有获取锁，那就阻塞等待锁； 
* 4.2、确定HashEntry[i]的下标。`index = (tab.length - 1) & hash`; 
* 4.3、如果当前HashEntry没有初始化，先初始化，并将键值对插入；
*  4.4、已经初始化，遍历HashEntry链，有重复的，新值覆盖旧值，否则，插入； 
* 4.5、**插入之后，判断是否需要扩容**，扩容：Segment[]是不能扩容的，只能扩容一个个Segment中的HashEntry[]的大小为原来的两倍

**get()方法**

<img src="http://image.easyblog.top/15965148764775c348927-bf62-4713-8a0f-d8685f5d8f24.png" alt="img" style="zoom:50%;" />

**get操作流程**： 

（1）计算 hash值，

（2）通过hash值找到 Segment数组中的下标。

（3）再次根据 hash 找到每Segment内部的 HashEntry[]数组的下标。

（4）遍历该数组位置处的链表，直到找到相等（内存地址相同或两个元素的hash值相同并且equals方法返回true）的 key。

get 是不需要加锁的：原因是get方法是将共享变量（table）定义为volatile，让被修饰的变量对多个线程可见(即其中一个线程对变量进行了修改，会同步到主内存，其他线程也能获取到最新值)，允许一写多读的作。

Segment的get操作实现非常简单和高效。**先经过一次hash()，然后使用散列值运算定位到Segment，在定位到聚义的元素的过程。**

get操作的高效是因为整个get操作不需要加锁，为什么他不需要加锁呢？是**因为get方法中使用的共享变量都被定义成了volatile类型**，比如：统计当前Segment大小的count，和用于存储key-value的HashEntry。定义成volatile的变量能够在多个线程之间保证内存可见性，如果与多个线程读，它读取到的值一定是当前这个变量的最新值。



**size()方法**

size()方法就是求当前ConcurrentHashMap中元素实际个数的方法，它是**弱一致性的**。方法的逻辑大致是：**首先他会使用不加锁的模式去尝试计算 ConcurrentHashMap 的 size，比较前后两次计算的结果，结果一致就认为当前没有元素加入或删除，计算的结果是准确的，然后返回此结果；如果尝试了三次之后结果还是不一致，它就会给每个 Segment 加上锁，然后计算 ConcurrentHashMap 的 size 返回。**

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121205801.png" style="zoom:50%;" />

**jdk1.8 ConcurrentHashMap**

JDK1.8的实现已经摒弃了Segment的概念，而是直接使用 **数组+链表+红黑树** 的数据结构来实现的，**并发控制使用的是CAS+synchronized**，jdk1.8版本的ConcurrentHashMap看起来就像是优化过之后线程安全的HashMap,虽然在JDK1.8中还能看到Segment的身影，但是已经简化了属性，只是为了兼容旧版本。下图是jdk1.8中ConcurrentHashMap的结构示意图：

<img src="http://image.easyblog.top/15964512103041ffc1840-4e2e-49d0-b0f8-2d94c2726d63.jpg" alt="img" style="zoom:67%;" />

**添加元素操作—put()**

**put()方法流程梳理：**

（1）首先我们通过源码看到，jdk1.8中ConcurrentHashMap不允许key或value为null，如果你违反了就会报NPE。

（2）之后获取到hash值，在之后会首先判断当前hash表是否被初始化了，因为jdk1.8中ConcurrentHashMap是懒惰初始化的，只有第一次put的时候才会初始化。初始化会调用initTable方法，该方法中使用CAS设置seizeCtl的值来保证线程安全。

（3）如果哈希表已经初始化了，然后计算key的哈希桶的位置，如果在这个位置还是null，那就直接使用CAS设置新节点到桶的这个位置即可；定位桶的算法还是**i=(tab.length-1)&hash**

（4）如果检查发现当前槽位的**头结点的hash值==-1**（标记为是ForwardingNode结点了），表示当前hash表正在扩容中，此时其他线程过去帮忙扩容;

（5）如果当前hash表存在、(n-1)&hash 位子有元素了并且没有在扩容，那就是发生了哈希冲突，解决冲突之前首先对链表的头结点/红黑树的root结点上锁

- 5.1、如果key的桶的位置还是链表，那就在链表的**尾部插入新的元素**，再次过程中还会统计链表的结点个数，存储在bitCount中，用于在插入之后判断是否需要扩容以及检查是否相同key的结点存在，如果存在那就执行值替换逻辑；
- 5.2、如果key的桶的位置已经是红黑树了，那就把新的元素插入红黑树中

（6）插入完毕之后会判断binCount的值是否已经大于等于树化阈值（TREEIFY_THRESHOLD=8）了，如果是，那就把链表转换为红黑树，不过最后转不转得成还要看哈希表的容量是不是大于MIN_TREEIFY_CAPACITY（64），如果没有达到只会扩容

**初始化哈希表—initTable()**

在put过程中如果是第一次put，此时hash表还没有初始化，因此需要首先初始化哈希表。初始化哈希表会调用initTable()方法，这个方法会使用CAS加锁，然后实例化一个hash表

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121203420.png" style="zoom:67%;" />

 **获取元素操作—get()**

get()方法没有加锁，即可以并发的读，敢这么做重要是因为Node数组被volatile被修饰了，volatile保证了共享变量在多线程下的内存可见性，即其他线程只要一修改Node数组中的数据，get操作的线程马上就可以知道修改的数据。

<img src="http://image.easyblog.top/15965397939966be09e6d-d8da-495f-b0ea-bc64c50fc780.png" alt="img" style="zoom:50%;" />

get()方法逻辑梳理：

（1）计算出key的hash值；

（2）根据 hash 值找到哈希槽的位置：**(n - 1) & hash**

（3）根据该位置处头节点的性质进行查找：

* 1）如果该位置为 null，那么直接返回 null 就可以了
* 2）如果该位置处的节点刚好就是我们需要的，返回该节点的值即可
* 3）如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面调用 find 接口，程序会根据上下文执行具体的方法。
* 4）如果以上 3 条都不满足，那就是链表，进行遍历比对即可

**获取元素的个数—size()**

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121203722.png" style="zoom:67%;" />

 **扩容操作—transfer()**

扩容的逻辑比较复杂，这里不再贴出源码了，我们来捋一下关键流程就好了：

- 首先扩容会传进来两个参数：旧哈希表和新哈希表（`Node<K,V>[] tab, Node<K,V>[] nextTab`），在第一个线程调用这个方法的时候新哈希表nextTab=null
- **当线程判断nextTab=null之后，会new一个是旧hash表2倍大小的新哈希表**（`Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];`）
- **创建新哈希表完成之后就是元素结点的搬迁工作了**。这个过程中值的注意的是，**当一个线程把旧哈希表上桶中的元素搬迁到新的哈希表上之后或者这个桶中没有元素，它用一个ForwardingNode类型的结点挂在这个桶下，以此告诉其他线程这个桶位置已经被处理了，这样可以避免其他线程get或put时出现错误**
- **还需要注意的是，在移动桶中元素的过程中，还是需要对链表和红黑树分别处理**，前者的判断依据是头结点的hash值大于等于0，后者的判断依据是头结点的hash值小于0并且头结点是TreeBin类的实例。

##### 7、ConcurrentHashMap和Hashtable都是线程安全的，在实现上有什么区别？



##### 8、ConcurrentHashMap是的size是如何计算的？

参考`ConcurrentHashMapde 实现原理？`的size()方法

##### 9、LinkedHashMap如何在O(1)时间复杂度里删除一个元素的？

参考使用LinkedHashMap实现LRU缓存的实现一问

##### 10、HashSet的实现原理

HashSet实际上是一个HashMap实例，都是一个存放链表的数组。它不保证存储元素的迭代顺序；此类允许使用null元素。HashSet中不允许有重复元素，这是因为HashSet是基于HashMap实现的，**HashSet中的元素都存放在HashMap的key上面，而value中的值都是统一的一个固定的Object对象(private static final Object PRESENT = new Object())**;

HashSet中add方法调用的是底层HashMap中的put()方法，而如果是在HashMap中调用put，首先会判断key是否存在，如果key存在则修改value值，如果key不存在这插入这个key-value。而在set中，因为value值没有用，也就不存在修改value值的说法，因此往HashSet中添加元素，首先判断元素（也就是key）是否存在，如果不存在这插入，如果存在着不插入，这样HashSet中就不存在重复值。

 所以判断key是否存在就要重写元素的类的equals()和hashCode()方法，当向Set中添加对象时，首先调用此对象所在类的hashCode()方法，计算次对象的哈希值，此哈希值决定了此对象在Set中存放的位置；若此位置没有被存储对象则直接存储，若已有对象则通过对象所在类的equals()比较两个对象是否相同，相同则不能被添加。

##### 11、Hashtable和HashMap的区别？

(1） **HashMap的基类是AbstractMap, Hashtable的基类是Dictionary**, 他们共同实现了Map接口

（2）**HashMap的初始容量是16，Hashtable的初始容量都是11**,负载因子都是0.75。但是扩容机制不同, HashMap是旧数组的2×旧表长度, 而Hashtable是2×旧表长度+1

（3） HashMap是非线程安全的，而Hashtable是线程安全的，因为所有的方法都使用了synchronized.

（4） HashMap使用迭代器迭代, Hashtable可以使用迭代器和枚举。

（6） HashMap中K和V都可以是null（存放在table[0]）,但是Hashtable中都不能是null.

（7） HashMap中取消了contains方法，使用了containsKey和containsValue,但是Hashtable中三个方法都有

（9）对象的定位方法不同:

- Hashtable:使用K的hashCode直接作为hash值,和数组长度进行求余运算,得到键值对在数组中的位置,然后再使用equals方法形成链表。
- HashMap:使用K的hashCode进行高低16位异或运算作为hash值,和数组的长度减一进行&运算， 得到键值对在数组中的位置，然后再使用equals方法形成链表。说一下计算桶的位置为什么是这个样子，就是因为扩容的时候是2的n次方进行扩容, hash值在和2的n次方进行求余运算和&运算的结果一样, 但是&运算要快的多。同时正是因为扩容倍数的特殊性，导致扩容后不需要重新键值对在新数组的位置只需要判断K的hash值多出来的那一位是0还是1. 如果是0, 新表中键值对的位置和旧表-样。 如果是1,新表中键值对的位置等于旧表的位置+旧表的长度。

（10）Hashtable由于是线程安全的，因此采用了一种快速失败的机制。允许多个线程同时修改但不会抛出异常；HashMap采用了一种安全失败机制的机制，他不允许在遍历元素的时候，集合发生改，如果发生改变就会抛出异常

##### 12、TreeMap的实现原理？

##### 13、List如何一遍遍历一遍删除元素？

使用Iterator遍历List，并使用Iterator的remove()方法删除元素，原理可以参考：[安全失败机制（fail-safe）和快速失败机制（fail-fast）](https://www.easyblog.top/article/details/192#%E4%B8%83%E3%80%81%E5%AE%89%E5%85%A8%E5%A4%B1%E8%B4%A5%E6%9C%BA%E5%88%B6%EF%BC%88fail-safe%EF%BC%89%E5%92%8C%E5%BF%AB%E9%80%9F%E5%A4%B1%E8%B4%A5%E6%9C%BA%E5%88%B6%EF%BC%88fail-fast%EF%BC%89)

##### 14、快速失败（fail-fast）和安全失败（fail-safe）机制的含义？

*  **快速失败机制 fail-fast**

**fail-fast是java集合的一种错误检测机制，在遍历集合的时候当对集合的结构进行修改的时候，就会触发fail-fast。比如我们使用迭代器遍历集合的时候，如果在遍历过程中对集合的结构进行了修改（比如删除元素，增加元素），就会抛出`ConcurrentmodificationException`异常**。

<img src="http://image.easyblog.top/1595933610575c4da05ab-05d7-4aca-95c6-9890668f4daf.png" alt="img" style="zoom:50%;" />

其实不光使用Iterator在遍历的时候不能修改集合元素的个数，增强for、forEach()方法等都不可以再遍历的增加或删除元素。

**原理**：**迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个int类型的变量modCount统计修改的次数，他表示的是集合在遍历之前已经修改过的次数，每当删除或添加元素之后都会把modCount+1，此时当调用hasNext()/next()方法时会判断modCount和exceptedModCount的值是否相等，如果相等就返回继续遍历，否则抛出ConcurrentModificationException，终止遍历。**

**应用场景**：java.util包下的集合类使用了这种机制（Hashtable除外，它使用的是fail-safe）,不能在多线程下发生并发修改（迭代过程中被修改）算是一种安全机制吧。

* **安全失败机制 fail-safe**

**采用安全失败机制的集合容器，在遍历的时候不会直接在原来的内容量上遍历，而是复制一份在副本上遍历。由于遍历是在拷贝的副本上进行的，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，因此不会引发`ConcurrentmodificationException`**

**应用场景**：J.U.C包下都是安全失败机制容器，可以在多线程环境下并发的修改和访问。

##### 15、CopyOnWriteArrayList讲一下

CopyOnWriteArrayList是J.U.C包下的一个并发容器，它是**线程安全且读操作无锁的ArrayList，写操作（增删改）则通过将底层数组拷贝一份，更改操作全部在新数组上进行，是一种读写分离**的并发策略，我们也可以称这种容器为"写时复制器"，Java并发包中类似的容器还有CopyOnWriteArraySet。

在jdk1.8中CopyOnWriteArraylist的底层数据结构还是数组，它使用ReentrarntLock来保证线程安全

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121213045.png" style="zoom:67%;" />

**添加元素—add()**

add()方法的逻辑非常简单，**在添加元素之前先获取当前对象的锁，之后在原数组的基础上复制一个新数组并且长度+1，之后把新元素放入新增加的数组索引位置之后在把老数组的引用改为这个新数组的引用**，解锁成功后就完成了添加元素的逻辑。

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121213139.png" style="zoom:67%;" />

 **删除操作**

和add方法逻辑大致相同，都是需要先获取锁，如果移除的数据在数组末尾免责直接复制原数组的`[0-array.length-1]`即可;如果要删除的元素不在数组末尾，那就会先new一个是原数组长度-1的新数组，然后使用`System.arrayCopy`把原数组中除要删除元素之外的其他元元素复制过去。

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121213246.png" style="zoom:67%;" />

**获取元素—get()**

CopyOnWriteArrayList允许并发的读，就是因为他没有加任何锁，任何线程只要来了就会可以获取数据。为啥敢这么写呢？**这是因为CopyOnWriteArrayList中的Object数组是被volatile保护着，volatile可以保证共享数据在多个线程之间的可见性，即任何线程去获取值都是最新的值**。

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210121213350.png" style="zoom:67%;" />

#### 总结—CopyOnWriteArrayList优缺点分析

**优点：**

读操作性能很高，因为无需任何同步措施，比较适用于**读多写少**的并发场景。Java的list在遍历时，若中途有别的线程对list容器进行修改，则会抛出**ConcurrentModificationException**异常。而CopyOnWriteArrayList由于其"读写分离"的思想，遍历和修改操作分别作用在不同的list容器，所以在使用迭代器进行遍历时候，也就不会抛出ConcurrentModificationException异常了，这就是一种 **[安全失败机制](https://www.easyblog.top/article/details/187?visitorUId=667020#三安全失败机制fail-safe和快速失败机制fail-fast)** （并发容器几乎都是这种机制）。

**缺点：**

　　缺点也很明显，**一是内存占用问题**，毕竟每次执行写操作都要将原容器拷贝一份，数据量大时，对内存压力较大，可能会引起频繁GC；**二是无法保证实时性**，Vector对于读写操作均加锁同步，可以保证读和写的强一致性。而CopyOnWriteArrayList由于其实现策略的原因，写和读分别作用在新老不同容器上，在写操作执行过程中，读不会阻塞但读取到的却是老容器的数据。



#### Java并发

##### 1、什么是进程?什么是线程？

**进程**

进程可以理解为一个应用程序执行的实例（比如在windows下打开Word就启动了一个进程），进程是资源分配的最小单位，每个进程都有自己独立的地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段。**进程主要有数据、程序和程序控制块（PCB）组成，其中PCB是系统感知进程存在的唯一标志。**

**线程**

线程是进程中的一个执行单元，一个进程中可以启动多个线程，并且一个进程中的多个线程可以共享此进程中的所用资源。每个线程都有自己独立的运行时桟和程序计数器，**线程是CPU调度的最小单位**。

##### 2、并发和并行的概念？

- **并发（concurrent）**：单核CPU 下，操作系统通过任务调度器，将CPU的时间片分给不同的线程使用，只是由于CPU的切换速度非常快（Windows下一个最小的时间片是15ms），让用户看上去是同步执行的，实际上还是串性执行的。**这种线程轮流使用CPU的方法叫并发。**
- **并行（parallel）：多个cpu或者多台机器同时处理任务**，是真正意义上的同时执行。

##### 3、Java线程间通信同步有哪几种方式？

* （1）**多个线程同步**：多个线程通过synchronized关键字这种方式来实现线程间的通信。

	```java
	public class MyObject {
	
	    synchronized public void methodA() {
	        //do something....
	    }
	
	    synchronized public void methodB() {
	        //do some other thing
	    }
	}
	
	public class ThreadA extends Thread {
	
	    private MyObject object;
	//省略构造方法
	    @Override
	    public void run() {
	        super.run();
	        object.methodA();
	    }
	}
	
	public class ThreadB extends Thread {
	
	    private MyObject object;
	//省略构造方法
	    @Override
	    public void run() {
	        super.run();
	        object.methodB();
	    }
	}
	
	public class Run {
	    public static void main(String[] args) {
	        MyObject object = new MyObject();
	
	        //线程A与线程B 持有的是同一个对象:object
	        ThreadA a = new ThreadA(object);
	        ThreadB b = new ThreadB(object);
	        a.start();
	        b.start();
	    }
	}
	```

	由于线程A和线程B持有同一个MyObject类的对象object，尽管这两个线程需要调用不同的方法，但是它们是同步执行的，比如：线程B需要等待线程A执行完了methodA()方法之后，它才能执行methodB()方法。这样，线程A和线程B就实现了 通信。

	这种方式，本质上就是“共享内存”式的通信。多个线程需要访问同一个共享变量，谁拿到了锁（获得了访问权限），谁就可以执行。

* **while轮询的方式**：通过一个标志位，让线程不断地while轮询，当while条件成立后做某些事或停止做某些事。存在问题：（1）while循环浪费CPU性能；（2）可能会存在内存可见性问题，容易造成死循环

* **wait/notify机制**：简单的说，等待/通知机制就是一个【线程A】等待，一个【线程B】通知（线程A可以不用再等待了）。比如生产者和消费者模型，消费者等待生产者生产资源，这是等待，生产者生产好资源通知等待的消费者去消费，这是通知。

	等待/通知的相关方法是任意Java对象都具备的，因为这些方法被定义在java.lang.Object类中

	```java
	wait()     //代用该方法的线程会进入到WAITING状态，并且当前线程会被放置到等待队列中，只有等待另外线程的唤醒或被中断返回，调用wait()方法后线程会释放对象锁，同时该方法必须在同步方法或同步块中使用，否则会抛出IllegalMonitorStateException异常。
	wait(long)     //超时等待一段时间，时间单位是ms,如果没有被唤醒就超时返回
	wait(long,int)   //更精细的超时等待，精确到ns
	notify()        //唤醒一个在等待对象锁的其他线程，如果有多个线程在等待该对象锁，那么会由线程规划器随机唤醒一个线程，此方法也必须在同步方法或同步块中使用，否则会抛出IllegalMonitorStateException异常。
	notifyAll()     //唤醒所有等待此对象锁的线程
	
	注意！notify()或notifyAll()在调用之后，等待线程不会立即从WAITING状态立即变为RUNNING状态，而是需要等到调动notify()或notifyAll()的方法释放对象锁之后才会从WAITING状态返回。
	```

	**等待/通知机制的经典范式（模板）**

	（1）等待方（消费者）需遵循如下原则：

	- 获取对象锁
	- 如果条件不满足，那么调用对象的wait()方法，被通知后仍然要检查条件
	- 条件满足则执行对应逻辑

	```java
	synchronized(对象){
	   while(条件不满足){
	       对象.wait();
	   }
	   对应的逻辑;
	}
	```

	（2）通知方（生产者）需遵循如下原则：

	- 获得对象锁
	- 改变条件
	- 通知所有等待该对象锁的线程

	```java
	synchronized(对象){
	    改变条件;
	    对象.notifyAll();
	}
	```

* **管道通信**：使用java.io.PipedInputStream 和 java.io.PipedOutputStream进行通信

* **套接字（Socket）**:通过Socket还可以实现在不同主机上的两个线程间的通信

##### 4、多线程共享数据？

##### 5、信号量和互斥量的区别？

##### 临界区(Critical Section)

保证在某一时刻只有一个线程能访问数据的简便办法。在任意时刻只允许一个线程对共享资源进行访问。如果有多个线程试图同时访问临界区，那么在有一个线程进入后其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操 作共享资源的目的。

##### 互斥量(Mutex)

互斥量跟临界区很相似，只有拥有互斥对象的线程才具有访问资源的权限，由于互斥对象只有一个，因此就决定了任何情况下此共享资源都不会同时被多个线程所访问。当前占据资源的线程在任务处理完后应将拥有的互斥对象交出，以便其他线程在获得后得以访问资源。互斥量比临界区复杂。因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。 

Mutex本质上说就是一把锁，提供对资源的独占访问，所以Mutex主要的作用是用于互斥。Mutex对象的值，只有0和1两个值。这两个值也分别代表了Mutex的两种状态。值为0, 表示锁定状态，当前对象被锁定，用户进程/线程如果试图Lock临界资源，则进入排队等待；值为1，表示空闲状态，当前对象为空闲，用户进程/线程可以Lock临界资源，之后Mutex值减1变为0。

##### 信号量(Semaphores)

**信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。**

信号量可以分为几类：

（１）**二进制信号量(binary semaphore)**：只允许信号量取0或1值，其同时只能被一个线程获取。

（２）**整型信号量（integer semaphore)**：信号量取值是整数，它可以被多个线程同时获得，直到信号量的值变为0。

（３）**记录型信号量（record semaphore)**：每个信号量s除一个整数值value（计数）外，还有一个等待队列List，其中是阻塞在该信号量的各个线程的标识。当信号量被释放一个，值被加一后，系统自动从等待队列中唤醒一个等待中的线程，让其获得信号量，同时信号量再减一。

信号量通过一个计数器控制对共享资源的访问，信号量的值是一个非负整数，所有通过它的线程都会将该整数减一。如果计数器大于0，则访问被允许，计数器减1；如果为0，则访问被禁止，所有试图通过它的线程都将处于等待状态。

计数器计算的结果是允许访问共享资源的通行证。因此，为了访问共享资源，线程必须从信号量得到通行证， 如果该信号量的计数大于0，则此线程获得一个通行证，这将导致信号量的计数递减，否则，此线程将阻塞直到获得一个通行证为止。当此线程不再需要访问共享资源时，它释放该通行证，这导致信号量的计数递增，如果另一个线程等待通行证，则那个线程将在那时获得通行证。

PV操作及信号量的概念都是由荷兰科学家E.W.Dijkstra提出的。信号量S是一个整数，S大于等于零时代表可供并发进程使用的资源实体数，但S小于零时则表示正在等待使用共享资源的进程数。

**P操作 申请资源**：

(1) S减1；

(2) 若S减1后仍大于等于零，则进程继续执行；

(3) 若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转入进程调度。

**V操作 释放资源**：

(1) S加1；

(2) 若相加结果大于零，则进程继续执行；

(3) 若相加结果小于等于零，则从该信号的等待队列中唤醒一个等待进程，然后再返回原进程继续执行或转入进程调度。

##### 6、线程是怎么实现的？Thread类中有哪些方法？wait()是线程的方法吗？

##### 7、wait和sleep的区别？

* （1）wait()方法定义在Object类中，作用于所有对象；sleep()方法定义在Thread类中，作用于当前线程；
* （2）wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用；
* （3）**最主要的区别**：**调用 wait()方法后，线程会放弃对象锁；而sleep()方法调用后不会释放锁资源**，如果sleep()是在同步上下文中调用的，那么其他线程是无法进入到当前同步块或者同步方法中的
* （4）sleep在使用的时候必须捕获异常，而wait，notify和notifyAll不需要捕获异常

##### 8、线程实现各有哪些优缺点？

##### 9、Java中如何启动一个线程

* **第一种方法是将类声明为 Thread 的子类。该子类应重写 Thread 类的 run 方法，然后在run方法里实现相应的逻辑代码**

	```java
	public class ThreadTest {
	
	    public static void main(String[] args) {
	        Task task = new Task();
	        task.setName("test-thread");
	        task.start();
	    }
	
	    static class Task extends Thread{
	
	        @Override
	        public void run() {
	            System.out.println(Thread.currentThread().getName());
	        }
	    }
	
	}
	```

* **第二种方法是实现Runnable接口，并编写run方法,相比继承Thread类创建线程的好处是以实现接口的方式创建线程可以对类进行更好的扩展，该类可以继承其他类来扩展自身需求，相比第一种方式更加灵活，扩展性强。**

	```java
	public class RunnableTest{
	
	    public static void main(String[] args){
	        Thread t=new Thread(new Task(),"test-thread");
	        t.start();
	    }
	
	    static class Task implements Runnable{
	        @Override
	        public void run() {
	            System.out.println(Thread.currentThread().getName());
	        }
	    }
	}
	```

* **第三种方法，如果你想要在线程执行完毕之后得到带有返回值的线程则实现Callable接口。我们只需要实现Callable接口的call()方法，而且call方法还可以有返回值，还可以抛出异常。在jdk1.5中提供了Future接口来表示call()方法的返回值，并且提供了一个FutureTask实现类。**

	```java
	public class CallableTest {
	
	    public static void main(String[] args) {
	        /**
	         * FutureTask实现了Runnable接口，因此FutureTask也就相当于是一个Runnable实现类
	         */
	        FutureTask<Integer> ft = new FutureTask<Integer>(new Task());
	        Thread thread = new Thread(ft, "callable-test");
	        thread.start();
	        try {
	            //FutureTask的get()方法会阻塞
	            System.out.println(ft.get());
	        } catch (InterruptedException e) {
	            e.printStackTrace();
	        } catch (ExecutionException e) {
	            e.printStackTrace();
	        }
	    }
	
	    static class Task implements Callable<Integer> {
	
	        /**
	         * 实现call()方法
	         *
	         * @return
	         * @throws Exception
	         */
	        public Integer call() throws Exception {
	            int ret = 0;
	            for (int i = 0; i < 100; i++) {
	                ret += i & (i - 1);
	            }
	            return ret;
	        }
	    }
	
	}
	```

##### 10、Java中线程有几种状态？

Java中的线程有5种状态：**新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）、死亡（Dead）**

<img src="http://image.easyblog.top/1585712810812ab80dad3-d004-48ea-b160-3558796ca2b2.png" alt="img" style="zoom:50%;" />

- （1）**New**：当程序使用 **new 关键字创建了一个线程之后**，该线程就处于新建状态，此时仅由 JVM 为其分配内存，并初始化其成员变量的值
- （2）**Runnable**：线程被创建后，其他线程**调用了线程的start()方法**之后该线程处于这个状态。该状态的线程处于可执行线程池中，就绪状态的线程表示有权力去获取CPU时间片了，CPU时间片就是执行权。当线程拿到CPU时间片后就会马上执行run()方法，这时线程就进入了运行状态。
- （3）**Running**：线程获取到CPU时间片后线程执行任务的状态
- （4）**Blocked**：阻塞状态是由于当前执行中的线程因为某种原因放弃CPU使用权，暂时停止运行的状态。处于阻塞状态的线程必须再次切换到Runnable才能再次获取到CPU时间片。阻塞的类型可以分为三种：
	- **等待阻塞**：运行中的线程执行了wait()方法，JVM会把该线程放入等待队列（waiting queue）
	- **同步阻塞**：运行中的线程尝试获取一个对象的对象锁时，当发现这把锁正在被其他线程使用，那么JVM就会把该线程放入锁池(lock pool )
	- **其他阻塞**：运行中的线程调用了sleep()、join()方法或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。
- （5）**Dead**：当执行中的线程执行完线程任务或执行过程中发生了Error或Exception线程都会死亡。

##### 11、什么是线程的上下文切换？

多线程编程中**一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。**

概括来说就是：当前任务在用完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换会这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。

**当发生以下情况时，会发生线程上下文切换**：

- **线程的CPU时间片用完**
- **垃圾回收**
- **有更高优先级的线程需要运行**
- **线程自己调用了sleep()、yield()、wait()、join()、park()....**

##### 12、ThreadLocal了解吗？他是如何解决内存泄漏问题的？在使用的时候要注意什么？

**ThreadLocal是什么？**

**ThreadLocal是一个本地线程变量工具类。ThreadLocal中填充的变量只属于当前线程，与其他线程无关。ThreadLocal为变量在每个线程中都创建了一个副本，每个线程可以访问自己内部的副本变量。**

ThreadLocal的应用场景：

**1、在进行对象跨层传递的时候，使用ThreadLocal可以避免多次传递，打破层次间的约束。**

**2、线程间数据隔离**

**3、进行事务操作，用于存储线程事务信息。**

**4、数据库连接，Session会话管理**



**使用ThreadLocal**

ThreadLocal的作用是每一个线程创建一个副本，我们使用一个例子来验证一下：

<img src="https://pics0.baidu.com/feed/14ce36d3d539b600ff663d8e75a8c62fc75cb759.jpeg?token=44530368d6f896c24c1566224aa81a47&s=B8C3A144D2B4806F165DF8030000E0C1" alt="img" style="zoom:67%;" />

**ThreadLocal的底层结构**

（1）每个Thread中维护着一个ThreadLocalMap的引用

（2）ThreadLocalMap是ThreadLocal的内部类，用Entry来进行存储

（3）ThreadLocal创建的副本是存储在自己的threadLocals中的，也就是自己的ThreadLocalMap。

（4）ThreadLocalMap的键值为ThreadLocal对象，而且可以有多个threadLocal变量，因此保存在map中

（5）在进行get之前，必须先set，否则会报空指针异常，当然也可以初始化一个，但是必须重写initialValue()方法。

（6）ThreadLocal本身并不存储值，它只是作为一个key来让线程从ThreadLocalMap获取value。



**ThreadLocal几个注意的点**

<img src="https://pics3.baidu.com/feed/91ef76c6a7efce1b563edc5501a900dbb58f6512.jpeg?token=a6acac56e087a9c1581a7acfc867015d&s=A642F210061F6DCA0AF341C5030030BB" alt="img" style="zoom:70%;" />

上面这张图详细的揭示了ThreadLocal和Thread以及ThreadLocalMap三者的关系。

* 1、每个Thread维护了一个Map—ThreadLocalMap，TreadLocalMap就是类似HashMap一样的key-value存储容器，但它使用开放定址法来解决Hash冲突，这种冲突避免手段效率极低，因此在使用ThreadLocal的时候不建议存过多的数据

* 2、ThreadLocalMap中的key就是ThreadLocal该线程的ThreadLocal对象引用，它是一个弱引用（ThreadLocalMap中存储数据的结构是Entry节点，这个Entry是ThreadLocalMap的内部类，它继承了WeakReference(弱引用)），弱引用有一个特性就是**一个实例对象只有弱引用的话，那么一旦发生GC无论当前堆空间是否紧张，这个实例是一定会被GC清除的**，为什么这么设计呢？

	<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210122161732.png" style="zoom:67%;" />

	**这么做主要是因为使用强引用会导致即使threadlocal对象没使用甚至已经被回收了，但是由于key和Entry是强引用，如果线程一直在运行的话，会导致内存泄漏发生，使用弱引用就可以解决key无法回收的问题**；

	但是即使key的内存泄漏问题解决了，vlaue和Entry之间同样是强引用，如果不正确的使用ThreadLocal任然会造成内存泄漏，咋办呢？ThreadLocal为我们提供了remove()方法，他可以清理Entry中的元素。因此在使用ThreadLocal的使用有以下建议：

	* **（强制）在代码逻辑中使用完ThreadLocal，都要调用remove方法，及时清理**。

		解释：目前我们使用多线程都是通过线程池管理的，对于核心线程数之内的线程都是长期驻留池内的。显式调用remove，**一方面是防止内存泄漏，最为重要的是，不及时清除有可能导致严重的业务逻辑问题，产生线上故障（使用了上次未清除的值）。**

		**最佳实践：在ThreadLocal使用前后都调用remove清理，同时对异常情况也要在finally中清理。**

	* **（建议）ThreadLocal作为全局成员变量并且使用static修饰**。

		如果ThreadLocal不加static，则每次其所在类实例化时，都会有重复ThreadLocal创建。这样即使线程在访问时不出现错误也有资源浪费。（单例模式下当我没说！）

##### 13、CAS的含义  ABA问题是如何解决的？

**13.1、CAS是什么？**

CAS（Compare And Sweap或者Compare And Set，比较替换），工作原理是：**一个CAS操作有三个操作数，目标内存地址V，旧的预期值E和将要替换的新值B，在进行替换操作前比较当且仅当目标内存地址V中的值和旧的预期值E值相等的时候才会发生替换，否则什么都不做。CAS主要是为了解决原子性问题，同时又不想利用重量级的锁的一种方案**

CAS是Java中的一种**乐观锁**技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

**13.2、乐观锁**

乐观锁，是系统对操作保持一种比较乐观的状态，认为线程中运行时大概率不会产生资源竞争的情况，因此不会运行的时候就开始获取锁，只有等到有资源竞争的时候才会获取锁，`Java`中一般通过`CAS`机制来解决。

**13.3、CAS为什么可以解决原子性问题？**

在CAS底层中，通过判断内存中某个位置的值是否为预期值，如果是则更新为新的值，**该比较和赋值动作是原子的。是完全依赖于硬件的功能，通过底层硬件实现原子的功能（程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（`lock cmpxchg`）。反之，如果程序是在单处理器上运行，就省略lock前缀），该过程的执行是不允许中断的，不会造成所谓的数据不一致问题。**

**13.4、既然CAS就可以解决原子性问题，那是不是可以这么说并发编程中可以不需要`synchronized`或者`ReentrantLock`了？是不是对象的原子性保证用`CAS`就够了**

> Tips：一般面试官如果这么问问题的话，肯定是想问某个技术是否有无缺陷。

不是的。因此`CAS`本身也有很多缺点。最显著的有三个缺点：

1. 循环开销大：如果比较的时候一直不等于预期值，则会一直循环等待，直到比较成功为止，该过程会给CPU带来较大开销。
2. 只能保证一个共享变量的原子操作。对于多个共享变量无法保证原子性，因为每次比较的都是一个元素。
3. ABA问题。

**13.4、ABA问题？能简单解释一下吗？**

> 面试想听的其实是：什么是ABA问题，为什么有ABA问题，如何解决等几方面考虑。

**什么是ABA问题，为什么有ABA问题**

所谓`ABA`问题，比如数值`i = 5`，`A`线程本来想改成10，在更改之前，`B`线程先将i先由5变成了6，再更新成5，但是`A`线程并不知道`i`发生过改变，仍然将`i`改成10。尽管最后的结果没有问题，但是整个过程还是不对的。

**ABA问题的解决方法？**

一般的解决方法是给共享数据加上一个版本号(version)，每次修该之前不仅要比较预期值和内存值是否一致，还要比较版本号是否一致，只有两者同时满足才可以修改，修改值之后将版本号同时更新。

**Java中的解决方法是使用时间戳作为版本，比如AtomicStampedReference这个类中就使用了一个stamp字段来存储时间戳当做版本**

> Tips：一般聊到这里，面试官就会换一个话题，此时可以抓住时机，说一下数据库中的MVCC也是用到了版本号的方法来实现了乐观锁机制，相信我绝对加分！！！

##### 14、volatile关键字的原理？

**14.1、volatile的作用**

volatile是java虚拟机提供的轻量级同步机制，主要特点有三个：

1. **volatile可以保证不同线程对一个变量的可见性**，即一个线程修改了被voaltile修饰的变量后，这新值对其他线程来说是立即可见的;
2. **volatile可以禁止指令重排序**，保证了有序性；
3. volatile不能保证原子性，更加不能保证线程安全，要想保证原子性和线程安全还是乖乖的使用锁吧！

> Tips：面试中，肯定不是说完这三点就完了，一般需要展开来说。

所谓可见性，是多线程中独有的。A线程修改值之后，B线程能够知道参数已经修改了，这就是**线程间的可见性。** A修改共享变量i之后，B马上可以感知到该变量的修改。

**14.2、面试官可能会追问，为什么会出现变量可见性问题？**

这个就涉及到Java的内存模型了（俗称JMM），因此你需要简单说说Java的内存模型。

<img src="http://image.easyblog.top/15971084794948dee08b1-8488-4fcc-88ff-1ba161da1a39.png" alt="img" style="zoom:50%;" />

JMM即Java Memory Model，它将JVM内存抽象为**主内存**和**工作内存**。主内存是所有的线程共享的内存区域；工作内存是线程私有的。JMM规定：

- **所有的变量都存储在主内存中(虚拟机内存的一部分)，对于所有线程都是共享的**。
- 每个线程都有自己的工作内存，**工作内存中保存的是该线程使用到的变量副本（该副本就是主内存中该变量的一份拷贝）**，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。
- **线程之间无法直接访问对方的工作内存中的变量**，线程间变量的传递均需要通过主内存来完成

> 面试中记得不要干说理论，结合一下例子，让面试官感到你真的掌握了。上面的问题你抓住主内存、线程内存分别阐述即可

比如，存在两个线程A、B，同时从主线程中获取一个对象（i = 25），某一刻，A、B的工作线程中i都是25，A效率比较高，片刻，改完之后，马上将i更新到了主内存，但是此时B是完全没有办法i发生了变化，仍然用i做一些操作。**问题就发生了，B线程没有办法马上感知到变量的变化！！**

**14.3、volatile可以保证程序的原子性吗？**

volatile不保证原子性。为什么无法保证原子性呢？
因为上述的Java的内存模型的存在，修改一个i的值并不是一步操作，过程可以分为三步：

1. 从主内存中读取值，加载到工作内存
2. 工作内存中对i进行自增
3. 自增完成之后再写回主内存。

每个线程获取主内存中的值修改，然后再写回主内存，多个线程执行的时候，存在很多情况的写值的覆盖。



**14.4、面试官：你刚才说到了`volatile`禁止指令重排，可以说说里面的原理吗？**

> 此刻需要故作沉思，需要表现出在回忆的样子，（为什么这么做，你懂得，毕竟没有面试官喜欢背题的同学）。

哦哦，这个之前操作了解过。计算机在底层执行程序的时候，为了提高效率，经常会对指令做重排序，一般重排序分为三种

1. **编译器优化的重排序**。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；
2. **指令并行的重排**。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序，处理器的重排序又被称为**乱序执行（out-of-order execution,OOE）技术**；
3. **内存系统的重排**。由于处理器使⽤缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执⾏的。

##### （2）as-if-serial语义

单线程下，无论怎么样重排序，最后执行的结果都一致的，并且指令重排遵循基本的数据依赖原则，数据需要先声明再计算；多线程下，线程交替执行，由于编译器存在优化重排，两个线程中使用的变量能够保证一致性是无法确定的，结果无法预测。

volatile本身的原理是利用内存屏障来实现，通过插入内存屏障禁止在内存屏障前后的指令执行重排序的优化。

**内存屏障有啥作用呢，是怎么实现的呢？**

其实前面的lock前缀指令实际上相当于一个**内存屏障**（也成内存栅栏），内存屏障会提供3个功能：

- （1）**它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成**；
- （2）**它会强制将对缓存的修改操作立即写入主存**；
- （3）**如果是写操作，它会导致其他CPU中对应的缓存行无效**。

**Volatile与内存屏障又是如何起着作用的呢？**

<img src="http://image.easyblog.top/15971265900601c1b0648-b4c5-4ca8-8f5a-e415a9f3cf26.png" alt="img" style="zoom:33%;" /><img src="http://image.easyblog.top/1597126244876a33e5514-0a25-4eef-b9ca-e4a018f84e28.png" alt="img" style="zoom:33%;" />

对于volatile变量进行写操作时，会在写操作后面加上一个store屏障指令，将工作内存中的共享变量值即可刷新到主内存；
对于Volatile变量进行读操作时，会在读操作前面加入一个load屏障指令，读取之前马上读取主内存中的数据。

##### 15、synchronized的三种使用方式？

synchronized是Java语言内置的锁，可以用于代码块和方法（包括静态方法和普通成员方法）

* **synchronized代码块**

	<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210122201241.png" style="zoom:67%;" />

* **synchronzied修饰实例方法**

	<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210122201225.png" style="zoom:67%;" />

	在这种情况下多线程并发访问实例方法时，如果其他线程调用同一个对象的被 `synchronized` 修饰的方法，就会被阻塞。相当于把锁记录在这个方法对应的对象上（相当于synchronized(this){...}）。

* **synchronzied修饰静态方法**

	<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210122201233.png" style="zoom:67%;" />

	这种情况下进行多线程并发访问时，如果其他线程也是调用属于同一类的被 `synchronized` 修饰的静态方法，就会被阻塞。相当于把锁信息记录在这个方法对应的Class对象上。又由于Class的相关数据存储在永久带 PermGen（jdk1.8 则是 metaspace），永久代是全局共享的，因此静态方法锁相当于类的一个全局锁 。因此当一个线程访问类中的静态方法时，其他线程无法再访问这个类中的任何成员。

##### 16、synchronized的实现原理？

> Tips：首先回答对synchronized的认识

`synchronized`关键字是Java并发编程中线程同步的常用手段之一，其作用有三个:

 1. 互斥性：确保线程互斥的访问同步代，锁自动释放，多个线程操作同个代码块或函数必须排队获得锁，
2. 可见性：保证共享变量的修改能够及时可见，获得锁的线程操作完毕后会将所数据刷新到共享内存区[1]
3. 有序性：不解决重排序，但保证有序性

**同步代码块**

<img src="http://image.easyblog.top/1597050921017c784e919-4a57-4974-9f1e-87740aad79b0.png" alt="img" style="zoom:40%;" />

其实我们使用`javap`命令反编译synchronized之后就可以发现**同步代码块在字节码层面通过monitorenter和monitorex两条字节码指令实现的**。

- 当进入方法执行到**monitorenter**指令时，当前线程会尝试获取Monitor的所有权，成为这个Monitor的Owner，获取成功后继续执行临界区中的代码，执行结果会执行**monitorexit**指令，表示释放锁；如果获取锁失败那就会进入阻塞队列中等待；
- 如果当前线程已经是此Monitor的Owner了，再次执行到monitorenter那就直接进入，并将进入次数+1
- 同理，当执行完monitorexit，对应的进入数就-1，直到为0，才可以被其他线程持有

细心的同学可能会发现，**为什么在反编译后的字节码中出现了两次`monitorexit`指令**？

答：程序正常退出，得用一个 `monitorexit` 吧，如果中间出现异常，正常执行的`monitorexit`可能就无法执行到，锁会一直无法释放。所以编译器会为同步代码块添加了一个隐式的 `try-finally` 异常处理，在 `finally` 中会调用 `monitorexit` 命令最终释放锁。

**同步方法**

<img src="http://image.easyblog.top/15970498789810ce65221-08a0-4b1a-950c-cbf81517dee4.png" alt="img" style="zoom:45%;" />

**方法的同步：在方法常量表中记录一个ACC_SYNCHRONIZED访问标记，调用指令会检查方法的常量表中是否设置了ACC_SYNCHORINZED标记 ,如果设置了这个标志，执行线程就需要先获取Monitor，获取成功之后才能执行方法，最后方法执行完毕释放Monitor。** 在方法执行期间，执行线程持有了该Monitor之后，其他线程就无法再获取了。如果在执行同步方法期间发生了异常，并且方法内部无法处理此异常，那么同步方法将会在抛出异常后自动释放Monitor。



synchronized锁，其本质就是锁的对象，所以了解原理之前先介绍下java对象。下图展示的是Java 对象在内存中的内存结构：

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/12/java2-1609296223.png" alt="全网最细：17张图带你秒杀synchronized关键字" style="zoom:33%;" />

可以看到，内存中的对象一般由三部分组成，分别是**对象头、对象实际数据和对齐填充**。 

* **对象头**包含 Mark Word、Class Pointer。如果是数组还有一个Length 字段。

	* **Mark Word 记录了对象的hashCode、锁信息，垃圾回收信息等。** 

	* **Class Pointer 用于指向对象对应的 Class 对象（其对应的元数据对象）的内存地址。**
	* **Length只适用于对象是数组时，它保存了该数组的长度信息。**

* 对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定。

* 对齐填充表示最后一部分的填充字节位，JVM要求Java对象大小必须是8字节的整数倍，因此如果对象的大小满足条件将会填充，这部分不包含有用信息。 

`synchronized` 锁使用的就是对象头的 Mark Word 字段中的一部分。Mark Word 中的某些字段发生变化，就可以代表锁不同的状态。

在jdk1.6之前，Synchronized锁实现的都是重量级锁，锁的标识位是10，其中指针指向的是monitor对象（监视器锁）的起始位置，每个对象都有一个与之关联的Monitor对象，当Monirot被某个线程持有后，它便处于锁定状态。在JAVA虚拟机中，montitor是由ObjectMonitor（C++源码）实现，其主要数据结构如下左图所示：

<img src="https://www.javazhiyin.com/wp-content/uploads/2021/01/java6-1610525480.png" alt="Synchronized原理分析" style="zoom:50%;" /><img src="http://image.easyblog.top/1585816771705f9e2fc1a-12fa-4087-af24-c33a49346ecd.png" alt="img" style="zoom:50%;" />

ObjectMonitor中有两个队列，\_WaitSet和\_EntryList，用来保存ObjectWaiter对象列表（每个等待锁的线程都会被封装成ObjectWaiter对象）。

* \_WaitSet用于保存处于wait状态的线程；若线程调用了wait方法，将释放当前持有的monitor，owner变量恢复为null,count减1，同时该线程会进入WaitSet集合中等待被唤醒，
* \_EntryList用户保存处于竞争锁而处于阻塞状态的线程。当多个线程同时访问一段同步代码时，首先会进入\_EntryList集合阻塞等待；
* \_owner指向持有ObjectMonitor对象的线程（获取到对象锁的线程），当线程获取到对象的monitor后会进入\_owner区域并把monitor的owner设置为当前线程，同时count加1，若当前线程执行完毕将释放monitor并复位变量的值，以便其他线程进入获取锁。

重量级锁的缺点很明显：**依赖底层操作系统的 mutex 相关指令实现，加锁解锁需要在用户态和内核态之间切换，性能损耗非常明显。**



##### 17、synchronized锁升级过程

在jdk1.6开始，synchronized加入了偏向锁和轻量级锁来提升了Synchronized的整体性能。

**无锁到偏向锁**

在大多数情况下，锁不仅不存在竞争，而且总是由同一个线程多次获得，因此为了减少同一线程获取锁的代价引入了偏向锁。

首先检测是否为可偏向的状态，如果处于可偏向的状态，会测试当前Mark Word的线程ID是否指向自己，如果是，不需要再次获取锁，直接执行同步代码。

如果线程ID不是自己的线程ID，就会通过CAS获取锁，获取成功代表当前偏向锁不存在竞争，获取失败，这说明当前偏向锁存在锁竞争，这时候就会先启动偏向锁撤销。

锁撤销流程：当出现竞争，持有锁的线程会等待一个全局安全点阻塞，遍历线程栈，查看是否有被锁对象的锁记录（Lock Record）,如果有Lock Record，需要修复锁记录和Mark Word,使其变成无锁状态，将是否为偏向锁状态置为0，然后开始进行轻量级锁加锁流程。

**偏向锁升级为轻量级锁**

如果有不止一个线程在交替着使用一个锁对象，那么synchronized锁对象就会升级为轻量级锁。

* **首先线程在自己的桟帧中产生创建一块锁记录空间，并把对象头中的Mark Word复制到锁记录中，被称为Displaced Mark Word。**
* **然后线程尝试使用CAS操作将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，随后将锁标志设为00；如果CAS操作失败，表示其他线程竞争锁，当前线程将进入到自旋获取锁的过程。**

自旋是一个耗费处理器资源的行为，因此当自旋一定次数后，锁就会升级为重量级锁，当前线程就会被阻塞，自旋默认的次数是10次，可以通过JVM参数`-X:preBlockSpin`来修改。

**在jdk1.6中引入了自适应的自旋锁。自适应的锁的自旋时间不是固定的，他会根据上一次在同一锁上的自旋时间以及拥有者的状态来决定。如果在同一个自旋锁对象上，自旋等待成功获取了锁并且正在运行，那么JVM就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续更长时间。如果对于某个锁，自旋成功很少获取到锁，那么JVM就会省略自旋过程，以避免浪费处理器资源。**

**轻量级锁升级成重量级锁**

当多个线程请求获取轻量级锁的时候，轻量级锁就会膨胀为**重量级锁**，重量级锁就是指当一个线程获得锁之后，其余等待这个锁的线程都将进入到阻塞状态。重量级锁是操作系统层面的锁，此时线程的调度都将由操作系统负责，因此这就会引起频繁的上下文切换，导致线程被频繁的唤醒和挂起，使得程序性能下降。重量级锁的底层实现在JVM层面是通过对象内部的监视器（monitor）实现的。

##### 18、synchronized和Lock的区别？

* （1）**synchronized是Java的关键字是jvm层面上的互斥锁，Lock通过类实现的一个互斥锁**
* （2）**使用synchronized时，当线程执行完同步代码之后或者出现异常之后jvm会自动让线程释放锁；但是Locak在使用的时候必须手动显示的在finally块中释放锁,如果没这样做，容易产生死锁**
* （3）**Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；**
* （4）**通过Lock可以知道有没有成功获取锁，而synchronized却无法办到**
* （5）**Lock可以提高多个线程进行读操作的效率。从性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。****

##### 19、AQS的原理？

**AQS：AbstractQueuedSynchronizer（队列同步器）。它使用一个int类型的成员变量state表示同步状态，通过内置的一个FIFO队列完成线程的排队工作。**

AQS支持两种资源分享的方式：Exclusive（独占式，只有一个线程能执行，如ReentrantLock）和Share（共享式，多个线程可同时执行，如Semaphore/CountDownLatch）。

一般使用AQS都是同步继承AQS，并只需要实现共享资源state的获取和释放方式即可，其他如线程队列的维护（如获取资源失败入队/唤醒出队等）等操作，AQS在顶层已经实现了。

AQS代码内部提供了一系列操作锁和线程队列的方法，主要操作锁的方法包含以下几个：

- compareAndSetState()：利用CAS的操作来设置state的值
- tryAcquire(int)：独占方式获取锁。成功则返回true，失败则返回false。
- tryRelease(int)：独占方式释放锁。成功则返回true，失败则返回false。
- tryAcquireShared(int)：共享方式释放锁。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
- tryReleaseShared(int)：共享方式释放锁。如果释放后允许唤醒后续等待结点返回true，否则返回false。

像ReentrantLock就是实现了自定义的tryAcquire-tryRelease，从而操作state的值来实现同步效果。

**status变量**

```java
//在互斥锁中它表示着线程是否已经获取了锁，0未获取，1已经获取了，大于1表示重入数。
private volatile int state;//共享变量，使用volatile修饰保证线程可见性
```

CLH中每一个节点的状态(waitStatus)取值如下：

- **CANCELLED(1)**：表示当前线程已经被取消（等待超时或者被中断了）
- **SIGNAL(-1)**：表示后继节点需要被唤醒
- **CONDITION(-2)**：表示节点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的节点将从等待队列转移到同步队列中，等待获取同步锁
- **PROPAGATE(-3)**：共享模式下，前驱节点不仅会唤醒其后继节点，同时也可能会唤醒后继的后继节点
- **0**：当一个Node被初始化时waitStatus的默认值

另外这个state变量被volatile修饰，可以保证线程间的内存可见性，对于他的操作都是CAS操作。

**FIFO队列**

FIFO队列其实就是一个CLH锁队列，**通过节点中的“状态”字段来判断一个线程是否应该阻塞。当该节点的前一个节点释放锁的时候，该节点会被唤醒。**

> **CLH锁**其实就是一种是基于逻辑队列非线程饥饿的一种自旋公平锁，由于是 Craig、Landin 和 Hagersten三位大佬的发明，因此命名为CLH锁。
>
> **CLH锁原理如下：**
>
> 1. 首先有一个尾节点指针，通过这个尾结点指针来构建等待线程的逻辑队列，因此能确保线程线程先到先服务的公平性，因此尾指针可以说是构建逻辑队列的桥梁；此外这个尾节点指针是原子引用类型，避免了多线程并发操作的线程安全性问题；
> 2. 通过等待锁的每个线程在自己的某个变量上自旋等待，这个变量将由前一个线程写入。由于某个线程获取锁操作时总是通过尾节点指针获取到前一线程写入的变量，而尾节点指针又是原子引用类型，因此确保了这个变量获取出来总是线程安全的。
>
> AQS就是基于CLH锁原理实现的一个通用队列同步器。

<img src="https://www.javazhiyin.com/wp-content/uploads/2019/10/java4-1571279872.png" alt="面试必备：Java AQS 实现原理（图文）分析" style="zoom:60%;" />

在AQS内部中还维护了两个Node对象`head`和`tail`，一开始默认都为null

```java
private transient volatile Node head;  //队列的头
private transient volatile Node tail;  //队列的尾 
```

除此之外，**AQS内部还定义了一个静态类Node，表示CLH队列的每一个结点，该结点的作用是对每一个等待获取资源的线程做了封装，包含了需要同步的线程本身、线程等待状态等**

<img src="http://image.easyblog.top/1586618237429b59582f0-1072-4ce7-a5f3-a4b467727da8.png" alt="img" style="zoom:40%;" />



**AQS重要源码分析**

**获取同步锁**

通过调用同步器的 **acquire(int arg)** 方法可以获取同步状态，调用了该方法后的线程不会对中断操作响应。方法的代码如下：

<center><img src="http://image.easyblog.top/158653462775538360b2e-8784-412b-8edb-1580754da1c3.png" alt="img" style="zoom:45%;" /><img src="http://image.easyblog.top/15865275435402494e537-effc-47e3-a657-044cab641f9b.png" alt="img" style="zoom:50%;" /></center>

- 首先调用`tryAcquire(int arg)`方法，该方法的作用是获取独占式同步状态，底层依赖CAS实现，如果获取成功返回true，否则返回false；需要注意的是，这个方法在AQS内部并没有真正的逻辑，他把这部分交给子类实现。

- 如果获取同步失败，AQS回首先调用`addWaiter()`方法将当前线程包装一个Node节点对象，并插入FIFO同步队列的尾部；

- 最后调用`acquireQueued(Node node,int arg)`方法使得该线程在特定条件下可以多次尝试获取锁。

	<img src="http://image.easyblog.top/158653735767222b19751-5964-40b1-9eb1-edcd340c6383.png" alt="img" style="zoom:50%;" />

	从代码中我们也看到了。如果当前节点就是head节点的后继时，会再次尝试获取锁，获取成功之后会将head指向自己。只有当前节点是head的结点的后继节点时才可以再次尝试获取锁，这么做的理由有以下两个：

	- （1）**这样做可以维护队列的FIFO特性**；
- （2）**头结点是成功获取到同步状态的结点，而头结点的线程释放了同步状态后，将会唤醒其后继结点，后继结点的线程被唤醒或需要检查自己的前驱结点是否是头结点**。
	

如果当前节点不是head节点的后继，那么方法将会调用`shouldParkAfterFailedAcquire()`方法根据前驱节点的状态来设置当前节点的是否应该被阻塞，具体来说就是：

- 如果前驱节点的状态为`SIGNAL`，说明闹钟标志已设好，返回true表示当前节点可以放心wait它。
- 如果前驱节点的状态为`CANCELLED`，说明前驱节点本身不再等待了，那么需要跨越这些节点，然后找到一个有效节点，再把node和这个有效节点的前驱后继连接好。
- 如果是其他情况，那么CAS尝试设置前驱节点为`SIGNAL`。

当判断当前节点可以被阻塞后，会接着调用`parkAndCheckInterrupt()`方法让线程进入等待状态。底层是通过LockSupport.park(this);实现的。park()会让当前线程进入waiting状态。在此状态下，有两种途径可以唤醒该线程：1）被unpark()；2）被interrupt()。



最后，总结一下acquire()的流程：

- 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；
- 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；
- acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。
- 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。

**释放同步锁**

当一个线程获得同步状态并执行完相应的逻辑之后，就需要释放同步同步状态，是的后续接待也可以获得同步状态。通过调用同步器的relaese(int arg)方法可以释放同步锁状态，该方法在释放了昂前线程的同步状态之后会唤醒其后继结点。下面是该方法的源码：

<img src="http://image.easyblog.top/1586593955570f293fa25-bf14-42e6-ad44-ff42e482a82f.png" alt="img" style="zoom:60%;" />

方法会首先调用 **tryRelaese(int args)** 释放同步状态，这个方法在AQS没有实现，需要子类实现具体的逻辑。tryRelaese(int args)返回true之后调用 **unparkSuccessor(h)** 方法,在这个方法内会使用LockSupport.unpark()方法唤醒当前结点的后继结点。



##### 20、基于AQS实现的Lock(ReentrantLock)、ConutDownLatch、CyclicBarrier和Semaphore介绍？

* **20.1、ReentrantLock （互斥锁）**：**ReentrantLock的作用和synchronize是一样的，都是实现互斥锁的功能，但是ReentrantLock需要手写代码对锁进行获取和释放(一定要在finally里面释放)，要不然就永远死锁了，ReentrantLock也可以用来做线程之间的挂起和通知，synchronize一般是使用object的wait和notify来实现，ReentrantLock使用Condition来实现线程之间的通信。**

* **20.2、ReentrantReadWriteLock（读写锁）**：ReentrantReadWriteLock锁是一个读写分离的锁，这种锁主要用于读多写少的业务场景，读写锁在同一时刻允许多个读线程访问，但是在写线程访问时，所有的读线程和其他线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读写锁，使得并发性比一般的排它锁有了很大提升。因为大多数应用场景都是读多于写的，因此在这样的情况下，读写锁可以提高吞吐量。读写锁有三个特性：公平性、重入性和锁降级。**口诀就是：读共享、写互斥、读写互斥。**

* **20.3、CountDownLatch（闭锁）**：CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。

	 **CountDownLatch 的两种应用场景**

	①某一线程在开始运行前等待n个线程执行完毕。将 CountDownLatch 的计数器初始化为n ：`new CountDownLatch(n)`，每当一个任务线程执行完毕，就将计数器减1 `countdownlatch.countDown()`，当计数器的值变为0时，在`CountDownLatch上 await()` 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

	②实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 `CountDownLatch` 对象，将其计数器初始化为 1 ：`new CountDownLatch(1)`，多个线程在开始执行任务前首先 `coundownlatch.await()`，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。

	**CountDownLatch 的不足**

	CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。

* **20.4、CyclicBarrier（循环栅栏）**：CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。

	**CyclicBarrier 的应用场景**

	CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个Excel保存了用户所有银行流水，每个Sheet保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet的日均银行流水，最后，再用barrierAction用这些线程的计算结果，计算出整个Excel的日均银行流水。

	**CyclicBarrier和CountDownLatch的区别**

	<img src="https://www.javazhiyin.com/wp-content/uploads/2018/11/java6-1543319916.png" alt="并发编程面试必备：AQS 原理以及 AQS 同步组件总结" style="zoom:67%;" />

* **20.5、Semaphore（信号量）**：**synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。**Semaphore 有两种模式，公平模式和非公平模式。

   - **公平模式：** 调用acquire的顺序就是获取许可证的顺序，遵循FIFO；
   - **非公平模式：** 抢占式的。

##### 21、非公平锁和公平锁

<img src="https://upload-images.jianshu.io/upload_images/5416516-4193bedd4a71ab02.png?imageMogr2/auto-orient/strip|imageView2/2/w/994/format/webp" alt="img" style="zoom:40%;" />

ReentrantLock是一个基于AQS实现的互斥锁，在他的构造方法中可以传入一个boolean类型的变量，当传入true的时候表示使用公平锁，否者默认会使用非公平锁。

* 非公平锁：多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。
	- 优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。
	- 缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。
* 公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。
	- 优点：所有的线程都能得到资源，不会饿死在队列中。
	- 缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。

ReentrantLock有一个内部类Sync，该类继承自AQS，实现了同步功能。同时该类还有两个子类**FairSync和NonFairSync**两个子类，分别表示公平类和非公平了

**公平锁和非公平锁的区别**

最大的区别就在于获取锁的时候由差异：

<img src="https://ss2.baidu.com/6ONYsjip0QIZ8tyhnq/it/u=1563127424,3811789047&fm=173&app=25&f=JPEG?w=640&h=1037&s=08607532091B404D1AF580DA0000C0B2" alt="img" style="zoom:60%;" />

分析以上代码，我们可以看到**公平锁就是在获取锁之前会先调用`hasQueuedProcessors()`方法来判断等待队列是否为空或者自己是否位于队列头部，该条件通过才能继续获取锁。**

##### 22、JUC原子类的实现原理？（以AtomicInteger为主讲解）

volatile不能解决num++这类复合类操作的原子性问题，相比锁机制，使用原子类更精巧。

悲观的解决方案（阻塞同步）：

​      num++操作，1.读取 2. 加一  3. 写入 三步组成的，就是复合类的操作，在并发环境下，如果不做不做何人同步处理，就会有线程安全问题。最直接的处理方式就是加锁。

```java
synchronized(this) {
    num++;
}
```

   使用独占锁机制来解决，是一种悲观的并发策略。每次操作数据时都认为别的线程会参与竞争修改，所以直接加锁。同一时刻只能用一个线程持有锁，那其他线程就会阻塞。线程的挂起和恢复会带来很大的性能开销。

乐观的解决策略：

​     就是每次操作数据的时候，都认为别的线程不会参与竞争修改，也不加锁。如果操作成功了那最好；如果失败了，如中途有别的线程进入并修改了数据，也不会阻塞，一般采用反复尝试的策略。

**以AtomicInteger的incrmentAndGet()为例**

```java
public final int incrementAndGet() {
        for (;;) {
            int current = get();
            int next = current + 1;
            if (compareAndSet(current, next))   //CAS保证原子性
                return next;
        }
}
 
public final boolean compareAndSet(int expect, int update) {
    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
}
```

incrementAndGet的逻辑：

1. 先获取当前的value值

  2. 对value加一

3. 第三步时关键，调用comparaAndSet方法来进行原子更新操作，语义是：

​     先检查当前value是否等于current,如果相等，则意味着value没被其他线程修改过，更新并返回true,如果不相等，compareAndSet则会返回false,然后继续尝试更新。其实就是**CAS算法**。

**总结**

（1）**AtomicInteger维护了一个volaitle修饰的int类型的变量value来存储实际的值，这是CAS和voaltile的金典结合，既保证了变量修改的原子性，同时有保证了可见性。**

（2）**AtomicInteger的核心方法都最终与Unsafe中的`compareAndSwapInt()`方法有关（CAS），这个方法保证了变量修改的原子性。**

（3）**AtomicInteger是CAS在Java中的典型实现，看上去很完美，但是它却没有解决CAS带来的一个大问题：ABA问题**

##### 23、Executor框架体系介绍？

<img src="http://image.easyblog.top/16013007894639841fb53-22df-4c33-8604-cef7d6539ae6.png" alt="img" style="zoom:67%;" />

1、最顶层的`Executor`是一个接口，它里面只有一个方法：**execute()**，用于向线程池提交任务。

2、Executor下有一个重要子接口`ExecutorService`，其中定义了线程池的具体行为

- 1，**execute（Runnable command）**：履行Ruannable类型的任务,
- 2，**submit（task）**：可用来提交Callable或Runnable任务，并返回代表此任务的Future对象
- 3，**shutdown（）**：有序的完成已提交的任务，但是不再接收新任务,
- 4，**shutdownNow（）**：停止所有正在执行的任务，暂停正在等待的任务的处理，并返回正在等待执行的任务的列表。
- 5，**isTerminated（）**：测试是否所有任务都执行完毕了。
- 6，**isShutdown（）**：测试是否该线程池是否被关闭。

3、`ThreadPoolExecutor`是Java中线程池的核心实现类，用来执行被提交的任务。接下来我们就以`ThreadPoolExecutor`为中心来探究一下Java中线程池的原理。

##### 24、线程池ThreadPoolExecutor作用、参数的含义、有几种？

**线程池的作用**

（1）**降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗 

（2）**提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。 

（3）**提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

**线程池的构造方法**

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
    //省略.....
}
```



##### 26、ThreadPoolExecutor有很4个构造方法，这里我用参数最全的一个来说明一下各个参数的含义：

- 1、**corePoolSize**：线程池中核心线程个数

- 2、**maximunPoolSize**：线程池最大允许的线程个数（这里有一个救急线程的概念，就是非核心线程，它的数量是maximunPoolSize-corePoolSize）

- 3、**keepAliveTime**：这个参数是给非核心线程设定的，他表示非核心线程可以空闲时间，超过这个时间就会被回收

- 4、**unit**：空闲时间的单位

- 5、**workQueue**：任务队列，它是一个阻塞队列，用于存放等待执行的任务。

- 6、**threadFactory**：线程工厂，用于创建线程以及可以给线程起一个有意义的名字

- 7、**RejectedExecutionHandler**：当任务队列和线程池都处于满负荷运行时，新提交的任务应该如何处理的策略，称为**饱和策略**。Java中提供的策略有以下4种：

	> （1）ThreadPoolExecutor.AbortPolicy：直接抛出异常，这是默认的策略
	>
	> （2）ThreadPoolExecutor.CallerRunsPolicy：让调用者来执行该任务
	>
	> （3）ThreadPoolExecutor.DisCardPolicy：不做任何处理，直接把任务丢掉，也不抛出任何异常
	>
	> （4）ThreadPoolExecutor.DisCardOldestPolicy：丢弃任务队列头部的任务，然后尝试执行当前任务

	当然，我们也可以根据我们的业务场景通过实现`RejectExeptionPolicy`接口实现自定义策略。

**线程池任务提交的流程**

![img](http://image.easyblog.top/158636140301387db9ed6-7a20-42db-94d6-5377024a8cc7.jpg)

* （1）首先会判断运行中的线程数是否小于corePoolSize，如果小于，则直接创建新的线程执行任务。
* （2）如果运行中的线程大于corePoolSize，判断workQueue任务队列是否已经满了，如果还没有满，则将任务放到任务队列中排队等待被处理；
* （3）如果workQueue任务队列满了，则判断当前线程数是否大于线程池的最大线程数，如果没有大于最大线程数则创建新的线程处理任务；
* （4）如果运行中的线程数大于最大线程数，则通过拒绝策略处理新提交的任务。在ThreadPoolExecutor中提供了4种拒绝策略：AbortPolicy：直接抛出异常，这是默认的策略；CallerRunsPolicy：让调用者来执行该任务；DisCardPolicy：不做任何处理，直接把任务丢掉，也不抛出任何异常；DisCardOldestPolicy：丢弃任务队列头部的任务，然后尝试执行当前任务

**如何合理配置线程池参数？**

要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析：

1. 任务的性质：CPU密集型任务，IO密集型任务和混合型任务。
2. 任务的优先级：高，中和低。
3. 任务的执行时间：长，中和短。
4. 任务的依赖性：是否依赖其他系统资源，如数据库连接。

任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能少的线程数量，如配置**Ncpu+1**个线程的线程池。IO密集型任务则由于需要等待IO操作，线程并不是一直在执行任务，则配置尽可能多的线程，如**2xNcpu**。混合型的任务，如果可以拆分，则将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过`Runtime.getRuntime().availableProcessors()`方法获得当前设备的CPU个数。

优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。

执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。

依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，如果等待的时间越长CPU空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用CPU。

并且，阻塞队列**最好是使用有界队列**，如果采用无界队列的话，一旦任务积压在阻塞队列中的话就会占用过多的内存资源，甚至会使得系统崩溃。

##### 26、阻塞队列有几种，分别都有哪些特性？

阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

<img src="http://image.easyblog.top/1587444510867628c9aac-b66a-488b-8165-365de883ebf5.jpg" alt="img" style="zoom:30%;" />

##### (1)、ArrayListBlockingQueue

ArrayListBlockingQueue是一个用数组实现的有界阻塞队列，此队列按照先进先出（FIFO）的原则对元素进行排序。支持公平锁和非公平锁（默认情况下是非公平锁）。

```java
public ArrayBlockingQueue(int capacity) {
    //默认使用的是非公平锁
    this(capacity, false);
}
//通过boolean类型的参数可以控制使用公平锁还是非公平锁
public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity <= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];
    lock = new ReentrantLock(fair);
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}
```

##### (2)、LinkedBlockingQueue

LinkedBlockingQueue是一个用**单链表**实现的有界阻塞队列。此队列的默认长度和最大长度为`Integer.MAX_VALUE`。此队列按照先进先出的原则对元素进行排序。

##### (3)、PriorityBlockingQueue

一个支持线程优先级排序的无界队列，默认自然序进行排序，也可以自定义实现compareTo()方法来指定元素排序规则，不能保证同优先级元素的顺序。

##### (4)、DelayQueue

DelayQueue是一个支持延时获取元素的无界阻塞队列。队列基于PriorityBlockingQueue实现。队列中的元素必须实现Delayed接口，在创建元素是可以指定多久才能从队列中获取当前元素。DelayQueue可以用于 **缓存系统设计** 和 **定时任务调度** 这样的应用场景。

##### (5)、SynchronousQueue

SynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。它支持公平访问队列。默认情况下线程采用非公共策略访问队列。**当使用公平锁的时候，等待的线程会采用先进先出的顺序访问队列**。

```java
//默认使用非公平锁
public SynchronousQueue() {
    this(false);
}
//通过boolean类型的参数可以控制使用公平锁还是非公平锁
public SynchronousQueue(boolean fair) {
    transferer = fair ? new TransferQueue<E>() : new TransferStack<E>();
}
```

##### ( 6)、LinkedTransferQueue

LinkedTransferQueue是一个由链表实现的无界阻塞Transfer队列。相对于其他阻塞队列，LinkedTransferQueue多了transfer和tryTransfer方法

##### (7)、LinkedBlockingDeque

LinkedBlockingDeque是一个由**双链表**实现的双向阻塞队列。队列头部和尾部都可以添加和移除元素，多线程并发时，可以将锁的竞争最多降到一半。

##### 27、Java中如何正常终止一个线程？

Java中停止一个线程正确的方式是使用interrupt()方法给线程一个中断信号，让线程处理完三后工作后自行结束，绝对不应该的是调用Thread类的stop()方法

关于使用interruput()方法来终止线程，最佳的说明文档就是javadoc了。在这个方法的javadoc上说明了在使用interruput()的三种情况：

- （1）如果当前线程处于阻塞状态：比如调用了sleep()、wait()以及重载方法、join()以及重载方法或者其他操作让当前线程进入到阻塞状态，**此时调用interrupt()，那么它的中断状态会被清除为false并且会收到一个InterruptedException异常**

	> 比如一个线程调用了wait()方法后处于阻塞状态，此时别处调用interrupt()后会立即将线程的中断标记设为“true”，但是由于线程处于阻塞状态，所以该“中断标记”会立即被清除为“false”，同时，会产生一个InterruptedException的异常。

- （2）如果线程被阻塞在一个Selector选择器中，那么通过interrupt()中断它时，线程的中断标记会被设置为true，并且它会立即从选择操作中返回。

- （3）线程未处于阻塞状态，那么通过interrupt()中断线程时，它的中断标记会被设置为“true”

##### 28、主线程可以捕获子线程的异常吗？

正常情况下，如果不做特殊的处理，在主线程中是不能够捕获到子线程中的异常的。如果想要在主线程中捕获子线程的异常，我们需要使用ExecutorService，同时做一些修改。

##### 29、as-if-serial语义和happens-before语义？

**as-if-serial语义**

无论如何重排序，单线程内程序的执行结果不能被改变。编译器、runtime和处理器都必须遵循as-if-serial语义。为了遵守这条语义，编译器和处理器不会对存在数据依赖关系的操纵进行重排序，反之，就会被重排序。

**happens-before语义**

JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，

那么这2个操作之间必须要存在happens-before关系。这里提到的2个操作既可以是一个线程之内，也可以是不同线程之间。

与程序员密切相关的happens-before规则如下： 
1、程序顺序规则：一个线程中的每个操作，happens-before于线程中的任意后续操作。 
2、监视器锁规则：一个锁的解锁，happens-before于随后对这个锁的加锁。 
3、volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 
4、传递性：如果A happens-before B，且Bhappens-before C，那么Ahappens-before C。 
需要注意的是： 
  两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！ 
happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第 
二个操作之前。 
  一个happens-before规则对应一个或多个编译器和处理器重排序规则。对于Java程序员来说， 
happens-before规则简单易懂，它避免Java程序员为了理解JMM提供的内存可见性保证而去 

学习复杂的重排序以及这些规则的具体实现方法。

##### 30、JMM内存模型

JMM就是 Java Memory Model 的缩写，中文名即Java内存模型。因为在不同的硬件生产商和不同的操作系统下，内存的访问有一定的差异，所以会造成相同的代码运行在不同的系统上会出现各种问题。所以**java内存模型(JMM)屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致的并发效果。**

Java内存模型将内存分为**主内存**和 **工作内存**两个部分，并且规定所有的变量都存储在主内存中，包括实例变量、静态变量，但是不包括局部变量和方法参数。每个线程都有自己的工作内存，**线程工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行。线程不能直接读写内存中的变量**。

**不同的线程之间也无法访问对方工作内存中的变量。线程之间变量值的传递均需要通过主内存来完成**。

 **主内存和本地内存结构**

从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。本地内存它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化之后的一个数据存放位置。

<img src="https://img-blog.csdn.net/20160507135725155" alt="è¿éåå¾çæè¿°" style="zoom:60%;" />

**JMM定义了什么？**

整个Java内存模型实际上是围绕着三个特征建立起来的。分别是：原子性，可见性，有序性。

**原子性**

原子性指的是一个操作是不可分割，不可中断的，一个线程在执行时不会被其他线程干扰。

**面试官拿笔写了段代码，下面这几句代码能保证原子性吗**？

```java
int i = 2;
int j = i;
i++;
i = i + 1;
```

第一句是基本类型赋值操作，必定是原子性操作。

第二句先读取i的值，再赋值到j，两步操作，不能保证原子性。

第三和第四句其实是等效的，先读取i的值，再+1，最后赋值到i，三步操作了，不能保证原子性。

JMM只能保证基本的原子性，如果要保证一个代码块的原子性，提供了monitorenter 和 moniterexit 两个字节码指令，也就是 synchronized 关键字。因此在 synchronized 块之间的操作都是原子性的。

**可见性**

可见性指当一个线程修改共享变量的值，其他线程能够立即知道被修改了。**Java是利用volatile关键字来提供可见性的**。 当变量被volatile修饰时，这个变量被修改后会立刻刷新到主内存，当其它线程需要读取该变量时，会去主内存中读取新值。而普通变量则不能保证这一点。

**除了volatile关键字之外，final和synchronized也能实现可见性**。

synchronized的原理是，在执行完，进入unlock之前，必须将共享变量同步到主内存中。

final修饰的字段，一旦初始化完成，如果没有对象逸出（指对象为初始化完成就可以被别的线程使用），那么对于其他线程都是可见的。

**有序性**

在Java中，**可以使用synchronized或者volatile保证多线程之间操作的有序性**。实现原理有些区别：

volatile关键字是使用内存屏障达到禁止指令重排序，以保证有序性。

synchronized的原理是，一个线程lock之后，必须unlock后，其他线程才可以重新lock，使得被synchronized包住的代码块在多线程之间是串行执行的。

**JMM的八种内存交互操作？**

<img src="http://image.easyblog.top/160109608021984ce7f47-7c02-405a-9f24-a737f6d0eb9a.png" alt="img" style="zoom:67%;" />

1. lock(锁定)，作用于**主内存**中的变量，把变量标识为线程独占的状态。
2. read(读取)，作用于**主内存**的变量，把变量的值从主内存传输到线程的工作内存中，以便下一步的load操作使用。
3. load(加载)，作用于**工作内存**的变量，把read操作主存的变量放入到工作内存的变量副本中。
4. use(使用)，作用于**工作内存**的变量，把工作内存中的变量传输到执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。
5. assign(赋值)，作用于**工作内存**的变量，它把一个从执行引擎中接受到的值赋值给工作内存的变量副本中，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作。
6. store(存储)，作用于**工作内存**的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的write使用。
7. write(写入)：作用于**主内存**中的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。
8. unlock(解锁)：作用于**主内存**的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。

再补充一下JMM对8种内存交互操作制定的规则：

- 不允许read、load、store、write操作之一单独出现，也就是read操作后必须load，store操作后必须write。
- 不允许线程丢弃他最近的assign操作，即工作内存中的变量数据改变了之后，必须告知主存。
- 不允许线程将没有assign的数据从工作内存同步到主内存。
- 一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use、store操作之前，必须经过load和assign操作。
- 一个变量同一时间只能有一个线程对其进行lock操作。多次lock之后，必须执行相同次数unlock才可以解锁。
- 如果对一个变量进行lock操作，会清空所有工作内存中此变量的值。在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值。
- 如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量。
- 一个线程对一个变量进行unlock操作之前，必须先把此变量同步回主内存。

#### JVM

#####  一、ClassLoader类加载器

**1、类加载过程**

类从被加载到虚拟机内存中开始，到卸载出内存为止，他的整个生命周期包括：**加载（Loading）**、**验证（Verify）**、**准备（Prepare）**、**解析（Resolve）**、**初始化（Initialization）**、**使用（Using）** 和**卸载（Unloading）**7个阶段。其中验证、准备和解析可以合起来统称为链接（Linking）。各个阶段的发生顺序：

<img src="http://image.easyblog.top/15813276429581b8a5e4a-b04d-4965-8ce5-ae24b2948fd1.jpg" alt="img" style="zoom:40%;" />

**加载**

**（1）类加载时机**

Java虚拟机中并没有明确规定类的加载时机，这个不同的虚拟机产品会有不同的实现。但是Java虚拟机规范中对于类的初始化阶段有明确的规定，当出现以下5种情况时必须立即对类进行初始化（间接说明了类的5种加载的时机）：

> 1. 当使用new关键字实例化对象、读取或设置一个类的静态字段、调用一个类的静态方法的时候
> 2. 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类还没有初始化过，则需要初始化
> 3. 当初始化一个类的时候如果发现他的父类还没有初始化，那么需要先初始化父类
> 4. 当虚拟机启动的时候，用户指定的执行主类（含有main方法的那个类）会优先初始化这个类
> 5. 当使用动态语言支持时如果一个java.lang.invoke.MethodHandle实例最后的解析结果为RET_getStatic、RET_putStatic、RET_invokeStatic的方法句柄，并且这个方法句柄所在的类没有进行初始化，则需要先初始化。

**（2）类加载流程**

在加载阶段，JVM完成下面3件事：

> 1. 通过一个类的全限定名来获取定义此类的二进制字节流
> 2. 将字节流所代表的静态存储结构转化为方法区的运行时数据结构
> 3. **在内存中生成一个代表这个类的java.lang.Class对象**，作为方法区这个类的各种数据的访问接口

总结一下，加载阶段JVM的工作就是：**将类.class字节码文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区中的数据结构**



**链接**

链接阶段具体有三个过程：**验证、准备和解析**。 

**（1）验证阶段**： **验证是链接的第一步，这一步的作用是为了确保class文件中字节流包含的信息符合虚拟机的要求，并且不会危害虚拟机的自生安全**。

> ​    验证大致上会完成下面4个阶段的检查动作：**文件格式验证**、**元数据验证**、**字节码验证**和**符号引用验证**。如果输入的字节流不符合class文件格式的约定，JVM就会抛出一个java.lang.VerifyError异常或其子类异常。

**Tips**：虚拟机的类加载机制中，验证阶段绝对是非常重要的一个阶段，但是它并不是必要的阶段。如果我们的程序（无论是我们自己写的还是第三方的）都已经被反复使用和验证的情况下，那么在真正运行的时候就可以考虑使用`-Xverify:none`来关闭大部分的类验证措施，以缩短类加载的时间。

**（2）准备阶段**

准备阶段是**JVM正式为类变量分配内存并为类变量设置初始值的阶段**，这些变量所使用的内存将在方法区中进行分配。**不过要清楚几点是**：

1）这个阶段给类变量设置的初始值并不是变量后面有程序员指定的值，而是统一设置为零值。正真指定的值这时是存放在类构造器<clinit>()方法中，例如下面的例子：

```css
 public static int a=100;   //在准备阶段变量a会在方法区中分得内存并被赋初值为0，之后又会在初始化阶段初始化为100
```

（2）即被static修饰同时又被final修饰的常量由于在编译的时候就被分配值了，准备阶段只会显示的初始化，也即准备阶段不会管这些常量的。 

（3）这里只会为一个类中的类变量分配内存并初始化零值，实例变量将会在对象实例化的时候随对象一起分>配在Java堆中。

**（3）解析阶段**

 解析阶段是**JVM将常量池的符号引用转换为直接引用的过程**。解析操作主要针对的类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定7类符号限定引用进行。



**初始化（Initialization）**

初始化阶段是类加载过程的最后一个阶段，到了这一步才正真开始执行类中定义的Java程序代码。**初始化阶段就是系统给类变量赋指定值并且执行静态代码块的阶段，或者说初始化阶段是执行类构造器<clinit>()方法的过程。**

关于 **<clinit>()** 方法我们需要明确下面几点：

> 1. <clinit>()方法是由javac编译器自动收集类中所有类变量的赋值动作和静态代码块中的语句合并而来，不需要人为定义。
> 2. <clinit>()方法虽然叫类构造器，但它与类的构造函数（类的构造函数在虚拟机视角下是<init>()方法）不同，他不需要显示的调用父类构造器，虚拟机会保证在子类的<clinit>()方法执行前，父类的<clinit>()方法已经执行完毕。
> 3. <clinit>()方法不是必须的，如果一个类中即没有静态语句块，也没有类变量，那么编译器就可以不为这个类生成<clinit>()方法。
> 4. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁、同步。如果有多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的<clinit>()方法，其他的线程都会阻塞。

**2、类加载器种类以及加载范围**

从JVM的角度来讲，只存在两种不同的类加载器：引导类加载器（Bootstrap ClassLoader）和用户自定义类加载器。之所以这样划分是因为引导类加载器是使用C++实现的，它是虚拟机的一部分，而其他的加载器（比如扩展类加载器、应用类加载器......）都是使用Java语言实现的，独立于虚拟机外部，并且都直接或间接的继承自`java.lang.ClassLoader`这个抽象类。

但是从Java开发人员的角度来看，JVM的类加载器可以细分为以下几种：

**（1）启动类加载器（Bootstrap ClassLoader）**

> 1）启动类加载器使用C++语言实现，它就是JVM的组成部分 
>
> 2）它用来加载Java的核心类库（$JAVA_HOME/jre/lib/rt.jar、resoures.jar，sun.boot.class.path路径下的内容），用于提供JVM自身需要的类（大致就是以java、javax、sun开头的类库） 
>
> 3）由于是使用C++实现的，因此它不继承自java.lang.Classloader，也没有父加载器，并且启动类加载器无法被Java程序直接引用，如果尝试获取启动类加载器，那么一定返回的是null

**（2）扩展类加载器（Extension ClassLoader）**

由Java语言实现，具体的实现在sun.misc.Launcher$ExtClassLoader这个内部类中，他派生与ClassLoader，主要负责加载$JAVA_HOME/jre/lib/ext目录中的类库，或者被java.ext.dirs系统变量所指定的路径中的所有类库。

**（3）应用类加载器（Application ClassLoder）**

由sun.misc.Launcher$AppClassLoader实现。由于这个类加载器是ClassLoader中getSystemClassLaoder()方法的返回值，因此也称其为系统类加载器。它一般负责加载用户路径（ClassPath）上的类库，我们自己写的类一般情况下就是通过这个类加载器加载的。下图时ClassLoader、ExtClassLoader、AppClassloader之间在语言层面的继承关系



**3、双亲委派是什么**

<img src="http://image.easyblog.top/15813186368441321d601-da6e-4b34-a8cf-1e7dc59fb779.jpg" alt="img" style="zoom:40%;" />

**双亲委派机制工作原理**

* 1）如果一个类加载器收到了类加载的请求，他不会自己立即去加载，而是把这个加载请求委托给父级加载器执行加载请求；
* 2）如果一个父级加载器还存在父级加载器，则进一步向上委托，依次递归，请求最终会传达到最顶层的启动类加载器；
* 3）如果父级加载器可以完成加载任务，就成功返回，倘若父级加载器无法完成加载任务，则它的子级类加载器才会尝试自己加载，如果还是不行在给子级加载器的子级加载器去加载，这就是双亲委派机制。

**需要注意的是**： 1. 双亲委派模型示意图所展示的不是几种类加载器的继承关系，而是他们在加载一个类的时候的委托关系（优先级关系），而这些类本质上也并不存在继承关系，示意图中所展示的只是一种层级（阶级）关系 2. 一个类如果所有的类加载器都加载失败，那么系统就会抛出`ClassNotFoundException`异常

另外，双亲委派机制实在ClassLoader类的loadClass()方法中实现的，因此如果不想使用算清委派机制，可以重写这个方法，但是一般不建议重写该方法。

**双亲委派机制的好处**（为什么需要双亲委派机制？）

1）可以避免一个类被重复加载 2）可以保护程序安全，尤其是核心API不会遭到随意篡改

**4、为什么需要破坏双亲委派模型（线程上下文类加载器了解吗）**

Java 提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现。常见的 SPI 有 JDBC、JCE、JNDI、JAXP 和 JBI 等。

这些 SPI 的接口由 Java 核心库来提供，而这些 SPI 的实现代码则是作为 Java 应用所依赖的 jar 包被包含进类路径（CLASSPATH）里。SPI接口中的代码经常需要加载具体的实现类。那么问题来了，SPI的接口是Java核心库的一部分，是由**启动类加载器(Bootstrap Classloader)来加载的；SPI的实现类是由系统类加载器(System ClassLoader)**来加载的。引导类加载器是无法找到 SPI 的实现类的，因为依照双亲委派模型，BootstrapClassloader无法委派AppClassLoader来加载类。

而线程上下文类加载器破坏了“双亲委派模型”，可以在执行线程中抛弃双亲委派加载链模式，使程序可以逆向使用类加载器。

**Tomcat与spring的类加载器案例**

接下来将介绍《深入理解java虚拟机》一书中的案例，并解答它所提出的问题。（部分类容来自于书中原文）

**Tomcat中的类加载器**

在Tomcat目录结构中，有三组目录（“/common/*”,“/server/*”和“shared/*”）可以存放公用Java类库，此外还有第四组Web应用程序自身的目录“/WEB-INF/*”，把java类库放置在这些目录中的含义分别是：

- 放置在common目录中：类库可被Tomcat和所有的Web应用程序共同使用。
- 放置在server目录中：类库可被Tomcat使用，但对所有的Web应用程序都不可见。
- 放置在shared目录中：类库可被所有的Web应用程序共同使用，但对Tomcat自己不可见。
- 放置在/WebApp/WEB-INF目录中：类库仅仅可以被此Web应用程序使用，对Tomcat和其他Web应用程序都不可见。

为了支持这套目录结构，并对目录里面的类库进行加载和隔离，Tomcat自定义了多个类加载器，这些类加载器按照经典的双亲委派模型来实现，如下图所示

<img src="https://img-blog.csdn.net/20160925001518808" alt="Tomcatä¸­çç±»å è½½å¨" style="zoom:33%;" />

灰色背景的3个类加载器是JDK默认提供的类加载器，这3个加载器的作用前面已经介绍过了。而 CommonClassLoader、CatalinaClassLoader、SharedClassLoader 和 WebAppClassLoader 则是 Tomcat 自己定义的类加载器，它们分别加载 /common/*、/server/*、/shared/* 和 /WebApp/WEB-INF/* 中的 Java 类库。其中 WebApp 类加载器和 Jsp 类加载器通常会存在多个实例，每一个 Web 应用程序对应一个 WebApp 类加载器，每一个 JSP 文件对应一个 Jsp 类加载器。

从图中的委派关系中可以看出，CommonClassLoader 能加载的类都可以被 CatalinaClassLoader 和 SharedClassLoader 使用，而 CatalinaClassLoader 和 SharedClassLoader 自己能加载的类则与对方相互隔离。WebAppClassLoader 可以使用 SharedClassLoader 加载到的类，但各个 WebAppClassLoader 实例之间相互隔离。而 JasperLoader 的加载范围仅仅是这个 JSP 文件所编译出来的那一个 Class，它出现的目的就是为了被丢弃：当服务器检测到 JSP 文件被修改时，会替换掉目前的 JasperLoader 的实例，并通过再建立一个新的 Jsp 类加载器来实现 JSP 文件的 HotSwap 功能。

5、如何破坏双亲委派模型

重写ClassLoader类的`loadClass()`方法，别重写`findClass`方法，因为`loadClass`是核心入口，将其重写成自定义逻辑即可破坏双亲委派模型。

6、如何自定义一个类加载器

只需要继承`java.lang.Classloader`类，然后覆盖他的`findClass(String name)`方法即可，该方法根据参数指定的类名称，返回对应 的Class对象的引用。

**自定义类加载器示例**

**自定义类加载器 CustomClassLoader：** 继承ClassLoader，重写findClass()方法，在findClass方法中使用文件IO将需要加载的类读取到byte数组中就OK了，之后交给defineClass方法处理就可以了。

```java
public class CustomClassLoader extends ClassLoader {

    //类的路径
    private String classPath;

    public CustomClassLoader(String classPath) {
        this.classPath = classPath;
    }

    //name表示这个类的类的全限定名
    @Override
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        byte[] bytes = null;
        InputStream is = null;
		//将类名中的.转换为路径符号/
        name = name.replaceAll("\\.", "/");
        ByteArrayOutputStream out = new ByteArrayOutputStream();
        try {
		    //读取class文件的流
            is = new FileInputStream(new File(classPath+"/"+name+".class"));
            int len = 0;
            while (-1 != (len = is.read())) {
                out.write(len);
            }
            bytes = out.toByteArray();
        } catch (Exception e) {
            e.printStackTrace();
        }finally {
            try {
                assert is != null;
                is.close();
                out.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if(bytes==null){
            throw new ClassNotFoundException();
        }
        return defineClass(name,bytes,0,bytes.length);
    }
}
```

**测试代码**

```java
public class AppTest {

    @Test
    public void test(){
        try {
            //Car E:\IDE Java Files\LeetCode\algorithm\src\main\java\algorithm\greedy\Car.java
            CustomClassLoader classLoader = new CustomClassLoader("E:\\IDE Java Files\\LeetCode\\algorithm\\src\\main\\java");
            Class clazz = classLoader.loadClass("algorithm.greedy.Car");
            Object o = clazz.newInstance();
            Method print = clazz.getDeclaredMethod("print", null);
            print.invoke(o, null);
           /* Car car = new Car();
            car.print();*/
        }catch (Exception e){
            e.printStackTrace();
        }
    }

}
```

**7、热部署原理**

采取破坏双亲委派模型的手段来实现热部署，默认的`loadClass()`方法先找缓存，你改了class字节码也不会热加载，所以自定义ClassLoader，去掉找缓存那部分，直接就去加载，也就是每次都重新加载。

#####  二、Java内存区域

1、Java内存结构

<img src="https://image.easyblog.top/jvm-pic.jpg" style="zoom:67%;" />

**程序计数器**

程序计数器（Program Conputer Register）这是一块较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器，在虚拟机的概念模型里，字节码解释器的工作就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。

　　**①、线程私有**

　　Java虚拟机支持多线程，是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任一确定的时刻，一个处理器只会执行一条线程中的指令，因此为了线程切换后能恢复到正确的执行位置，每条线程都需要一个独立的程序计数器。因此线程启动时，JVM 会为每个线程分配一个PC寄存器（Program Conter，也称程序计数器）。

　　**②、记录当前字节码指令执行地址**

　　如果当前线程执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是 Native 方法，则这个计数器值为空（Undefined）。

　　**③、不抛 OutOfMemoryError 异常**

　　程序计数器的空间大小不会随着程序执行而改变，始终只是保存一个 returnAdress 类型的数据或者一个与平台相关的本地指针的值。所以该区域是Java运行时内存区域中唯一一个Java虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。

**虚拟机栈**

Java虚拟机栈（Java Virtual Machine stack），这块区域也是线程私有的，与线程同时创建，用于存储栈帧。Java 每个方法执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息，每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。

<img src="https://images2018.cnblogs.com/blog/1120165/201807/1120165-20180722152410736-914758638.png" alt="img" style="zoom:50%;" />

**①、线程私有**

　　随线程创建而创建，声明周期和线程保持一致。

**②、由栈帧组成**

　　线程每个方法被执行的时候都会创建一个栈帧，用于存储局部变量表、操作栈、动态链接、方法出口等信息，每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。

**③、抛出 StackOverflowError 和 OutOfMemoryError 异常**

　　如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常；如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。

**本地方法栈**

本地方法栈（Native Method Stacks）作用和虚拟机栈类型，虚拟机栈执行的是Java方法，本地方法栈执行的是 Native 方法，本地方法栈也会抛出抛出 StackOverflowError 和 OutOfMemoryError 异常。

注意：由于虚拟机规范并没有对本地方法栈中的方法使用语言、使用方式和数据结构强制规定，因此具体的虚拟机可以自由实现它。上图我们也给出在 HotSpot 虚拟机中，本地方法栈和虚拟机栈合为一体了。

**Java堆**

Java堆是Java虚拟机所管理内存最大、被所有线程共享的一块区域，目的是用来存放对象，基本上所有的对象实例和数组都在堆上分配（不是绝对）。Java堆也是垃圾回收器管理的主要区域。

**①、线程共享**

堆存放的对象，某个线程修改了对象属性，另外一个线程从堆中获取的该对象是修改后的对象，为什么堆要设计成线程共享呢？

我们可以假设堆是线程私有的，很显然一个系统创建的对象会有很多，而且有些对象会比较大，如果设计成线程私有的，那么如果有很多线程同时工作，那么都必须给他们分配相应的私有内存，我相信内存很快就撑爆了，很显然将堆设计为线程共享是最好不过了，不过凡事都具有两面性，线程共享的设计这也带来了**多线程并发资源冲突问题**，关于这个问题由于不是本系列博客的主旨，这里就不做详细介绍了。

**②、存放对象**

基本上所有的对象实例和数组都要在堆上进行分配，但是随着 JIT 编译器的发展和逃逸分析技术的成熟，栈上分配、标量替换等优化技术会导致对象不一定在堆上进行分配。

**③、垃圾收集**

　　Java堆也被称为“GC堆”，是垃圾回收器的主要操作内存区域。当前垃圾回收器都是使用的分代收集算法，所以Java堆还可以分为：新生代和老年代，而新生代又可以分为 Eden 空间、From Survivor 空间、To Survivor空间。这是为了更好的回收内存，关于垃圾回收算法在后续博客会详细介绍。

<img src="http://image.easyblog.top/1581945296692366e8ad8-8995-4e99-9631-e5e9e10b617b.png" alt="img" style="zoom:67%;" />

**④、抛出 OutOfMemoryError 异常**

　　根据Java虚拟机规范，Java堆可以处于物理上不连续的内存空间中，只要逻辑上连续即可，实现时既可以实现成固定大小，也可以是扩展的。如果在堆中没有完成实例分配，并且堆也无法扩展，将抛出OutOfMemoryError 异常。

**方法区**

方法区（Method Area）用来存储已被Java虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

方法区也称为“永久代”，这是因为垃圾回收器对方法区的垃圾回收比较少，主要是针对常量池的回收以及对类型的卸载，回收条件比较苛刻。经常会导致对此内存未完全回收而导致内存泄露，最后当方法区无法满足内存分配时，将抛出 OutOfMemoryError 异常。

在JDK1.8 的 HotSpot 虚拟机中，已经去掉了方法区的概念，用 Metaspace 代替，并且将其移到了本地内存来规划了。

**运行时常量池**

在Java虚拟机规范中，运行时常量池（Runtime Constant Pool）用于存放编译期生成的各种字面量和符号引用，是**方法区**的一部分。但是Java虚拟机规范对其没有做任何细节的要求，所以不同虚拟机实现商可以按照自己的需求来实现该区域，比如在 **HotSpot** 虚拟机实现中，就将运行时常量池移到了堆中。

**①、存放字面量、符号引用、直接引用**

　　通常来说，该区域除了保存Class文件中描述的引用外，还会把翻译出来的直接引用也存储在运行时常量池，并且Java语言并不要求常量一定只能在编译器产生，运行期间也可能将常量放入池中，比如String类的intern()方法，**当调用intern方法时，如果池中已经包含一个与该`String`确定的字符串相同`equals(Object)`的字符串，则返回该字符串。否则，将此String对象添加到池中，并返回此对象的引用。**。

**②、抛出 OutOfMemoryError 异常**

　　运行时常量池是方法区的一部分，会受到方法区内存的限制，当常量池无法申请到内存时，会抛出该异常。

**直接内存**

直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，它也不是Java虚拟机规范定义的内存区域。我们可以看到在 HotSpot 中，就将方法区移除了，用元数据区来代替，并且将元数据区从虚拟机运行时数据区移除了，转到了本地内存中，也就是说这块区域是受本机物理内存的限制，当申请的内存超过了本机物理内存，才会抛出 OutOfMemoryError 异常。

直接内存也是受本机物理内存的限制，在JDK1.4中新加入的 NIO（new input/output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer 对象作为这块内存的引用操作，这样避免了在Java堆和Native堆中来回复制数据，显著提高性能。

2、对象创建时堆内存分配算法

- 指针碰撞

> 前提要求堆内存的绝对工整的。
>
> 所有用过的内存放一边，没用过的放另一边，中间放一个分界点的指示器，当有对象新生时就已经知道大小了，指示器只需要像没用过的内存那边移动与对象等大小的内存区域即可。

<img src="https://image.easyblog.top/%E6%8C%87%E9%92%88%E7%A2%B0%E6%92%9E.jpg" style="zoom:40%;" />

- 空闲列表

> 假设堆内存并不工整，那么空闲列表最合适。
>
> JVM维护一个列表 ，记录哪些内存块是可用的，当对象创建时从列表中找到一块足够大的空间划分给新生对象，并将这块内存标记为已用内存。

<img src="https://image.easyblog.top/%E7%A9%BA%E9%97%B2%E5%88%97%E8%A1%A8.jpg" style="zoom:50%;" />

**3、对象在内存中的存储布局**

在HotSpot虚拟机中对象在内存中的存储布局可以分为：**对象头、实例数据和对齐填**充3部分。

<img src="http://image.easyblog.top/159427348170717f20231-8e84-46f2-8ae5-b4fed58c5c9f.png" alt="img" style="zoom:50%;" />

**（1）对象头（Object Header）**

对象头在HotSpot虚拟机中被分为了两部分，**一部分官方称为Mark Word;另一部分是类型指针**。如果对象是一个Java数组，那在对象头中还有一块用于记录数组长度的数据。

<img src="http://image.easyblog.top/15822769154174f52765f-4a90-4384-aed8-2f530eb98f2b.png" alt="img" style="zoom:80%;" />

* 第一部分**Mark Word用于存储对象自身的运行时数据**，如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、对象分代年龄等信息。
* 第二部分是**类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例**。在不开启类指针压缩（-XX:+UseCompressedClassPointers）的情况下是8字节。压缩后变为4字节，默认压缩。 通过命令：`java -XX:+PrintCommandLineFlags -version` 查看classPointer是否开启压缩

**（2）实例数据（Instance Data）**

 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。     这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在 Java 源码中定义顺序的影响。

**（3）对齐填充**

由于HotSpot VM的自动内存管理系统要求对象的起始地址必须是8字节的整数倍，即：Java对象的大小必须是8字节的整数倍，而对象头的大小正好是8字节的整数倍，所以当对象的实例数据没有对齐的时候，就需要对齐填充来补全。因此对齐填充并不是必须存在的，也没有特殊的含义，它仅仅起到了占位符的作用。

**4、对象怎么定位**

目前主流的对象访问方式有使用**句柄** 和 **直接指针**两种方式。

**（1）句柄访问**     

在Java堆内存中划分一块内存专门用来作为句柄池，JVM桟的局部变量表的reference存储对象的句柄地址，而句柄中保存了对象实例数据与类型数据的具体地址，如下图所示：

<img src="http://image.easyblog.top/1582280468345e2700388-2407-422f-8c39-d74306d2a90e.jpg" alt="enter image description here" style="width:60%;" />

使用句柄方式最大的好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。

**（2）直接指针访问**

​    此时reference直接存储对象在堆中的地址，不再需要句柄池，这样做最大的好处是提高了性能，因为它节省了一次指针定位的时间开销。然而这也是HotSpot VM所选择的对象访问方式。

<img src="http://image.easyblog.top/1582280393660ad3239df-e018-4404-8174-319e5ceb4e47.jpg" alt="直接指针访问" style="width:60%;" />

**5、判断对象是否能被回收的算法**

* **①、引用计数算法**

	　　这种算法是这样的：给每一个创建的对象增加一个引用计数器，每当有一个地方引用它时，这个计数器就加1；而当引用失效时，这个计数器就减1。当这个引用计数器值为0时，也就是说这个对象没有任何地方在使用它了，那么这就是一个无效的对象，便可以进行垃圾回收了。这种算法实现简单，而且效率也很高。但是**Java没有采用该算法来进行垃圾回收**，因为这种算法无法解决对象之间的循环引用问题。

	**②、根搜索算法**

	这里直接给出结论：**在主流的商用程序中（Java，C#），都是使用根搜索算法（GC Roots Tracing）来判定对象是否存活。** 

	该算法思路：通过一系列名为“GC Roots” 的对象作为终点，当一个对象到GC Roots 之间无法通过引用到达时，那么该对象便可以进行回收了。

	<img src="http://image.easyblog.top/1582340634188cbd9a85a-2a5a-48ef-acf6-bca177d9caad.jpg" alt="img" style="zoom:60%;" />

	如上图所示，GC Roots到Object1、Object2、Object3、Object4都是可达的（可达意为GC Roots沿着某条路径（引用链）一定可以找到该对象），但是GC Roots到Object5、Object6、Object7没有可达的引用链，因此它们将会被判断为可回收的对象。

	- 优点：更加精确和严谨，可以分析出循环数据结构相互引用的情况；
	- 缺点：实现比较复杂、需要分析大量数据，消耗大量时间、分析过程需要GC停顿（引用关系不能发生变化），即停顿所有Java执行线程（称为"Stop The World"，是垃圾回收重点关注的问题）。

	在Java语言中可以作为**GC Roots的对象有以下几种**

	（1）**虚拟机桟桟帧中的局部变量表所引用的对象。** 

	（2）**方法区中类的静态的属性所引用的对象**。 

	（3）**方法区中常量引用的对象**。 

	（4）**本地方法桟中本地方法所引用的对象**。

6、如何判断对象是否能被回收/finalize方法回收对象两次标记过程（宣告一个对象的死亡）

**当一个对象被GC Roots标记为不可用之后，要宣告一个对象的死亡还要至少经过两次标记**：

（1）当一个对象通过可达性分析发现CG Roots与他不可达，那他会被第一次标记并且进行第一次筛选，筛选的条件是此对象的finalize()方法是否有必要执行。当对象的finalize方法没有重写或已经被执行过了，那么将不会再执行，那么此对象就会立即被宣告死亡。

（2）如果这个对象有必要执行 finalize() 方法，那么该**对象将会被放置在一个由虚拟机自动建立、低优先级，名为 F-Queue 队列中，GC会对F-Queue进行第二次标记**，如果对象在finalize() 方法中成功拯救了自己（比如重新与GC Roots建立连接），那么第二次标记时，就会将该对象移除即将回收的集合，否则就会被回收。

**7、Java堆内存组成部分**

<img src="https://image.easyblog.top/heap.jpg" style="zoom:50%;" />

堆大小 = 新生代 + 老年代。如果是Java8则没有Permanent Generation，Java8将此区域换成了Metaspace。

其中新生代(Young) 被分为 Eden和S0（from)和S1(to)。

默认情况下Edem : from : to = 8 : 1 : 1﻿，此比例可以通过 –XX:SurvivorRatio 来设定

**8、什么时候抛出StackOverflowError**

方法运行的时候栈的深度超过了虚拟机容许的最大深度的时候，所以不推荐递归的原因之一也是因为这个，效率低，死归的话很容易就StackOverflowError了。

9、Java中会存在内存泄漏吗，请简单描述。(参考Java基础部分，有详细答案)

**10、栈帧是什么？包含哪些东西**

<img src="http://image.easyblog.top/1581509922671b475799d-b825-4c79-b2cc-8277c5786dcc.jpg" alt="img" style="width:60%;" />

（1） 桟内存**线程私有**的，它的**生命周期与线程相同**（即随着线程的创建而创建，随着线程的销毁而销毁） 

（2）虚拟机桟描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个 **桟帧** 用于存储 **局部变量表（Local Variables）、操作数桟（Operand Stack）、动态链接（Dynamic Linking）、方法返回地址（Return Address）** 等信息。新创建的桟帧会被保存到Java虚拟机栈的栈顶，方法执行完毕后自动将此桟帧出栈。一般我们把虚拟机桟栈顶的桟帧称作当前方法。

**11、简述一个方法的执行流程**

方法的执行到结束其实就是栈帧的入栈到出栈的过程，方法的局部变量会存到栈帧中的局部变量表里，递归的话会一直压栈压栈，执行完后进行出栈，所以效率较低，因为一直在压栈，栈是有深度的。

**12、方法区会被回收吗**

方法区回收价值很低，主要回收废弃的常量和无用的类。

如何判断无用的类：

- 该类所有实例都被回收（Java堆中没有该类的对象）
- 加载该类的ClassLoader已经被回收
- 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方利用反射访问该类

13、一个Object对象包含多少个字节?

会占用16个字节。比如`Object obj = new Object();`

因为obj引用占用栈的4个字节，new出来的对象占用堆中的8个字节，4+8=12，但是对象要求都是8的倍数，所以对象的字节对齐（Padding）部分会补齐4个字节，也就是占用16个 字节。

再比如：

```java
public class NewObj {
    int count;
    boolean flag;
    Object obj;
}
NewObj obj = new NewObj();
```

这个对象大小为：空对象8字节+int类型4字节+boolean类型1字节+对象的引用4字节=17字节，需要8的倍数，所以字节对齐需要补充7个字节，也就是这段程序占用24字节。

**14、为什么把堆栈分成两个**

- 栈代表了处理逻辑，堆代表了存储数据，分开后逻辑更清晰，面向对象模块化思想。

	栈是线程私有，堆是线程共享区，这样分开也节省了空间，比如多个栈中的地址指向同一块堆内存中的对象。

- 栈是运行时的需要，比如方法执行到结束，栈只能向上增长，因此会限制住栈存储内容的能力，而堆中的对象是可以根据需要动态增长的。

**15、栈的起始点是哪**

main函数，也是程序的起始点。

**16、为什么基本类型不放在堆里**

因为基本类型占用的空间一般都是1-8个字节（所需空间很少），而且因为是基本类型，所以不会出现动态增长的情况（长度是固定的），所以存到栈上是比较合适的。反而存到可动态增长的堆上意义不大。

**17、Java参数传递是值传递还是引用传递**

值传递。

基本类型作为参数被传递时肯定是值传递；引用类型作为参数被传递时也是值传递，只不过“值”为对应的引用。假设方法参数是个对象引用，当进入被调用方法的时候，被传递的这个引用的值会被程序解释到堆中的对象，这个时候才对应到真正的对象，若此时进行修改，修改的是引用对应的对象，而不是引用本身，也就是说修改的是堆中的数据，而不是栈中的引用。

**18、为什么不推荐递归**

因为递归一直在入栈入栈，短时间无法出栈，导致栈的压力会很大，栈也有深度的，容易爆掉，所以效率低下。

**19、为什么参数大于2个要放到对象里**

因为除了double和long类型占用局部变量表2个slot外，其他类型都占用1个slot大小，如果参数太多的话会导致这个栈帧变大，因为slot大，放个对象的引用上去的话只会占用1个slot，增加堆的压力减少栈的压力，堆自带GC，所以这点压力可以忽略。

**20、对象的创建过程**

一个Java对象的创建过程往往包括 **类初始化** 和 **类实例化** 两个阶段。在前面的类加载流程我们探讨了Java类的加载流程，这里我们来讨论一下Java类的实例化流程。

**1）类加载检查**

虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程，具体加载过程这里略过。

**2）分配内存（指针碰撞和空闲列表的选择）**

在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。

* （1）**指针碰撞**：假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。

* （2）**空闲列表**：如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记 录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例， 并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。

* （3）选择依据：选择哪种分配方式由 Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决 定。因此，在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。

HotSpot采取G1垃圾回收器，其具有压缩整理功能，系统采用的分配算法是指针碰撞。

**3）并发处理**

对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的， 可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来 分配内存的情况。解决这个问题有两种方案，一种是对分配内存空间的动作进行同步处理 ——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；另一种是把内存分 配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）。哪个线程要分配内 存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。 虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。

**4）零值初始化**

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作解释了对象的实例字段在Java代码中为什么可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

**5）设置对象头**

接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对 象头（Object Header）之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了。但从Java程 序的视角来看，对象创建才刚刚开始——＜init＞方法还没有执行，所有的字段都还为零。

**6）执行初始化和构造器**

class是从子类到基类依次查找，有关静态初始化的动作从基类到子类依次执行。在为所创建对象的存储空间清零后，找到继承链中最上层的基类： 然后从基类到子类依次执行以下这两步操作。

（1）执行其出现在域定义处的初始化动作 ；
（2）然后再执行其构造器 。

#####   三、GC垃圾回收

**1、GC是什么？为什么要GC**

GC：垃圾收集，GC能帮助我们自动释放jvm内存，可以一定程度避免OOM问题，但是也无法完全避免。Java的GC是自动工作的，不像C++需要主动调用。

当new对象的时候，GC就开始监控这个对象的地址大小和使用情况了，通过可达性分析算法寻找不可达的对象然后进行标记看看是否需要GC回收掉释放内存。

**2、你能保证GC执行吗？**

不能，我只能通过手动执行`System.gc()`方法通知GC执行，但是他是否执行的未知的。

**3、对象的引用类型有哪几种，分别介绍下**

**（1）强引用**

类似`Object obj=new Object()`这样的引用方式就是强引用，**只有所有的GC Roots对象都不通过强引用引用该对象的时候，该对象才能被垃圾回收**。日常开发中，使用最多的可能就是强引用了吧！

**（2）软引用**

对于只有软引用的对象而言，当系统内存空间足够时，它不会被系统回收；如果内存空间不足了，就会被回收。软引用可以使用`SoftReference<V>`类来实现并且可以配合引用队列来释放软引用自身

使用场景：软引用可以用于存放一些重要性不是很强又不能随便让清除的对象，比如图片编辑器、视屏编辑器、缓存等

**（3）弱引用**

对于只有弱引用的对象而言，当系统垃圾回收机制运行时，不管系统内存是否足够，该对象所占用的内存一定会被回收。在不需要的时候，让JVM自动帮我们处理掉它们。弱引用可以使用`WeakReference<V>`类来实现。同理可以配合引用队列来释放弱引用自身

使用场景：ThreadLocal中的ThreadLocalMap中的key和ThreadLocal对象之间就是弱引用；WeakHashMap类中的key

**（4） 虚引用**

如果一个对象只有一个虚引用时，那么它和没有引用的效果大致相同。

使用场景：用于对象销毁前的一些操作，比如说资源释放等

**4、垃圾收集算法有哪些**

垃圾回收涉及到大量的程序细节，而且各个平台的虚拟机操作内存的方式也不一样，但是他们进行垃圾回收的算法是通用的，所以这里我们也只介绍几种通用算法。

**①、标记-清除算法**

**算法实现**：分为标记-清除两个阶段，首先根据上面的根搜索算法标记出所有需要回收的对象，在标记完成后，然后在统一回收掉所有被标记的对象。

**缺点**：

1、效率低：标记和清除这两个过程的效率都不高。

2、容易产生内存碎片：因为内存的申请通常不是连续的，那么清除一些对象后，那么就会产生大量不连续的内存碎片，而碎片太多时，当有个大对象需要分配内存时，便会造成没有足够的连续内存分配而提前触发垃圾回收，甚至直接抛出OutOfMemoryExecption。

<img src="https://img2018.cnblogs.com/blog/1120165/201907/1120165-20190701213406016-286379646.png" alt="img" style="zoom:50%;" />

**②、复制算法**

为了解决标记-清除算法的两个缺点，复制算法诞生了。

**算法实现**：将可用内存按容量划分为大小相等的两块区域，每次只使用其中一块，当这一块的内存用完了，就将还活着的对象复制到另一块区域上，然后再把已使用过的内存空间一次性清理掉。

**优点**：每次都是只对其中一块内存进行回收，不用考虑内存碎片的问题，而且分配内存时，只需要移动堆顶指针，按顺序进行分配即可，简单高效。

**缺点**：将内存分为两块，但是每次只能使用一块，也就是说，机器的一半内存是闲置的，这资源浪费有点严重。并且如果对象存活率较高，每次都需要复制大量的对象，效率也会变得很低。

<img src="https://img2018.cnblogs.com/blog/1120165/201907/1120165-20190701215336656-48891683.png" alt="img" style="zoom:50%;" />

 **③、标记-整理算法**

上面我们说过复制算法会浪费一半的内存，并且对象存活率较高时，会有过多的复制操作，效率低下。

如果对象存活率很高，基本上不会进行垃圾回收时，标记-整理算法诞生了。

**算法实现**：首先标记出所有存活的对象，然后让所有存活对象向一端进行移动，最后直接清理到端边界以外的内存。

**局限性**：只有对象存活率很高的情况下，使用该算法才会效率较高。

<img src="https://img2018.cnblogs.com/blog/1120165/201907/1120165-20190701215456537-787486222.png" alt="img" style="zoom:50%;" />

以上三种垃圾回收算法是JVM垃圾回收器最常使用的三种算法模型，基于这个算法，JVM中有一个**分代回收模型**。

模型实现：根据对象的存活周期不同将内存分为几块，然后不同的区域采用不同的回收算法。

1、对于存活周期较短，每次都有大批对象死亡，只有少量存活的区域，采用复制算法，因为只需要付出少量存活对象的复制成本即可完成收集；

2、对于存活周期较长，没有额外空间进行分配担保的区域，采用标记-整理算法，或者标记-清除算法。

比如，对于 HotSpot 虚拟机，它将堆空间分为如下两块区域：

<img src="http://image.easyblog.top/1581945296692366e8ad8-8995-4e99-9631-e5e9e10b617b.png" alt="img" style="zoom:67%;" />

堆有新生代和老年代两块区域组成，而新生代区域又分为三个部分，分别是 Eden,From Surivor,To Survivor ,比例是8:1:1。

新生代一般采用复制算法，每次使用一块Eden区和一块Survivor区，当进行垃圾回收时，将Eden和一块Survivor区域的所有存活对象复制到另一块Survivor区域，然后清理到刚存放对象的区域，依次循环。

老年代一般采用标记-清除或者标记-整理算法，根据使用的垃圾回收器来进行判断。

至于为什么要这样，这是由于内存分配的机制导致的，**新生代存的基本上都是朝生夕死的对象，而老年代存放的都是存活率很高的对象**。

**5、为什么要分代**

因为在不进行对象存活时间区分的情况下，每次垃圾回收都是对整个堆空间进行回收，花费时间会相对较长，也有很多对象完全没必要遍历，比如大对象存活的时间更长，遍历下来发现不需要回收，这样更浪费时间。所以才有了分代，分治的思想，进行区域划分，把不同生命周期的对象放在不同的区域，不同的区域采取最适合他的垃圾回收方式进行回收。

**6、分代垃圾回收是怎么工作的**

分代回收基于这样一个理念：不同的对象的生命周期是不一样的，因此根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用复制算法，老年代采用标记整理算法。这样来提高回收效率。

新生代执行流程：

- 把 Eden + From Survivor（S1） 存活的对象放入 To Survivor（S2） 区；
- 清空 Eden 和S1 区；
- S1 和 S2 区交换，S1 变 S2，S2变S1。

每次在S1到S2移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老年代。大对象也会直接进入老年代。

老年代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。

**7、垃圾回收器有哪些**

<img src="http://image.easyblog.top/1594299535371015eb6ac-5b51-4881-ad53-3a8d983adb26.jpeg" alt="深入理解JVM—垃圾回收器（Grabage Collector）进阶篇" style="zoom:50%;" />

**Serial**

采取复制算法，用于新生代，单线程收集器，所以在他工作时会产生StopTheWorld。单线程情况下效率更高，比如用于GUI小程序

 **ParNew**

采取复制算法，用于新生代，是Serial的多线程版本，多个GC线程同时工作，但是也会产生StopTheWorld，因为不能和工作线程并行。

**Parallel Scavenge**

采取复制算法，用于新生代，和ParNew一样，所以也会产生STW，多线程收集器，他是吞吐量优先的收集器，提供了很多参数来调节吞吐量。

 **Serial Old**

采取标记整理算法，用于老年代，单线程收集器，所以在他工作时会产生StopTheWorld。单线程情况下效率更高，比如用于GUI小程序

**Parallel Old**

采取标记整理算法，用于老年代，Parallel Scavenge收集器的老年代版本，吞吐量优先。

**CMS**

采取标记清除算法，老年代并行收集器，号称以最短STW时间为目标的收集器，并发高、停顿低、STW时间短的优点。主流垃圾收集器之一。

**G1**

采取标记整理算法，并行收集器。对比CMS的好处之一就是不会产生内存碎片，此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。而且他的STW停顿时间是可以手动控制一个长度为M毫秒的时间片段（可以用JVM参数 -XX:MaxGCPauseMillis指定），设置完后垃圾收集的时长不得超过这个（近实时）。

**8、详细介绍一下 CMS 垃圾回收器？**

采取标记清除算法，老年代并行收集器，号称以最短STW时间为目标的收集器，并发高、停顿低、STW时间短的优点。主流垃圾收集器之一。

主要分为四阶段：

- 初始标记：只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。所以此阶段会STW，但时间很短。
- 并发标记：进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程。不会STW。
- 重新标记：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。STW时间会比第一阶段稍微长点，但是远比并发标记短，效率也很高。
- 并发清除：清除GC Roots不可达对象，和用户线程一起工作，不需要暂停工作线程。

<img src="https://image.easyblog.top/CMS-work_process.jpg" style="zoom:50%;" />

所以CMS的优点是：

- 并发高
- 停顿低
- STW时间短。

缺点：

- 对cpu资源非常敏感（并发阶段虽然不会影响用户线程，但是会一起占用CPU资源，竞争激烈的话会导致程序变慢）。
- 无法处理浮动垃圾，当剩余内存不能满足程序运行要求时，系统将会出现 Concurrent Mode Failure，失败后而导致另一次Full GC的产生，由于CMS并发清除阶段用户线程还在运行，伴随程序的运行自然会有新的垃圾产生，这一部分垃圾是出现在标记过程之后的，CMS无法在本次去处理他们，所以只好留在下一次GC时候将其清理掉。
- 内存碎片问题（因为是标记清除算法）。当剩余内存不能满足程序运行要求时，系统将会出现 Concurrent Mode Failure，临时 CMS 会采用 Serial Old 回收器进行垃圾清除，此时的性能将会被降低。

**9、详细介绍一下 G1 垃圾回收器？**

采取标记整理算法，并行收集器。

特点：

- 并行与并发执行：利用多CPU的优势来缩短STW时间，在GC工作的时候，用户线程可以并行执行。
- 分代收集：无需其他收集器配合，自己G1会进行分代收集。
- 空间整合：不会像CMS那样产生内存碎片。
- 可预测的停顿：可以手动控制一个长度为M毫秒的时间片段（可以用JVM参数 -XX:MaxGCPauseMillis指定），设置完后垃圾收集的时长不得超过这个（近实时）。

原理：

G1并不是简单的把堆内存分为新生代和老年代两部分，而是把整个堆划分为多个大小相等的独立区域（Region），新生代和老年代也是一部分不需要连续Region的集合。G1跟踪各个Region里面的垃圾堆积的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。

补充：

Region不是孤立的，也就是说一个对象分配在某个Region中，他并非只能被本Region中的其他对象引用，而是整个堆中任意的对象都可以相互引用，那么在【可达性分析法】来判断对象是否存活的时候也无需扫描整个堆，Region之间的对象引用以及其他手机其中新生代和老年代之间的对象引用虚拟机都是使用Remembered Set来避免全堆扫描的。

步骤：

<img src="https://image.easyblog.top/G1%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%B5%81%E7%A8%8B.jpg" style="zoom:50%;" />

- 初始标记：仅仅标记GCRoots能直接关联到的对象，且修改TAMS的值让下一阶段用户程序并发运行时能正确可用的Region中创建的新对象。速度很快，会STW。
- 并发标记：进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程。不会STW。
- 最终标记：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。STW时间会比第一阶段稍微长点，但是远比并发标记短，效率也很高。
- 筛选回收：首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。

**10、GC日志分析**

![](https://image.easyblog.top/GC%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90.jpg)

**11、Minor GC与Full GC分别在什么时候发生**

新生代内存（Eden区）不够用时候发生Minor GC也叫YGC。

Full GC发生情况：

- 老年代被写满
- 持久代被写满
- System.gc()被显示调用（只是会告诉需要GC，什么时候发生并不知道）

**12、新生代垃圾回收器和老年代垃圾回收器都有哪些？有什么区别？**

- 新生代回收器：Serial、ParNew、Parallel Scavenge
- 老年代回收器：Serial Old、Parallel Old、CMS
- 整堆回收器：G1

新生代垃圾回收器一般采用的是复制算法，复制算法的优点是效率高，缺点是内存利用率低；老年代回收器一般采用的是标记-整理的算法进行垃圾回收。标记整理很适合大对象，不会产生空间碎片。

**13、栈上分配是什么意思**

这个就要从JVM的优化技术—**逃逸分析**讲起了。

逃逸分析的基本行为就是分析对象的动态作用域：

- 当一个对象在方法内定义时候并且只在方法中使用了，就认为没有发生逃逸；
- 当一个对象在方法中定义之后，它被外部方法所调用，就认为发生了逃逸。例如作为调用参数传递到其他参数中。

**发生了逃逸：**

```java
public StringBuilder(){
   StringBuilder sb=new StringBuilder();
   //.....处理逻辑
   return sb;
}
```

StringBuilder对象会作参数传递给其他方法，因此这里发生了逃逸，不会在桟上分配空间。

**没发生逃逸：**

```java
public String(){
   StringBuilder sb=new StringBuilder();
   //.....处理逻辑
   return sb.toString();
}
```

在方法中分配的内存没有传递给其他方法，自在本方法中使用了，没有发生逃逸，因此可以在桟上直接给StringBuilder分配内存。

**1）桟上分配**

一个方法的中的引用如果**没有发生逃逸**，则会**直接在桟帧上分配内存**，这样可以提高对象的分配效率并且可以减少GC的次数。

**桟上分配的好处**：

**不需要GC介入去回收这些对象，出栈即释放资源，可以提高性能。原理：由于我们GC每次回收对象的时候，都会触发Stop The World（STW），这时候所有用户线程都停止了，然后我们的GC线程工作去进行垃圾回收，如果对象频繁创建在我们的堆中，也就意味这我们也要频繁的暂停所有线程，这对于用户无非是非常影响体验的，栈上分配就是为了减少垃圾回收的次数**

**2）标量替换**

JVM中的原始数据类型(int,long等)都不能在进一步分解，他们就可以成为**标量**。相对的，如果一个数据可以继续分解，那么他成为聚合量，java中最典型的聚合量就是对象。如果逃逸分析证明一个对象不会被外部访问，并且这个这个对象是可以分解的，那么程序真正执行的时候可能不创建这个对象，而改为直接创建它的若干个被这个方法能够使用到的成员变量来代替。拆散后的变量便可以被单独的分析与优化，可以分别分配在栈帧或者寄存器上，原来的对象就不需要整体被分配在堆中。

标量替换的 JVM 参数如下：

- 开启标量替换：`-XX:+EliminateAllocations`
- 关闭标量替换：`-XX:-EliminateAllocations`
- 显示标量替换详情：`-XX:+PrintEliminateAllocations`

**3）锁消除**

线程同步的代价是相当高的，同步带来的后果是降低了并发性和程序性能。逃逸分析以判断某个对象是否始终只被一个线程访问，如果只被一个线程访问，那么该对象的同步操作就可以转化为没有同步的操作，这样可以大大提高并发性能 锁消除的 JVM 参数如下：

- 开启锁消除：`-XX:+EliminateLocks`
- 关闭锁消除：`-XX:-EliminateLocks`

锁消除在 JDK8 中都是默认开启的，并且锁消除都要建立在逃逸分析的基础上。

**14、简述下对象的分配规则**

<img src="http://image.easyblog.top/159754165529305b59fee-04a8-4b4d-bca0-036c837ac98d.png" alt="img" style="zoom:40%;" />

- **对象优先分配在Eden区**，如果Eden区没有足够的空间时，虚拟机执行一次YGC。并将还活着的对象放到from/to区，若本次YGC后还是没有足够的空间，则将启用分配担保机制在老年代中分配内存。
- **大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）**。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。大对象这个概念比较模糊，那么多大的对象是大对象呢？其实这个值可以使用jvm参数指定的：`-XX:PreTenureSizeThreshold=n`（仅适用于 DefNew / ParNew新生代垃圾回收器 ）。G1回收器的大对象判断，则依据Region的大小（`-XX:G1HeapRegionSize`）来判断，如果对象大于Region 50%以上，就判断为大对象Humongous Object。
- **长期存活的对象进入老年代**。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次YGC那么对象会进入Survivor区，之后每经过一次YGC那么对象的年龄加1，直到达到阀值对象进入老年区。默认阈值是15。可以通过`-XX:MaxTenuringThreshold`参数来设置。
- **动态判断对象的年龄**。其实**虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。**

- **空间分配担保**。每次进行YGC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行YGC，如果false则进行Full GC。

##### 四、实战调优

**1、你在项目中都使用了哪些参数打印GC？**

答：一般在项目中输出详细的 GC 日志，并加上可读性强的 GC 日志的时间戳。特别情况下我还会追加一些反映对象晋升情况和堆详细信息的日志，这些会单独打到gc.log文件中用来排查问题。另外，OOM 时自动 Dump 堆栈，我一般也会进行配置。

**2、常用的调优工具有哪些？**

答：JDK内置的命令行：jps（查看jvm进程信息）、jstat（监视jvm运行状态的，比如gc情况、jvm内存情况、类加载情况等）、jinfo（查看jvm参数的，也可动态调整）、jmap（生成dump文件的，在dump的时候会影响线上服务）、jhat（分析dump的，但是一般都将dump导出放到mat上分析）、jstack（查看线程的）。

JDK内置的可视化界面：JConsole、VisualVM，这两个在QA环境压测的时候很有用。

阿里巴巴开源的arthas：神器，线上调优很方便，安装和显示效果都很友好。

**3、如果有一个系统，内存一直消耗不超过10%，但是观察GC日志，发现FGC总是频繁产生，会是什么引起的？**

答：检查下系统是否存在`System.gc() ;`

4、线上一个系统跑一段时间就栈溢出了，怎么办 ？

答：1.首先检查下是否有死归这种无限递归的程序或者递归方法太多

​        2.可以看下栈大小，若太小则可以指定-Xss参数设置栈大小

**5、系统CPU经常100%，如何调优？**

CPU100%，那肯定是有线程一直在占用着系统资源，所以具体方法如下:

1. 找出哪个进程cpu占用高（top命令）
2. 该进程中的哪个线程cpu占用高（`top -Hp $pid`命令）
3. 将十进制的tid转化为十六进制（`printf %x $tid`命令）
4. 导出该线程的堆栈 (`jstack $pid >$pid.log`命令)
5. 查找哪个方法（栈帧）消耗时间 (`less $pid.log`)
6. 可以确认工作线程占比高还是垃圾回收线程占比高
7. 修改代码

**6、系统内存飙高，如何查找问题？**

1. 找出哪个进程内存占用高（top命令）
2. 查看jvm进程号（jps命令）
3. 导出堆内存 (jmap命令生成dump文件，注意：线上系统，内存特别大，jmap执行期间会对进程产生很大影响，甚至卡顿，所以操作前最好先从负载均衡里摘掉。)
4. 分析dump文件 (比如mat软件)

**7、大型项目如何进行性能瓶颈调优**

1. 数据库与SQL优化：一般dba负责数据库优化，比如集群主从等。研发负责SQL优化，比如索引、分库分表等。

2. 集群优化：一般OP负责，让整个集群可以很容易的水平扩容，再比如tomcat/nginx的一些配置优化等。

3. 硬件升级：选择最合适的硬件，充分利用资源。

4. 代码优化：很多细节，可以参照阿里巴巴规范手册和安装sonar插件这种检测代码质量的工具。也可以适当的运用并行，比如CountDownLatch等工具。

5. jvm优化：内存区域大小设置、对象年龄达到次数晋升老年代参数的调整、选择合适的垃圾收集器以及合适的垃圾收集器参数、打印详细的GC日志和oom的时候自动生成dump。

6. 操作系统优化

##### GC常用参数

- -Xmn：年轻代
- -Xms：最小堆
- -Xmx ：最大堆
- -Xss：栈空间
- -XX:+UseTLAB：使用TLAB，默认打开
- -XX:+PrintTLAB：打印TLAB的使用情况
- -XX:TLABSize：设置TLAB大小
- -XX:+DisableExplictGC：禁用System.gc()不管用 ，防止FGC
- -XX:+PrintGC：打印GC日志
- -XX:+PrintGCDetails：打印GC详细日志信息
- -XX:+PrintHeapAtGC：打印GC前后的详细堆栈信息
- -XX:+PrintGCTimeStamps：打印时间戳
- -XX:+PrintGCApplicationConcurrentTime：打印应用程序时间
- -XX:+PrintGCApplicationStoppedTime：打印暂停时长
- -XX:+PrintReferenceGC：记录回收了多少种不同引用类型的引用
- -verbose:class：类加载详细过程
- -XX:+PrintVMOptions：jvm参数
- -XX:+PrintFlagsFinal：-XX:+PrintFlagsInitial 必须会用
- -Xloggc:opt/log/gc.log：gc日志的路径以及文件名称
- -XX:MaxTenuringThreshold：升代年龄，最大值15

##### Parallel常用参数

- -XX:SurvivorRatio：年轻代中eden和from/to的比值。比如设置3就是eden:survivor=3:2，也就是from和to各占1，eden占用3
- -XX:PreTenureSizeThreshold：大对象到底多大
- -XX:MaxTenuringThreshold：升代年龄，最大值15
- -XX:+ParallelGCThreads：并行收集器的线程数，同样适用于CMS，一般设为和CPU核数相同
- -XX:+UseAdaptiveSizePolicy：自动选择各区大小比例

##### CMS常用参数

- -XX:+UseConcMarkSweepGC：设置年老代为并发收集
- -XX:ParallelCMSThreads：CMS线程数量
- -XX:CMSInitiatingOccupancyFraction：使用多少比例的老年代后开始CMS收集，默认是68%(近似值)，如果频繁发生SerialOld卡顿，应该调小，（频繁CMS回收）
- -XX:+UseCMSCompactAtFullCollection：在FGC时进行压缩
- -XX:CMSFullGCsBeforeCompaction：多少次FGC之后进行压缩
- -XX:+CMSClassUnloadingEnabled：年老代启用CMS，但默认是不会回收永久代(Perm)的。此处对Perm区启用类回收，防止Perm区内存满。
- -XX:CMSInitiatingPermOccupancyFraction：达到什么比例时进行Perm回收
- GCTimeRatio：设置GC时间占用程序运行时间的百分比
- -XX:MaxGCPauseMillis：停顿时间，是一个建议时间，GC会尝试用各种手段达到这个时间，比如减小年轻代

##### G1常用参数

- -XX:+UseG1GC：开启G1
- -XX:MaxGCPauseMillis：建议值，G1会尝试调整Young区的块数来达到这个值
- -XX:GCPauseIntervalMillis：GC的间隔时间
- -XX:+G1HeapRegionSize：分区大小，建议逐渐增大该值，1 2 4 8 16 32。随着size增加，垃圾的存活时间更长，GC间隔更长，但每次GC的时间也会更长 ZGC做了改进（动态区块大小）
- G1NewSizePercent：新生代最小比例，默认为5%
- G1MaxNewSizePercent：新生代最大比例，默认为60%
- GCTimeRatio：GC时间建议比例，G1会根据这个值调整堆空间
- ConcGCThreads：线程数量
- InitiatingHeapOccupancyPercent：启动G1的堆空间占用比例



####  智力题

##### 二进制问题

**金条问题**

有个商人雇用了一位手艺高超的工匠了为他做一个精致产品，工作一星期七天的代价是一条金条。商人手头上有一条金条，刚好有可以付工匠一星期的工钱。但工匠要求工钱要按每天来付。虽然他并不急着用钱，每天有钱进账，老人心里总是踏实一些。但商人家中有个规矩，金条每星期只能切二刀。后来商人想出以了个切割金条的办法，满足了工匠的要求。你知道商人是怎么切割金条才能满足工匠的吗？

解答：

```
切成1、2、4。这三个二进制数的组合能表示0-7中的任何一个。
```

-----

**老鼠和毒药**

实验室有100个瓶子，其中有一瓶装有慢性毒药（第3天发作)，另外99瓶装有蒸馏水。请问至少需要多少只小白鼠才能在3天内找出哪一瓶是慢性毒药？

解答：

```
利用二进制来做，最少的老鼠数量就是计算2的多少次方大于等于瓶子数量，例如本题为7。对100瓶进行二进制编码，这样可以排列出1xxxxxx，x1xxxxxx，...，xxxxxx1这样的七组序列，如果是1xxxxxx和x1xxxxx的老鼠死了，表示1100000有毒。
```



------

##### 水桶问题

 **倒水问题1**

一个装了10L水的桶，一个7L的空桶，一个3L的空桶，怎样变成2个5L

 解答：

```
初始时为10，0，0。
第二步7，0，3。
然后7，3，0。
然后4，3，3。
然后4，6，0。
然后1，6，3。
然后1，7，2。
然后8，0，2。
然后8，2，0。
然后5，2，3。
然后5，5，0。
```

\-----

**倒水问题2**

如果你有无穷多的水，一个3夸脱的和一个5夸脱的提桶，你如何准确称出 4夸脱的水？

解答：

```
初始时0，5
然后3，2
然后0，2
然后2，0
然后2，5
然后3，4
```

----

**舀酒问题**

据说有人给酒肆的老板娘出了一个难题：此人明明知道店里只有两个舀酒的勺子，分别能舀7两和11两酒，却硬要老板娘卖给他2两酒。聪明的老板娘毫不含糊，用这两个勺子在酒缸里舀酒，并倒来倒去，居然量出了2两酒，聪明的你能做到吗？

解答：

```
初始0，11
然后7，4
然后0，4
然后4，0
然后4，11
然后7，8
然后0，8
然后7，1
然后0，1
```

```
然后1，11
然后7，5
然后0，5
然后5，0
然后5，11，
然后7，9
然后0，9
然后7，2
```

-----

##### 钱问题

**赚钱问题**

一个人花8块钱买了一只鸡，9块钱卖掉了，然后他觉得不划算，花10块钱又买回来了，11块卖给另外一个人。问他赚了多少?

 解答：

```
-8+9-10+11=2
```

----

**假钱问题**

老王30买了双鞋，35卖，客人花100买，老王没零钱于是向老李换了100.补给客人后，客人走远后老李突然说是假钱，于是老王补偿给了老李，问老王一共亏了多少？

 解答：

```
卖鞋赚了35-30=5，假钱赔了100，一共亏95
```

-----

**取硬币问题**

30枚面值不全相同的硬币摆成一排，甲、乙两个人轮流选择这排硬币的其中一端，并取走最外边的那枚硬币。如果你先取硬币，能保证得到的钱不会比对手少吗？

解答：

```
先取者可以让自己总是取奇数位置上的硬币或者总是取偶数位置上的硬币。数一数是奇数位置上的面值总和多还是偶数位置上的面值总和多，然后总是取这些位置上的硬币就可以了。
```



----

 **旅馆问题**

有三个人去住旅馆，住三间房，每一间房$10元，于是他们一共付给老板$30，第二天，老板觉得三间房只需要$25元就够了于是叫小弟退回$5给三位客人，谁知小弟贪心,只退回每人$1，自己偷偷拿了$2，这样一来便等于那三位客人每人各花了九元，于是三个人一共花了$27，再加上小弟独吞了不$2，总共是$29。可是当初他们三个人一共付出$30那么还有$1呢？

解答：

```
他们所消费的27元里已经包括小弟贪污的2元了，再加退还的3元=30元。：这30元现在的分布是：老板拿25元，伙计拿2元，三人各拿1元，正好。
```



----

##### 蓝眼问题

**蓝眼睛问题**

有个岛上住着一群人，有一天来了个游客，定了一条奇怪的规矩：所有蓝眼睛的人都必须尽快离开这个岛。每晚8点会有一个航班离岛。每个人都看得见别人眼睛的颜色，但不知道自己的（别人也不可以告知）。此外，他们不知道岛上到底有多少人是蓝眼睛的，只知道至少有一个人的眼睛是蓝色的。所有蓝眼睛的人要花几天才能离开这个岛？

 解答：

```
有多少个蓝眼睛的人就会花多少天。
c=1：
假设岛上所有人都是聪明的，蓝眼睛的人四处观察之后，发现没有人是蓝眼睛的。但他知道至少有一人是蓝眼睛的，于是就能推导出自己一定是蓝眼睛的。因此，他会搭乘当晚的飞机离开。 
c=2：
两个蓝眼睛的人看到对方，并不确定c是1还是2，但是由上一种情况，他们知道，如果c = 1，那个蓝眼睛的人第一晚就会离岛。因此，发现另一个蓝眼睛的人仍在岛上，他一定能推断出c = 2，也就意味着他自己也是蓝眼睛的。于是，两个蓝眼睛的人都会在第二晚离岛。 
c>2：
逐步提高c时，我们可以看出上述逻辑仍旧适用。如果c = 3，那么，这三个人会立即意识到有2到3人是蓝眼睛的。如果有两人是蓝眼睛的，那么这两人会在第二晚离岛。因此，如果过了第二晚另外两人还在岛上，每个蓝眼睛的人都能推断出c = 3，因此这三人都有蓝眼睛。他们会在第三晚离岛。 
不论c为什么值，都可以套用这个模式。所以，如果有c人是蓝眼睛的，则所有蓝眼睛的人要用c晚才能离岛，且都在同一晚离开。 
```

----

**疯狗问题（跟蓝眼睛一样）**

有50家人家，每家一条狗。有一天警察通知，50条狗当中有病狗，行为和正常狗不一样。每人只能通过观察别人家的狗来判断自己家的狗是否生病，而不能看自己家的狗，如果判断出自己家的狗病了，就必须当天一枪打死自己家的狗。结果，第一天没有枪声，第二天没有枪声，第三天开始一阵枪响，问：一共死了几条狗？

 解答：

```
死了3条（第几天枪响就有几条）。
从有一条不正常的狗开始，显然第一天将会听到一声枪响。这里的要点是你只需站在那条不正常狗的主人的角度考虑。
有两条的话思路继续，只考虑有两条不正常狗的人，其余人无需考虑。通过第一天他们了解了对方的信息。第二天杀死自己的狗。换句话说每个人需要一天的时间证明自己的狗是正常的。有三条的话，同样只考虑那三个人，其中每一个人需要两天的时间证明自己的狗是正常的狗。
```

----

**耳光问题（跟蓝眼睛一样）**

一群人开舞会，每人头上都戴着一顶帽子。帽子只有黑白两种，黑的至少有一顶。每个人都能看到其他人帽子的颜色，却看不到自己的。主持人先让大家看看别人头上戴的是什么帽子，然后关灯，如果有人认为自己戴的是黑帽子，就打自己一个耳光。第一次关灯，没有声音。于是再开灯，大家再看一遍，关灯时仍然鸦雀无声。一直到第三次关灯，才有劈劈啪啪打耳光的声音响起。问有多少人戴着黑帽子？

解答：

```
有三个人戴黑帽。假设有N个人戴黑帽，当N＝1时，戴黑帽的人看见别人都为白则能肯定自己为黑。于是第一次关灯就应该有声。可以断定N＞1。对于每个戴黑帽的人来说，他能看见N-1顶黑帽，并由此假定自己为白。但等待N-1次还没有人打自己以后，每个戴黑人都能知道自己也是黑的了。所以第N次关灯就有N个人打自己。
```

----

##### 时间问题

**蜡烛燃烧问题**

两根蜡烛，燃烧完都需要1小时，怎么确定15分钟是多久？

 解答：

```
点燃第一根的一端，第二根的两端。
第二根烧完代表半小时后，点燃第一根另一端，烧完代表15分钟。 
```

---

##### 重量问题

**乒乓球重量**

 8个乒乓球，其中一个重，有一个秤，问至少几次能够找出重的那个乒乓球

 解答：

2次，分成3堆，3，3，2。

```
（1）称3和3，如果一样重，代表重的在2。
（2）称2个那一堆的。
------
（1）称3和3，不一样重，重的在3里面重的那堆。
（2）3个里面随便取2个，一样重，第三个重。不一样重，重的那个就是。
```

---

**盐重量问题**

有7克、2克砝码各一个，天平一只，如何只用这些物品五次内将140克的盐分成50、90克各一份？

解答： 

```
第一次：先分成70和70
第二次：通过7和2砝码将70分成9和61
第三次：通过9克盐和2砝码将61分成50和11
```

---

**药丸问题**

有20瓶药丸，其中19瓶装有1克/粒的药丸，余下一瓶装有1.1克/粒的药丸。给你一台称重精准的天平，怎么找出比较重的那瓶药丸？天平只能用一次。

 解答：

```
从药瓶#1取出一粒药丸，从药瓶#2取出两粒，从药瓶#3取出三粒，依此类推。如果每粒药丸均重1克，则称得总重量为210克（1 + 2 + … + 20 = 20 * 21 / 2 = 210），“多出来的”重量必定来自每粒多0.1克的药丸。 
药瓶的编号可由算式(weight - 210) / 0.1 得出。因此，若这堆药丸称得重量为211.3克，则药瓶#13装有较重的药丸。 
```

---

**药丸问题2**

你有四个装药丸的罐子，每个药丸都有一定的重量，被污染的药丸是没被污染的重量+1.只称量一次，如何判断哪个罐子的药被污染了？

解答：

```
从第一盒中取出一颗，第二盒中取出2 颗，第三盒中取出三颗。 依次类推，称其总量。减去10，多的数字就是药丸罐子序号。
```

----

##### 数学问题

**概率问题1**

一个家庭有两个小孩，其中有一个是女孩，问另一个也是女孩的概率（假定生男生女的概率一样）

 解答：

```
1/3
样本空间为（男男）（女女）（男女）（女男）
A＝（已知其中一个是女孩）＝）（女女）（男女）（女男）
B＝（另一个也是女孩）＝（女女）
于是P（B／A）＝P（AB）／P（A）＝（1／4）／（3／4）＝1／3
```

---

 **概率问题2**

你有两个罐子，每个罐子各有若干红色弹球和蓝色弹球，两个罐子共有50个红色弹球，50个蓝色弹球，随机选出一个罐子，随机从中选取出一个弹球，要使取出的是红球的概率最大，一开始两个罐子应放几个红球，几个蓝球？在你的计划中，得到红球的准确几率是多少？

解答：

```
一个罐子放1红，一个罐子放49红和50蓝，这样得到红球的概率接近3/4。
```

---

**扑克牌问题**

54张扑克牌，其中有十张是翻过来的。现在把你的眼睛蒙上，让你把扑克牌分成两叠（两叠的多少可以不一样）。要求在两叠中翻过来的扑克牌是相等的。请问该怎么做？

 解答：

```
第一步，你在这54张牌中任意取出10张，现在，扑克牌分成了两叠。44张和10张；第二步，44张那叠不动，将10张这叠每张都翻过来，便得到了符合条件的两叠牌。
解释：第一步之后，设44张那叠中正面牌x张，10张那叠中正面牌则为10-x张。第二步之后，44张那叠中正面牌保持x张，10张那叠反过来了：反面牌为10-x张，正面牌x张。
```

---

**扔鸡蛋问题**

有栋建筑物高100层。若从第N层或更高的楼层扔下来，鸡蛋就会破掉。若从第N层以下的楼层扔下来则不会破掉。给你2个鸡蛋，请找出N，并要求最差情况下扔鸡蛋的次数为最少。

解答：

```
14次
首先，让我们试着从10层开始扔鸡蛋，然后是20层，等等。 
如果鸡蛋1第一次扔下楼（10层）就破掉了，那么，最多需要扔10次。 
如果鸡蛋1最后一次扔下楼（100层）才破掉，那么，最多要扔19次（10、20、…、90、100层，然后是91到99层）。 
这么做也挺不错，但我们只考虑了绝对最差情况。我们应该进行“负载均衡”，让这两种情况下扔鸡蛋的次数更均匀。 我们的目标是设计一种扔鸡蛋的方法，使得扔鸡蛋1时，不论是在第一次还是最后一次扔下楼才破掉，次数越稳定越好。 
(1) 完美负载均衡的方法应该是，扔鸡蛋1的次数加上扔鸡蛋2的次数，不论什么时候都一样，不管鸡蛋1是从哪层楼扔下时破掉的。 
(2) 若有这种扔法，每次鸡蛋1多扔一次，鸡蛋2就可以少扔一次。 
(3) 因此，每丢一次鸡蛋1，就应该减少鸡蛋2可能需要扔下楼的次数。例如，如果鸡蛋1先从20层往下扔（不破），然后从30层扔下楼（破），此时鸡蛋2可能就要扔9次（从21到29 一次次试）。若鸡蛋1再扔一次，我们必须让鸡蛋2扔下楼的次数降为8次。也就是说，我们必须让鸡蛋1从39层扔下楼。 
(4) 由此可知，鸡蛋1必须从X层开始往下扔，然后再往上增加X-1层……直至到达100层。  
(5) 求解方程式X + (X-1) + (X-2) + … + 1 = 100，得到X (X + 1) / 2 = 100 → X = 14。
我们先从14层开始，然后是27层，接着是39层，依此类推，最差情况下鸡蛋要扔14次。 
其他情况也是一样的只需要求X (X + 1) / 2 = 楼层数量的X大约值即可。
```

---

**填数字**

0 1 2 3 4 5 6 7 8 9

\_  _  _  _  _  _  _  _  _  _ 在横线上填写数字，使之符合要求。

要求如下：对应的数字下填入的数，代表上面的数在下面出现的次数，比如3下面是1，代表3要在下面出现一次。

解答：

```
6 2 1 0 0 0 1 0 0 0
```

---

**规律**

1，11，21，1211，111221，下一个数是什么？

解答：

```
下行是对上一行的解释 所以新的应该是3个1 2个2 1个1 ：312211
```

-----

**猜数字问题**

教授选出两个从2到9的数，把它们的和告诉学生甲，把它们的积告诉学生乙，让他们轮流猜这两个数， 甲说：“我猜不出”， 乙说：“我猜不出”， 甲说：“我猜到了”，  乙说：“我也猜到了”， 问这两个数是多少？

解答：

```
3和4。设两个数为n1，n2，n1> =n2，甲听到的数为n=n1 n2，乙听到的数为m=n1*n2，证明n1=3，n2=4是唯一解。
证明：要证以上命题为真，不妨先证n=7
1)必要性：
  　i)  n> 5  是显然的，因为n <4不可能，n=4或者n=5甲都不可能回答不知道
  　ii)  n> 6  因为如果n=6的话，那么甲虽然不知道(不确定2 4还是3 3)但是无论是2，4还是3，3乙都不可能说不知道(m=8或者m=9的话乙说不知道是没有道理的)
  　iii)  n <8  因为如果n> =8的话，就可以将n分解成  n=4 x  和  n=6 (x-2)，那么m可以是4x也可以是6(x-2)而4x=6(x-2)的必要条件是x=6即n=10，那样n又可以分解成8 2，所以总之当n> =8时，n至少可以分解成两种不同的合数之和，这样乙说不知道的时候，甲就没有理由马上说知道。以上证明了必要性。
2)充分性
当n=7时，n可以分解成2 5或3 4
显然2 5不符合题意，舍去，容易判断出3 4符合题意，m=12，证毕
于是得到n=7  m=12  n1=3  n2=4是唯一解。 
```

---

##### 其他问题

**水果标签问题**

3个箱子里面放了 苹果，梨子，苹果加梨子，标签全错误，只能选择查看一箱的水果来改正所有标签

 解答：

```
查看贴苹果和梨标签那一个，如果拿出来的是苹果，代表这一箱只有苹果，因为如果是苹果和梨就代表标签没错了。
那么剩下的两箱就是梨，苹果和梨，剩下的标签是梨，苹果，由于标签全错，所以贴着苹果的是梨，贴着梨的是苹果和梨。
如果拿出来的是梨，同理代表这一箱只有梨。那么剩下的两箱就是苹果，苹果和梨，剩下的标签就是苹果，梨。由于标签全错，贴着苹果的就是苹果和梨，贴着梨的就是苹果。
```

----

**便士标签问题（和水果标签一样）**

假设在桌上有三个密封的盒，一个盒中有2枚银币(1银币=10便士)，一个盒中有2枚镍币(1镍币=5便士)，还有一个盒中有1枚银币和1枚镍币。这些盒子被标上10便士、 15便士和20便士，但每个标签都是错误的。允许你从一个盒中拿出1枚硬币放在盒前，看到这枚硬币，你能否说出每个盒内装的东西呢？

----

**吃药问题**

某种药方要求非常严格，你每天需要同时服用A、B两种药片各一颗，不能多也不能少。这种药非常贵，你不希望有任何一点的浪费。一天，你打开装药片A的药瓶，倒出一粒药片放在手心；然后打开另一个药瓶，但不小心倒出了两粒药片。现在，你手心上有一颗药片A，两颗药片B，并且你无法区别哪个是A，哪个是B。你如何才能严格遵循药方服用药片，并且不能有任何的浪费？

解答：

```
把手上的三片药各自切成两半，分成两堆摆放。再取出一粒药片A，也把它切成两半，然后在每一堆里加上半片的A。现在，每一堆药片恰好包含两个半片的A和两个半片的B。一天服用其中一堆即可。
```

---

 **硬币问题**

如何用一枚硬币等概率地产生一个1到3之间的随机整数？如果这枚硬币是不公正的呢？

答案：如果是公正的硬币，则投掷两次，“正反”为1，“反正”为2，“正正”为3，“反反”重来。**

解答：

```
如果是不公正的硬币，注意到出现“正反”和“反正”的概率一样，因此令“正反反正”、“反正正反”、“正反正反”分别为1、2、3，其余情况重来。另一种更妙的办法是，投掷三次硬币，“正反反”为1，“反正反”为2，“反反正”为3，其余情况重来。
```

---

**灯管问题**

在房里有三盏灯，房外有三个开关，在房外看不见房内的情况，你只能进门一次，你用什么方法来区分那个开关控制那一盏灯？

解答：

```
打开一个开关。过10分钟后关掉开关，并打开另一个开关。进屋确认可知：
亮的灯是由第二次打开的开关控制；
摸上去发热的不发亮的灯是由第一次打开的开关控制
剩下的第三盏灯是由未操作过的开关控制。
```

---

**盲人问题**

他们都各自买了两对黑袜和两对白袜，八对袜了的布质、大小完全相同，而每对袜了都有一张商标纸连着。两位盲人不小心将八对袜了混在一起。 他们每人怎样才能取回黑袜和白袜各两对呢？

解答： 

```
每一对分开，一人拿一只，因为袜子不分左右脚。
```

-----

**最大钻石问题**

一楼到十楼的每层电梯门口都放着一颗钻石，钻石大小不一。你乘坐电梯从一楼到十楼，每层楼电梯门都会打开一次，只能拿一次钻石，问怎样才能拿到最大的一颗？

解答：

```
选择前五层楼都不拿，观察各层钻石的大小，做到心中有数。后面五个楼层再选择，选择大小接近前五层楼出现过最大钻石大小的钻石。
```





#### Spring体系

##### 1、说一下spring中Bean的作用域

**singleton：**

  Spring IoC容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。Singleton作用域是Spring中的缺省作用域。

**prototype：**

  每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对象。

**request：**

  在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效。

**session：**

  在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效。

**global Session：**

  在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。

##### 2、说一下spring中Bean的生命周期

<img src="https://img-blog.csdnimg.cn/20201028180446251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzI0NDY5OA==,size_16,color_FFFFFF,t_70#pic_center" style="width:69%;" />

- 实例化一个Bean，也就是我们通常说的new。
- 按照Spring上下文对实例化的Bean进行配置，也就是IOC注入。
- 如果这个Bean实现了BeanNameAware接口，会调用它实现的setBeanName(String beanId)方法，此处传递的是Spring配置文件中Bean的ID。
- 如果这个Bean实现了BeanFactoryAware接口，会调用它实现的setBeanFactory()，传递的是Spring工厂本身（可以用这个方法获取到其他Bean）。
- 如果这个Bean实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文。
- 如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用After方法，也可用于内存或缓存技术。
- 如果这个Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。
- 如果这个Bean关联了BeanPostProcessor接口，将会调用postAfterInitialization(Object obj, String s)方法。
- 当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean接口，会调用其实现的destroy方法。
- 最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。

##### 3、**对Spring中依赖注入（DI）三种方式的认识**

**三种注入方式为：构造方法注入、setter方法注入和使用字段(Filed)注入（用注解方式）**

1. 设值注入与传统的JavaBean的写法更相似，程序员更容易理解、接受，通过setter方式设定依赖关系显得更加直观、明显;
2. 对于复杂的依赖关系，如果采用构造注入，会导致构造器过于臃肿，难以阅读。Spring在创建Bean实例时，需要同时实例化其依赖的全部实例，因而会产生浪费。而使用设置注入，则避免这下问题;
3. 在某些属性可选的情况下，多参数的构造器更加笨拙，官方更鼓励使用设值注入。
4. 构造注入可以在构造器中决定依赖关系的注入顺序，优先依赖的优先注入。
5. 对于依赖关系无须变化的Bean，构造注入更有用处，因为没有setter方法，所有的依赖关系全部在构造器内设定，因此，不用担心后续代码对依赖关系的破坏。
6. 构造注入使依赖关系只能在构造器中设定，则只有组件的创建者才能改变组件的依赖关系。对组件的调用者而言，组件内部的依赖关系完全透明，更符合高内聚的原则。
7. 设值注入不会重写构造方法的值。如果我们对同一个变量同时使用了构造方法注入又使用了设置方法注入的话，那么构造方法将不能覆盖由设值方法注入的值。
8. 建议采用以设值注入为主，构造注入为辅的注入策略。对于依赖关系无须变化的注入，尽量采用构造注入;而其他的依赖关系的注入，则考虑采用set注入。

##### **4、Spring框架中都用到了哪些设计模式？**

- 代理模式：在AOP和remoting中被用的比较多。
- 单例模式：在spring配置文件中定义的bean默认为单例模式。
- 模板方法模式：用来解决代码重复的问题。
- 前端控制器模式：Spring提供了DispatcherServlet来对请求进行分发。
- 依赖注入模式：贯穿于BeanFactory / ApplicationContext接口的核心理念。
- 工厂模式：BeanFactory用来创建对象的实例。

##### **5、BeanFactory 和ApplicationContext的区别**

BeanFactory 粗暴简单，可以理解为就是个 HashMap，Key 是 BeanName，Value 是 Bean 实例。通常只提供注册（put），获取（get）这两个功能。我们可以称之为 “低级容器”。

ApplicationContext 可以称之为 “高级容器”。因为他比 BeanFactory 多了更多的功能。他继承了多个接口。因此具备了更多的功能（例如资源的获取，支持多种消息（例如 JSP tag 的支持），对 BeanFactory 多了工具级别的支持等待。所以你看他的名字，已经不是 BeanFactory 之类的工厂了，而是 “应用上下文”， 代表着整个大容器的所有功能。）。该接口定义了一个 refresh 方法，此方法是所有阅读 Spring 源码的人的最熟悉的方法，用于刷新整个容器，即重新加载/刷新所有的 bean。

##### 6、spring IOC了解吗？讲一下

控制反转（`Inversion of Control`，简称`IoC`），是面向对象编程中的一种设计原则，可以用来降低代码之间的耦合度。其中最常见的方式叫做依赖注入（`Dependency Injection`，简称`DI`），还有一种方式叫“依赖查找”（`Dependency Lookup`）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体，将其所依赖的对象的引用传递(注入)给它。

谁控制谁，控制什么：

- 在之前，没有IOC时，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；
- 而现在，是由IOC专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；
- `谁控制谁？`当然是IOC容器控制了对象；`控制什么？`那就是主要控制了外部资源获取（不只是对象还包括比如文件等）。

所谓反转：

- 所谓的反转，其实是反转的控制权，由 `Spring` 来控制对象的生命周期，那么对象的控制就完全脱离了我们的控制，控制权交给了`Spring`。这个反转是指：我们由对象的控制者变成了`IOC` 的被动控制者。

**IOC的两种实现：依赖查找（DL）和依赖注入（DI）**。

IOC 和 DI 、DL 的关系：

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/12/java5-1609402546.png" style="zoom:70%;" />

- DI（`Dependency Injection`） 是 Spring 使用的方式，容器负责组件的装配。是 `IOC` 的具体实现。程序把依赖交给容器，容器帮你管理依赖。
- DL（`Dependency Lookup`）已经被抛弃。

**IOC容器的原理**

IOC容器其实就是一个大工厂，它用来管理我们所有的对象以及依赖关系。原理就是通过Java的反射技术来实现的！通过反射我们可以获取类的所有信息(成员变量、类名等等等)！再通过配置文件(xml)或者注解来描述类与类之间的关系。我们就可以通过这些配置信息和反射技术来构建出对应的对象和依赖关系了！

我们简单来看看实际Spring IOC容器是怎么实现对象的创建和依赖的：

<img src="https://www.javazhiyin.com/wp-content/uploads/2020/12/java6-1609402546.jpeg"  style="zoom:67%;" />

1. 根据Bean配置信息[在容器内部创建Bean](http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&mid=2247496582&idx=1&sn=d0253316d1b3efe8f66ab44dd4774817&chksm=fc799e28cb0e173e59a33aba80c96830fbff7260bea8d252504077bda776d7b8ba64a0eea4be&scene=21#wechat_redirect)定义注册表
2. 根据注册表加载、实例化bean、建立Bean与Bean之间的依赖关系
3. 将这些准备就绪的Bean放到Map缓存池中，等待应用程序调用

**IOC容器体系**

Spring容器(Bean工厂)可简单分成两种：BeanFactory（"低级容器"）和ApplicationContext（”高级容器“），ApplicationContext是BeanFactory的子类。为了更直观的展示 “低级容器” 和 “高级容器” 的关系，我这里通过常用的 ClassPathXmlApplicationContext 类，来展示整个容器的层级 UML 关系。

<img src="https://image.easyblog.top/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20210125141655.jpg" style="zoom:67%;" />

最上面的 BeanFactory 知道吧？我就不讲了。

下面的 3 个绿色的，都是功能扩展接口，这里就不展开讲。

看下面的隶属 ApplicationContext 粉红色的 “高级容器”，依赖着 “低级容器”，这里说的是依赖，不是继承哦。他依赖着 “低级容器” 的 getBean 功能。而高级容器有更多的功能：支持不同的信息源头，可以访问文件资源，支持应用事件（Observer 模式）。

通常用户看到的就是 “高级容器”。 但 BeanFactory 也非常够用啦！

左边灰色区域的是 “低级容器”， 只负载加载 Bean，获取 Bean。容器其他的高级功能是没有的。例如上图画的 refresh 刷新 Bean 工厂所有配置。生命周期事件回调等。

**IOC容器初始化过程**

> 解释了低级容器和高级容器，我们可以看看一个 IoC 启动过程是什么样子的。说白了，就是 ClassPathXmlApplicationContext 这个类，在启动时，都做了啥。（由于我这是 interface21 的代码，肯定和你的 Spring 4.x 系列不同）。

下图是 ClassPathXmlApplicationContext 的构造过程，实际就是 Spring IoC 的初始化过程。

<img src="https://image.easyblog.top/spring%20IOC%20%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B.jpg" style="zoom:70%;" />

这里再用文字来描述这个过程：

1. 用户在程序中构造 ClassPathXmlApplicationContext（简称 CPAC）
2. CPAC 首先访问了 “抽象高级容器” 的 final 的 refresh 方法，这个方法是模板方法。所以要回调子类（低级容器）的 refreshBeanFactory 方法，这个方法的作用是使用低级容器加载所有 BeanDefinition 和 Properties 到容器中。
3. 低级容器加载成功后，高级容器开始处理一些回调，例如 Bean 后置处理器。回调 setBeanFactory 方法。或者注册监听器等，发布事件，实例化单例 Bean 等等功能，这些功能，随着 Spring 的不断升级，功能越来越多，很多人在这里迷失了方向 ：）。

简单说就是：

1. 低级容器 加载配置文件（从 XML，数据库，Applet），并解析成 BeanDefinition 到低级容器中。
2. 加载成功后，高级容器启动高级功能，例如接口回调，监听器，自动实例化单例，发布事件等等功能。

 所以，一定要把 “低级容器” 和“高级容器” 的区别弄清楚。不能一叶障目不见泰山。

好，当我们创建好容器，就会使用 getBean 方法，获取 Bean实例对象，getBean 的流程如下：

<img src="https://image.easyblog.top/getBean.png" style="zoom:67%;" />

从图中可以看出，getBean 的操作都是在低级容器（AbstractBeanFactory）里操作的。其中有个递归操作，这个是什么意思呢？

假设：当 Bean_A 依赖着 Bean_B，而这个 Bean_A 在加载的时候，其配置的 ref = “Bean_B” 在解析的时候只是一个占位符，被放入了 Bean_A 的属性集合中，当调用 getBean 时，需要真正 Bean_B 注入到 Bean_A 内部时，就需要从容器中获取这个 Bean_B，因此产生了递归。

为什么不是在加载的时候，就直接注入呢？因为加载的顺序不同，很可能 Bean_A 依赖的 Bean_B 还没有加载好，也就无法从容器中获取，你不能要求用户把 Bean 的加载顺序排列好，这是不人道的。

所以，Spring 将其分为了 2 个步骤：

1. 加载所有的 Bean 配置成 BeanDefinition 到容器中，如果 Bean 有依赖关系，则使用占位符暂时代替。
2. 然后，在调用 getBean 的时候，进行真正的依赖注入，即如果碰到了属性是 ref 的（占位符），那么就从容器里获取这个 Bean，然后注入到实例中 —— 称之为依赖注入。可以看到，依赖注入实际上，只需要 “低级容器” 就可以实现。

##### 7、spring AOP了解吗？讲一下

**什么是AOP？**

AOP，即面向切面编程。通过预编译的方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生泛型，利用AOP可以对业务逻辑的各个部分进行隔离，从而使业务逻辑各个部分的耦合度降低，提高程序的可重用性，同时提高了开发效率。

**Spring AOP和AspectJ的关系？**

* Spring AOP 使用纯Java代码实现，不需要专门的编译过程和类加载器，在运行期通过代理方式向目标类织入增强代码。
* `AspectJ`是一个基于Java的**AOP框架**，Spring2.0开始，Spring AOP引入AspectJ的支持，AspectJ扩展了Java语言，提供了一个专门的编译器，在编译时提供横向代码的织入。

**Spring中AOP的实现**

**Spring AOP的底层实现有两种方式：一种是JDK动态代理，另一种是CGLib的方式**。

* JDK动态代理主要涉及java.lang.reflect包下边的两个类：**Proxy和InvocationHandler**。其中，InvocationHandler是一个接口，可以通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态地将横切逻辑和业务逻辑编织在一起。**JDK动态代理是面向接口的代理模式**，如果被代理目标没有接口那么Spring也无能为力，Spring通过Java的反射机制生产被代理接口的新的匿名实现类，重写了其中AOP的增强方法。
* **CGLib采用底层的字节码技术**，全称是：Code Generation Library，CGLib可以为一个类创建一个子类，Spring在运行期间通过 CGlib继承要被动态代理的类，重写父类的方法，实现AOP面向切面编程。
* **JDK动态代理 和 CGLib动态代理性能对比**：在1.6和1.7的时候，JDK动态代理的速度要比CGLib动态代理的速度要慢，但是并没有教科书上的10倍差距，在JDK1.8的时候，JDK动态代理的速度已经比CGLib动态代理的速度快很多了

**Spring AOP的原理**

可以将 AOP 分成 2 个部分来看， 第一：代理的创建； 第二：代理的调用。

##### 1、代理的创建（按步骤）：

1. 首先，需要创建代理工厂，代理工厂需要 3 个重要的信息：拦截器数组，目标对象接口数组，目标对象。
2. 创建代理工厂时，默认会在拦截器数组尾部再增加一个默认拦截器 —— 用于最终的调用目标方法。
3. 当调用 getProxy 方法的时候，会根据接口数量大余 0 条件返回一个代理对象（JDK or Cglib）。

##### 2、代理的调用

1. 当对代理对象进行调用时，就会触发外层拦截器。
2. 外层拦截器根据代理配置信息，创建内层拦截器链。创建的过程中，会根据表达式判断当前拦截是否匹配这个拦截器。而这个拦截器链设计模式就是职责链模式。
3. 当整个链条执行到最后时，就会触发创建代理时那个尾部的默认拦截器，从而调用目标方法。最后返回。

<img src="https://www.javazhiyin.com/wp-content/uploads/2018/10/java1-1539741534.jpg" style="zoom:60%;" />

关于调用过程，来张流程图：

<img src="https://www.javazhiyin.com/wp-content/uploads/2018/10/java7-1539741534.jpg"  style="zoom:67%;" />

##### **8、谈谈Spring MVC的工作流程**

<img src="http://image.easyblog.top/1597936663684c9fe5f02-c484-4866-baf1-88e4a152b2a6.png" style="zoom:50%;" />

SpringMVC的执行流程具体步骤：

第一步：客户端向服务器发起请求，DispatcherServlet（**前端控制器**）捕获用户请求

第二步：DispatcherServlet对请求的URL进行解析得到URI，并根据URI调用**HandlerMapping**查找Handler（可以根据xml配置，注解进行查找）并返回一个Handler

第三步：HandlerMapping向前端控制器返回Handler，HandlerMapping会把请求映射为**HandlerExecutionChain**对象（包含一个Handler处理器（页面控制器）对象，多个HandlerInterceptor拦截器对象），通过这种策略模式，很容易添加新的映射策略

第四步：DispatcherServlet根据得到的Handler选择一个合适的HandlerAdapter，提取Request中的模型数据，填充Handler入参，开始执行目标Contorller中的方法

第五步：Contorller执行完成后选择一个合适的ViewResolver将返回对象**ModelAndView**返回给DispatcherServlet

第六步：ViewResolver结合View和Model渲染视图并将渲染结果（HTML页面）返回给客户端。



##### 9、拦截器是什么，什么场景使用？

 Spring MVC中的拦截器（Interceptor）类似Servlet中的过滤器（Filter），但是比过滤器的功能更强大，它主要用于拦截用户请求并作相应的处理。例如**通过拦截器可以进行权限验证，记录请求信息的日志，判断用户是否登录，解决乱码问题等**。要使用Spring MVC中的拦截器，就需要对拦截器类进行定义和配置。通常拦截器类可以通过两种方式来定义：

1.通过实现HandlerInterceptor

 2.通过实现WebRequestInterceptor接口，或继承WebRequestInterceptor接口的实现类来定义。

HandlerInterceptor接口中有三种方法：

- preHandle（）：在目标方法执行之前回执行，有个布尔类型的返回值，当返回真表示放行，即允许执行目标方法；当返回false，表示不放行，即不运行执行目标方法，此时会中断以后的所有过程
- postHandle（）：在目标方法执行结束后会执行，并且解析视图之前执行
- afterCompletion（）：在请求到达页面，即视图渲染完成后执行

**拦截器和过滤器比较**
①拦截器是基于java的反射机制的，而过滤器是基于函数回调。
②拦截器不依赖与servlet容器，过滤器依赖与servlet容器。
③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。
④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。
⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。
⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑



##### 10、Spring中常见的使用多的注解有哪些

* 1、@Controller

	在SpringMVC 中提供了一个非常简便的定义Controller 的方法，你无需继承特定的类或实现特定的接口，只需使用@Controller 标记一个类是Controller ，然后使用@RequestMapping 和@RequestParam 等一些注解用以定义URL 请求和Controller 方法之间的映射，这样的Controller 就能被外界访问到。

* 2、@RequestMapping

	RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。

* 3、@Resource和@Autowired

	@Resource和@Autowired都是做bean的注入时使用，其实@Resource并不是Spring的注解，它的包是javax.annotation.Resource，需要导入，但是Spring支持该注解的注入。

* 4、@ModelAttribute和 @SessionAttributes

	代表的是：该Controller的所有方法在调用前，先执行此@ModelAttribute方法，可用于注解和方法参数中，可以把这个@ModelAttribute特性，应用在BaseController当中，所有的Controller继承BaseController，即可实现在调用Controller时，先执行@ModelAttribute方法。
	@SessionAttributes即将值放到session作用域中，写在class上面。

* 5、@PathVariable

	用于将请求URL中的模板变量映射到功能处理方法的参数上，即取出uri模板中的变量作为参数。

* 6、@RequestParam

	@RequestParam主要用于在SpringMVC后台控制层获取参数，类似一种是request.getParameter("name")，它有三个常用参数：defaultValue = "0", required = false, value = "isApp"；defaultValue 表示设置默认值，required 铜过boolean设置是否是必须要传入的参数，value 值表示接受的传入的参数类型。

* 7、@ResponseBody

	作用： 该注解用于将Controller的方法返回的对象，通过适当的HttpMessageConverter转换为指定格式后，写入到Response对象的body数据区。
	使用时机：返回的数据不是html标签的页面，而是其他某种格式的数据时（如json、xml等）使用；

* 8、@Component

	于通用的注解，当不知道一些类归到哪个层时使用，但是不建议。

* 9、@Repository
	用于注解dao层，在daoImpl类上面注解

##### 11、你之前项目中异常/国际化如何处理

**优雅的处理异常**

Spring 在 3.2 版本已经为我们提供了该功能： @ControllerAdvice 注解。此注解会捕捉Controller层抛出的异常，并根据 @ExceptionHandler 注解配置的方法进行异常处理。

一般在项目现在项目都是前后端分离的项目，返回的前端的一般都是JSON，因此为了统一管理，在项目中我会定义一个Controller返回对象专门用于返回各种信息给前端，一般我们都会在对象中定义三个字段：处理结果码code，处理结果信息msg、处理响应数据data(是个泛型)，除此之外还会定义一个系统异常枚举类，专门用于枚举系统中可能会出现的异常并继承RuntimeException实现一个自定义的异常，之后再需要抛异常的地方就通过自定义异常和自定义返回对象来给前端抛出异常。

<img src="https://image.easyblog.top/QQ%E6%88%AA%E5%9B%BE20210126151012.png" style="zoom:67%;" />

**资源国际化**

* 1、编写国际化资源文件：国际化资源文件就是使用一种键值的形式把要显示的信息的不同语言的翻译版本写到属性资源文件中。一般情况下我们用`*._zh_CN.properties`表示中文资源文件，`*._en_US.properties`表示英文资源，`*.properties`表示替代的资源文件。详请参考下图：

	<img src="https://i.loli.net/2019/08/14/OEKzenjBUhvIGDq.png" alt="img" style="zoom:50%;" />

* 2、自定义区域信息解析器

	（1）写一个类实现LocaleResolver接口或他的子接口或继承他的实现类，最主要是要实现它的resolveLocale()方法

	（2）在springmvc的配置文件中注册自定义的区域信息解析器

	（3）启动测试